{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Morgan Turville-Heitz\n",
    "CS 760\n",
    "10/18/2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myModel():\n",
    "\n",
    "    def __init__(self, w1_init, w2_init):\n",
    "        self.W_1 = w1_init\n",
    "        self.W_2 = w2_init\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "### Using TF for loading of the MNIST data, since it's built-in conveniently\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "tags": [
     "Not used"
    ]
   },
   "outputs": [],
   "source": [
    "def first_Layer(x, W_1):\n",
    "    ### For some single datapoint, x = [x1:xd]\n",
    "    ### Take x * W1_j to be the input into sigmoid j\n",
    "    h = sigmoid(np.dot(W_1, x))\n",
    "    return(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "tags": [
     "Not used"
    ]
   },
   "outputs": [],
   "source": [
    "def softmax(h, W_2):\n",
    "    z = np.dot(W_2, h)\n",
    "    z -= np.max(z)  # For numerical stability\n",
    "    yhats = np.exp(z) / np.sum(np.exp(z))\n",
    "\n",
    "    return yhats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "### Normalizing\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SHUFFLING THE DATA HERE ###\n",
    "\n",
    "ind = np.arange(x_train.shape[0])\n",
    "np.random.shuffle(ind)\n",
    "x_train = x_train[ind]\n",
    "y_train = y_train[ind]\n",
    "\n",
    "### Shuffle the test data and labels\n",
    "ind = np.arange(x_test.shape[0])\n",
    "np.random.shuffle(ind)\n",
    "x_test = x_test[ind]\n",
    "y_test = y_test[ind]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Converting to vectors in d x 1 \n",
    "x_train = x_train.reshape(x_train.shape[0], 28*28) \n",
    "x_test = x_test.reshape(x_test.shape[0], 28*28) \n",
    "### Converting to (k x 1) one-hot vectors in y\n",
    "y_train = np.eye(10)[y_train]\n",
    "y_test = np.eye(10)[y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectors X are 784 x 1 \n",
      "X Test dataset is (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "#Getting length of x from the first row of x\n",
    "d = len(x_train[0])\n",
    "print(f\"Vectors X are {d} x 1 \")\n",
    "print(f\"X Test dataset is {x_test.shape}\")\n",
    "d1 = 300\n",
    "d2 = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mini_batches(X, Y, batch_size):\n",
    "    m = len(Y)\n",
    "    indices = np.arange(m)\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    for start_idx in range(0, m, batch_size):\n",
    "        batch_idx = indices[start_idx:start_idx + batch_size]\n",
    "        yield X[batch_idx], Y[batch_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "Not used"
    ]
   },
   "outputs": [],
   "source": [
    "#W_1 = np.zeros((d1, d))\n",
    "#W_2 = np.zeros((d2, d1))\n",
    "W_1 = np.random.randn(d1, d) * 0.01\n",
    "W_2 = np.random.randn(d2, d1) * 0.01\n",
    "\n",
    "### Please note that I defined this myself, just to keep track of my weight vectors. I am not using a built-in Model method here.\n",
    "model = myModel(W_1, W_2)\n",
    "\n",
    "train_e = []\n",
    "test_e = []\n",
    "\n",
    "\n",
    "epochs = 15\n",
    "alpha = 0.006\n",
    "batch_size = 64  \n",
    "\n",
    "num_batches = len(x_train) // batch_size\n",
    "if len(x_train) % batch_size != 0:\n",
    "    num_batches += 1\n",
    "print(f\"Number of batches: {num_batches}\")\n",
    "interval = num_batches // 4\n",
    "\n",
    "for i in range(0, epochs):\n",
    "    print(f\"Epoch = {i}\")\n",
    "    \n",
    "    for j, (x_batch, y_batch) in enumerate(mini_batches(x_train, y_train, batch_size)):\n",
    "        dW1_total = np.zeros_like(model.W_1)\n",
    "        dW2_total = np.zeros_like(model.W_2)\n",
    "        \n",
    "        batch_loss = 0\n",
    "\n",
    "        for x_train_SGD, y_train_SGD in zip(x_batch, y_batch):\n",
    "            h = first_Layer(x_train_SGD, model.W_1)\n",
    "            yhats = softmax(h, model.W_2)\n",
    "            \n",
    "            epsilon = 1e-10\n",
    "            cross_loss = -np.sum(y_train_SGD * np.log(yhats + epsilon))\n",
    "            batch_loss += cross_loss\n",
    "\n",
    "            ### Backwards pass\n",
    "            e_term = yhats - y_train_SGD\n",
    "            sum_Term = h * (1 - h) * np.dot(model.W_2.T, e_term)\n",
    "            \n",
    "            dW2_total += np.outer(e_term, h)\n",
    "            dW1_total += np.outer(sum_Term, x_train_SGD)\n",
    "        \n",
    "        model.W_2 = model.W_2 - alpha * (dW2_total / batch_size)\n",
    "        model.W_1 = model.W_1 - alpha * (dW1_total / batch_size)\n",
    "\n",
    "        if j % 30 == 0:\n",
    "            train_e.append(batch_loss / batch_size)\n",
    "\n",
    "            total_test_loss = 0\n",
    "            for x_test_SGD, y_test_SGD in zip(x_test, y_test):\n",
    "                htest = first_Layer(x_test_SGD, model.W_1)\n",
    "                yhatstest = softmax(htest, model.W_2)\n",
    "                epsilon = 1e-10\n",
    "                cross_loss_test = -np.sum(y_test_SGD * np.log(yhatstest + epsilon))\n",
    "                total_test_loss += cross_loss_test\n",
    "            test_e.append(total_test_loss / len(x_test))\n",
    "\n",
    "            print(f\"  Batch {j}/{num_batches} - Training loss: {batch_loss / batch_size:.4f} - Average Test loss: {total_test_loss / len(x_test):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above is old code - below is what I am using after vectorizing the model for mini-batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches: 938\n",
      "Epoch = 0\n",
      "  Batch 0/938 - Training loss: 2.3132 - Average Test loss: 2.3044\n",
      "  Batch 100/938 - Training loss: 2.3031 - Average Test loss: 2.2902\n",
      "  Batch 200/938 - Training loss: 2.2751 - Average Test loss: 2.2738\n",
      "  Batch 300/938 - Training loss: 2.2265 - Average Test loss: 2.2409\n",
      "  Batch 400/938 - Training loss: 2.1660 - Average Test loss: 2.1727\n",
      "  Batch 500/938 - Training loss: 2.1274 - Average Test loss: 2.0572\n",
      "  Batch 600/938 - Training loss: 1.8531 - Average Test loss: 1.8974\n",
      "  Batch 700/938 - Training loss: 1.6803 - Average Test loss: 1.6980\n",
      "  Batch 800/938 - Training loss: 1.5826 - Average Test loss: 1.5017\n",
      "  Batch 900/938 - Training loss: 1.2766 - Average Test loss: 1.3319\n",
      "Epoch = 1\n",
      "  Batch 0/938 - Training loss: 1.2269 - Average Test loss: 1.2689\n",
      "  Batch 100/938 - Training loss: 1.2707 - Average Test loss: 1.1362\n",
      "  Batch 200/938 - Training loss: 0.9919 - Average Test loss: 1.0284\n",
      "  Batch 300/938 - Training loss: 0.9771 - Average Test loss: 0.9373\n",
      "  Batch 400/938 - Training loss: 0.8157 - Average Test loss: 0.8656\n",
      "  Batch 500/938 - Training loss: 1.0131 - Average Test loss: 0.8078\n",
      "  Batch 600/938 - Training loss: 0.6743 - Average Test loss: 0.7541\n",
      "  Batch 700/938 - Training loss: 0.9333 - Average Test loss: 0.7095\n",
      "  Batch 800/938 - Training loss: 0.7022 - Average Test loss: 0.6701\n",
      "  Batch 900/938 - Training loss: 0.5903 - Average Test loss: 0.6378\n",
      "Epoch = 2\n",
      "  Batch 0/938 - Training loss: 0.6343 - Average Test loss: 0.6295\n",
      "  Batch 100/938 - Training loss: 0.7803 - Average Test loss: 0.6077\n",
      "  Batch 200/938 - Training loss: 0.6497 - Average Test loss: 0.5769\n",
      "  Batch 300/938 - Training loss: 0.6504 - Average Test loss: 0.5583\n",
      "  Batch 400/938 - Training loss: 0.4408 - Average Test loss: 0.5403\n",
      "  Batch 500/938 - Training loss: 0.5232 - Average Test loss: 0.5281\n",
      "  Batch 600/938 - Training loss: 0.6877 - Average Test loss: 0.5095\n",
      "  Batch 700/938 - Training loss: 0.3479 - Average Test loss: 0.4958\n",
      "  Batch 800/938 - Training loss: 0.3878 - Average Test loss: 0.4843\n",
      "  Batch 900/938 - Training loss: 0.5046 - Average Test loss: 0.4736\n",
      "Epoch = 3\n",
      "  Batch 0/938 - Training loss: 0.4726 - Average Test loss: 0.4694\n",
      "  Batch 100/938 - Training loss: 0.4951 - Average Test loss: 0.4586\n",
      "  Batch 200/938 - Training loss: 0.4920 - Average Test loss: 0.4494\n",
      "  Batch 300/938 - Training loss: 0.5428 - Average Test loss: 0.4438\n",
      "  Batch 400/938 - Training loss: 0.4111 - Average Test loss: 0.4357\n",
      "  Batch 500/938 - Training loss: 0.3683 - Average Test loss: 0.4302\n",
      "  Batch 600/938 - Training loss: 0.2859 - Average Test loss: 0.4201\n",
      "  Batch 700/938 - Training loss: 0.5457 - Average Test loss: 0.4160\n",
      "  Batch 800/938 - Training loss: 0.5688 - Average Test loss: 0.4107\n",
      "  Batch 900/938 - Training loss: 0.4464 - Average Test loss: 0.4054\n",
      "Epoch = 4\n",
      "  Batch 0/938 - Training loss: 0.4626 - Average Test loss: 0.4013\n",
      "  Batch 100/938 - Training loss: 0.4237 - Average Test loss: 0.3989\n",
      "  Batch 200/938 - Training loss: 0.3872 - Average Test loss: 0.3934\n",
      "  Batch 300/938 - Training loss: 0.4339 - Average Test loss: 0.3889\n",
      "  Batch 400/938 - Training loss: 0.4236 - Average Test loss: 0.3858\n",
      "  Batch 500/938 - Training loss: 0.3541 - Average Test loss: 0.3823\n",
      "  Batch 600/938 - Training loss: 0.3461 - Average Test loss: 0.3779\n",
      "  Batch 700/938 - Training loss: 0.3160 - Average Test loss: 0.3729\n",
      "  Batch 800/938 - Training loss: 0.5522 - Average Test loss: 0.3697\n",
      "  Batch 900/938 - Training loss: 0.3856 - Average Test loss: 0.3690\n",
      "Epoch = 5\n",
      "  Batch 0/938 - Training loss: 0.4169 - Average Test loss: 0.3653\n",
      "  Batch 100/938 - Training loss: 0.3550 - Average Test loss: 0.3620\n",
      "  Batch 200/938 - Training loss: 0.4470 - Average Test loss: 0.3636\n",
      "  Batch 300/938 - Training loss: 0.3177 - Average Test loss: 0.3579\n",
      "  Batch 400/938 - Training loss: 0.4931 - Average Test loss: 0.3567\n",
      "  Batch 500/938 - Training loss: 0.3225 - Average Test loss: 0.3538\n",
      "  Batch 600/938 - Training loss: 0.5457 - Average Test loss: 0.3513\n",
      "  Batch 700/938 - Training loss: 0.4260 - Average Test loss: 0.3470\n",
      "  Batch 800/938 - Training loss: 0.3044 - Average Test loss: 0.3458\n",
      "  Batch 900/938 - Training loss: 0.3441 - Average Test loss: 0.3441\n",
      "Epoch = 6\n",
      "  Batch 0/938 - Training loss: 0.4568 - Average Test loss: 0.3441\n",
      "  Batch 100/938 - Training loss: 0.4328 - Average Test loss: 0.3411\n",
      "  Batch 200/938 - Training loss: 0.2944 - Average Test loss: 0.3396\n",
      "  Batch 300/938 - Training loss: 0.4192 - Average Test loss: 0.3383\n",
      "  Batch 400/938 - Training loss: 0.3082 - Average Test loss: 0.3383\n",
      "  Batch 500/938 - Training loss: 0.1502 - Average Test loss: 0.3348\n",
      "  Batch 600/938 - Training loss: 0.2966 - Average Test loss: 0.3329\n",
      "  Batch 700/938 - Training loss: 0.3624 - Average Test loss: 0.3339\n",
      "  Batch 800/938 - Training loss: 0.3649 - Average Test loss: 0.3319\n",
      "  Batch 900/938 - Training loss: 0.2482 - Average Test loss: 0.3289\n",
      "Epoch = 7\n",
      "  Batch 0/938 - Training loss: 0.4111 - Average Test loss: 0.3284\n",
      "  Batch 100/938 - Training loss: 0.3564 - Average Test loss: 0.3281\n",
      "  Batch 200/938 - Training loss: 0.3800 - Average Test loss: 0.3257\n",
      "  Batch 300/938 - Training loss: 0.3214 - Average Test loss: 0.3237\n",
      "  Batch 400/938 - Training loss: 0.1981 - Average Test loss: 0.3225\n",
      "  Batch 500/938 - Training loss: 0.3867 - Average Test loss: 0.3227\n",
      "  Batch 600/938 - Training loss: 0.3127 - Average Test loss: 0.3222\n",
      "  Batch 700/938 - Training loss: 0.3262 - Average Test loss: 0.3186\n",
      "  Batch 800/938 - Training loss: 0.2569 - Average Test loss: 0.3182\n",
      "  Batch 900/938 - Training loss: 0.3083 - Average Test loss: 0.3171\n",
      "Epoch = 8\n",
      "  Batch 0/938 - Training loss: 0.1983 - Average Test loss: 0.3157\n",
      "  Batch 100/938 - Training loss: 0.3802 - Average Test loss: 0.3162\n",
      "  Batch 200/938 - Training loss: 0.2085 - Average Test loss: 0.3152\n",
      "  Batch 300/938 - Training loss: 0.4147 - Average Test loss: 0.3147\n",
      "  Batch 400/938 - Training loss: 0.2477 - Average Test loss: 0.3121\n",
      "  Batch 500/938 - Training loss: 0.2960 - Average Test loss: 0.3120\n",
      "  Batch 600/938 - Training loss: 0.1922 - Average Test loss: 0.3118\n",
      "  Batch 700/938 - Training loss: 0.2697 - Average Test loss: 0.3087\n",
      "  Batch 800/938 - Training loss: 0.4555 - Average Test loss: 0.3075\n",
      "  Batch 900/938 - Training loss: 0.3061 - Average Test loss: 0.3085\n",
      "Epoch = 9\n",
      "  Batch 0/938 - Training loss: 0.4308 - Average Test loss: 0.3087\n",
      "  Batch 100/938 - Training loss: 0.2015 - Average Test loss: 0.3081\n",
      "  Batch 200/938 - Training loss: 0.3422 - Average Test loss: 0.3073\n",
      "  Batch 300/938 - Training loss: 0.5119 - Average Test loss: 0.3056\n",
      "  Batch 400/938 - Training loss: 0.4071 - Average Test loss: 0.3049\n",
      "  Batch 500/938 - Training loss: 0.2894 - Average Test loss: 0.3037\n",
      "  Batch 600/938 - Training loss: 0.2953 - Average Test loss: 0.3043\n",
      "  Batch 700/938 - Training loss: 0.0923 - Average Test loss: 0.3009\n",
      "  Batch 800/938 - Training loss: 0.2793 - Average Test loss: 0.3016\n",
      "  Batch 900/938 - Training loss: 0.1329 - Average Test loss: 0.3006\n",
      "Epoch = 10\n",
      "  Batch 0/938 - Training loss: 0.4052 - Average Test loss: 0.3032\n",
      "  Batch 100/938 - Training loss: 0.2866 - Average Test loss: 0.2993\n",
      "  Batch 200/938 - Training loss: 0.4439 - Average Test loss: 0.2993\n",
      "  Batch 300/938 - Training loss: 0.5251 - Average Test loss: 0.2987\n",
      "  Batch 400/938 - Training loss: 0.2665 - Average Test loss: 0.2979\n",
      "  Batch 500/938 - Training loss: 0.1972 - Average Test loss: 0.2958\n",
      "  Batch 600/938 - Training loss: 0.2409 - Average Test loss: 0.2967\n",
      "  Batch 700/938 - Training loss: 0.3295 - Average Test loss: 0.2952\n",
      "  Batch 800/938 - Training loss: 0.4159 - Average Test loss: 0.2953\n",
      "  Batch 900/938 - Training loss: 0.2439 - Average Test loss: 0.2944\n",
      "Epoch = 11\n",
      "  Batch 0/938 - Training loss: 0.4994 - Average Test loss: 0.2953\n",
      "  Batch 100/938 - Training loss: 0.2704 - Average Test loss: 0.2944\n",
      "  Batch 200/938 - Training loss: 0.2973 - Average Test loss: 0.2937\n",
      "  Batch 300/938 - Training loss: 0.2534 - Average Test loss: 0.2919\n",
      "  Batch 400/938 - Training loss: 0.4460 - Average Test loss: 0.2924\n",
      "  Batch 500/938 - Training loss: 0.3355 - Average Test loss: 0.2928\n",
      "  Batch 600/938 - Training loss: 0.2874 - Average Test loss: 0.2908\n",
      "  Batch 700/938 - Training loss: 0.2159 - Average Test loss: 0.2914\n",
      "  Batch 800/938 - Training loss: 0.2610 - Average Test loss: 0.2906\n",
      "  Batch 900/938 - Training loss: 0.2135 - Average Test loss: 0.2879\n",
      "Epoch = 12\n",
      "  Batch 0/938 - Training loss: 0.1985 - Average Test loss: 0.2894\n",
      "  Batch 100/938 - Training loss: 0.2649 - Average Test loss: 0.2913\n",
      "  Batch 200/938 - Training loss: 0.2951 - Average Test loss: 0.2895\n",
      "  Batch 300/938 - Training loss: 0.5286 - Average Test loss: 0.2890\n",
      "  Batch 400/938 - Training loss: 0.2534 - Average Test loss: 0.2857\n",
      "  Batch 500/938 - Training loss: 0.2880 - Average Test loss: 0.2869\n",
      "  Batch 600/938 - Training loss: 0.3975 - Average Test loss: 0.2855\n",
      "  Batch 700/938 - Training loss: 0.1654 - Average Test loss: 0.2857\n",
      "  Batch 800/938 - Training loss: 0.3684 - Average Test loss: 0.2859\n",
      "  Batch 900/938 - Training loss: 0.4263 - Average Test loss: 0.2847\n",
      "Epoch = 13\n",
      "  Batch 0/938 - Training loss: 0.3656 - Average Test loss: 0.2859\n",
      "  Batch 100/938 - Training loss: 0.3240 - Average Test loss: 0.2830\n",
      "  Batch 200/938 - Training loss: 0.3849 - Average Test loss: 0.2837\n",
      "  Batch 300/938 - Training loss: 0.2364 - Average Test loss: 0.2850\n",
      "  Batch 400/938 - Training loss: 0.3447 - Average Test loss: 0.2824\n",
      "  Batch 500/938 - Training loss: 0.2247 - Average Test loss: 0.2825\n",
      "  Batch 600/938 - Training loss: 0.1403 - Average Test loss: 0.2815\n",
      "  Batch 700/938 - Training loss: 0.3762 - Average Test loss: 0.2848\n",
      "  Batch 800/938 - Training loss: 0.2499 - Average Test loss: 0.2822\n",
      "  Batch 900/938 - Training loss: 0.2347 - Average Test loss: 0.2802\n",
      "Epoch = 14\n",
      "  Batch 0/938 - Training loss: 0.2884 - Average Test loss: 0.2820\n",
      "  Batch 100/938 - Training loss: 0.3474 - Average Test loss: 0.2800\n",
      "  Batch 200/938 - Training loss: 0.4975 - Average Test loss: 0.2793\n",
      "  Batch 300/938 - Training loss: 0.2749 - Average Test loss: 0.2795\n",
      "  Batch 400/938 - Training loss: 0.1417 - Average Test loss: 0.2798\n",
      "  Batch 500/938 - Training loss: 0.2214 - Average Test loss: 0.2788\n",
      "  Batch 600/938 - Training loss: 0.5044 - Average Test loss: 0.2790\n",
      "  Batch 700/938 - Training loss: 0.3964 - Average Test loss: 0.2777\n",
      "  Batch 800/938 - Training loss: 0.2899 - Average Test loss: 0.2775\n",
      "  Batch 900/938 - Training loss: 0.3145 - Average Test loss: 0.2780\n",
      "Epoch = 15\n",
      "  Batch 0/938 - Training loss: 0.2231 - Average Test loss: 0.2776\n",
      "  Batch 100/938 - Training loss: 0.3592 - Average Test loss: 0.2779\n",
      "  Batch 200/938 - Training loss: 0.3464 - Average Test loss: 0.2751\n",
      "  Batch 300/938 - Training loss: 0.2907 - Average Test loss: 0.2758\n",
      "  Batch 400/938 - Training loss: 0.1319 - Average Test loss: 0.2744\n",
      "  Batch 500/938 - Training loss: 0.2255 - Average Test loss: 0.2764\n",
      "  Batch 600/938 - Training loss: 0.1890 - Average Test loss: 0.2754\n",
      "  Batch 700/938 - Training loss: 0.1600 - Average Test loss: 0.2745\n",
      "  Batch 800/938 - Training loss: 0.3407 - Average Test loss: 0.2748\n",
      "  Batch 900/938 - Training loss: 0.1825 - Average Test loss: 0.2749\n",
      "Epoch = 16\n",
      "  Batch 0/938 - Training loss: 0.2842 - Average Test loss: 0.2729\n",
      "  Batch 100/938 - Training loss: 0.1446 - Average Test loss: 0.2725\n",
      "  Batch 200/938 - Training loss: 0.4233 - Average Test loss: 0.2726\n",
      "  Batch 300/938 - Training loss: 0.5196 - Average Test loss: 0.2710\n",
      "  Batch 400/938 - Training loss: 0.2434 - Average Test loss: 0.2720\n",
      "  Batch 500/938 - Training loss: 0.2080 - Average Test loss: 0.2719\n",
      "  Batch 600/938 - Training loss: 0.2160 - Average Test loss: 0.2699\n",
      "  Batch 700/938 - Training loss: 0.2257 - Average Test loss: 0.2724\n",
      "  Batch 800/938 - Training loss: 0.2313 - Average Test loss: 0.2697\n",
      "  Batch 900/938 - Training loss: 0.2337 - Average Test loss: 0.2697\n",
      "Epoch = 17\n",
      "  Batch 0/938 - Training loss: 0.1358 - Average Test loss: 0.2684\n",
      "  Batch 100/938 - Training loss: 0.2020 - Average Test loss: 0.2704\n",
      "  Batch 200/938 - Training loss: 0.4675 - Average Test loss: 0.2686\n",
      "  Batch 300/938 - Training loss: 0.2878 - Average Test loss: 0.2683\n",
      "  Batch 400/938 - Training loss: 0.1778 - Average Test loss: 0.2665\n",
      "  Batch 500/938 - Training loss: 0.4371 - Average Test loss: 0.2670\n",
      "  Batch 600/938 - Training loss: 0.1384 - Average Test loss: 0.2669\n",
      "  Batch 700/938 - Training loss: 0.3226 - Average Test loss: 0.2670\n",
      "  Batch 800/938 - Training loss: 0.1599 - Average Test loss: 0.2683\n",
      "  Batch 900/938 - Training loss: 0.1824 - Average Test loss: 0.2670\n",
      "Epoch = 18\n",
      "  Batch 0/938 - Training loss: 0.3243 - Average Test loss: 0.2663\n",
      "  Batch 100/938 - Training loss: 0.2482 - Average Test loss: 0.2663\n",
      "  Batch 200/938 - Training loss: 0.2881 - Average Test loss: 0.2648\n",
      "  Batch 300/938 - Training loss: 0.3493 - Average Test loss: 0.2656\n",
      "  Batch 400/938 - Training loss: 0.1654 - Average Test loss: 0.2652\n",
      "  Batch 500/938 - Training loss: 0.1455 - Average Test loss: 0.2642\n",
      "  Batch 600/938 - Training loss: 0.1264 - Average Test loss: 0.2650\n",
      "  Batch 700/938 - Training loss: 0.1895 - Average Test loss: 0.2639\n",
      "  Batch 800/938 - Training loss: 0.2802 - Average Test loss: 0.2629\n",
      "  Batch 900/938 - Training loss: 0.2601 - Average Test loss: 0.2640\n",
      "Epoch = 19\n",
      "  Batch 0/938 - Training loss: 0.4175 - Average Test loss: 0.2630\n",
      "  Batch 100/938 - Training loss: 0.2510 - Average Test loss: 0.2650\n",
      "  Batch 200/938 - Training loss: 0.2943 - Average Test loss: 0.2629\n",
      "  Batch 300/938 - Training loss: 0.3713 - Average Test loss: 0.2629\n",
      "  Batch 400/938 - Training loss: 0.1906 - Average Test loss: 0.2618\n",
      "  Batch 500/938 - Training loss: 0.2308 - Average Test loss: 0.2613\n",
      "  Batch 600/938 - Training loss: 0.1293 - Average Test loss: 0.2618\n",
      "  Batch 700/938 - Training loss: 0.1617 - Average Test loss: 0.2602\n",
      "  Batch 800/938 - Training loss: 0.3679 - Average Test loss: 0.2602\n",
      "  Batch 900/938 - Training loss: 0.1694 - Average Test loss: 0.2600\n",
      "Epoch = 20\n",
      "  Batch 0/938 - Training loss: 0.2242 - Average Test loss: 0.2590\n",
      "  Batch 100/938 - Training loss: 0.3005 - Average Test loss: 0.2588\n",
      "  Batch 200/938 - Training loss: 0.1675 - Average Test loss: 0.2590\n",
      "  Batch 300/938 - Training loss: 0.4419 - Average Test loss: 0.2598\n",
      "  Batch 400/938 - Training loss: 0.2329 - Average Test loss: 0.2590\n",
      "  Batch 500/938 - Training loss: 0.3765 - Average Test loss: 0.2585\n",
      "  Batch 600/938 - Training loss: 0.2498 - Average Test loss: 0.2589\n",
      "  Batch 700/938 - Training loss: 0.5589 - Average Test loss: 0.2588\n",
      "  Batch 800/938 - Training loss: 0.3376 - Average Test loss: 0.2563\n",
      "  Batch 900/938 - Training loss: 0.2825 - Average Test loss: 0.2572\n",
      "Epoch = 21\n",
      "  Batch 0/938 - Training loss: 0.1936 - Average Test loss: 0.2565\n",
      "  Batch 100/938 - Training loss: 0.2619 - Average Test loss: 0.2569\n",
      "  Batch 200/938 - Training loss: 0.2357 - Average Test loss: 0.2570\n",
      "  Batch 300/938 - Training loss: 0.3555 - Average Test loss: 0.2554\n",
      "  Batch 400/938 - Training loss: 0.2643 - Average Test loss: 0.2569\n",
      "  Batch 500/938 - Training loss: 0.1887 - Average Test loss: 0.2557\n",
      "  Batch 600/938 - Training loss: 0.3122 - Average Test loss: 0.2540\n",
      "  Batch 700/938 - Training loss: 0.1783 - Average Test loss: 0.2547\n",
      "  Batch 800/938 - Training loss: 0.0792 - Average Test loss: 0.2552\n",
      "  Batch 900/938 - Training loss: 0.2879 - Average Test loss: 0.2544\n",
      "Epoch = 22\n",
      "  Batch 0/938 - Training loss: 0.3427 - Average Test loss: 0.2546\n",
      "  Batch 100/938 - Training loss: 0.2511 - Average Test loss: 0.2519\n",
      "  Batch 200/938 - Training loss: 0.2483 - Average Test loss: 0.2540\n",
      "  Batch 300/938 - Training loss: 0.1388 - Average Test loss: 0.2528\n",
      "  Batch 400/938 - Training loss: 0.5081 - Average Test loss: 0.2513\n",
      "  Batch 500/938 - Training loss: 0.4350 - Average Test loss: 0.2523\n",
      "  Batch 600/938 - Training loss: 0.4101 - Average Test loss: 0.2522\n",
      "  Batch 700/938 - Training loss: 0.1154 - Average Test loss: 0.2520\n",
      "  Batch 800/938 - Training loss: 0.4588 - Average Test loss: 0.2527\n",
      "  Batch 900/938 - Training loss: 0.1515 - Average Test loss: 0.2501\n",
      "Epoch = 23\n",
      "  Batch 0/938 - Training loss: 0.1822 - Average Test loss: 0.2503\n",
      "  Batch 100/938 - Training loss: 0.2586 - Average Test loss: 0.2500\n",
      "  Batch 200/938 - Training loss: 0.1064 - Average Test loss: 0.2531\n",
      "  Batch 300/938 - Training loss: 0.1483 - Average Test loss: 0.2505\n",
      "  Batch 400/938 - Training loss: 0.2161 - Average Test loss: 0.2481\n",
      "  Batch 500/938 - Training loss: 0.1322 - Average Test loss: 0.2486\n",
      "  Batch 600/938 - Training loss: 0.1383 - Average Test loss: 0.2492\n",
      "  Batch 700/938 - Training loss: 0.1738 - Average Test loss: 0.2491\n",
      "  Batch 800/938 - Training loss: 0.1601 - Average Test loss: 0.2461\n",
      "  Batch 900/938 - Training loss: 0.2170 - Average Test loss: 0.2478\n",
      "Epoch = 24\n",
      "  Batch 0/938 - Training loss: 0.1716 - Average Test loss: 0.2484\n",
      "  Batch 100/938 - Training loss: 0.2444 - Average Test loss: 0.2455\n",
      "  Batch 200/938 - Training loss: 0.2724 - Average Test loss: 0.2465\n",
      "  Batch 300/938 - Training loss: 0.2804 - Average Test loss: 0.2457\n",
      "  Batch 400/938 - Training loss: 0.2357 - Average Test loss: 0.2452\n",
      "  Batch 500/938 - Training loss: 0.1763 - Average Test loss: 0.2471\n",
      "  Batch 600/938 - Training loss: 0.1590 - Average Test loss: 0.2446\n",
      "  Batch 700/938 - Training loss: 0.2378 - Average Test loss: 0.2448\n",
      "  Batch 800/938 - Training loss: 0.1424 - Average Test loss: 0.2450\n",
      "  Batch 900/938 - Training loss: 0.1697 - Average Test loss: 0.2436\n",
      "Epoch = 25\n",
      "  Batch 0/938 - Training loss: 0.3391 - Average Test loss: 0.2439\n",
      "  Batch 100/938 - Training loss: 0.3366 - Average Test loss: 0.2438\n",
      "  Batch 200/938 - Training loss: 0.2600 - Average Test loss: 0.2423\n",
      "  Batch 300/938 - Training loss: 0.1981 - Average Test loss: 0.2438\n",
      "  Batch 400/938 - Training loss: 0.2766 - Average Test loss: 0.2432\n",
      "  Batch 500/938 - Training loss: 0.1535 - Average Test loss: 0.2435\n",
      "  Batch 600/938 - Training loss: 0.2470 - Average Test loss: 0.2434\n",
      "  Batch 700/938 - Training loss: 0.3633 - Average Test loss: 0.2409\n",
      "  Batch 800/938 - Training loss: 0.3769 - Average Test loss: 0.2406\n",
      "  Batch 900/938 - Training loss: 0.4545 - Average Test loss: 0.2414\n",
      "Epoch = 26\n",
      "  Batch 0/938 - Training loss: 0.1063 - Average Test loss: 0.2394\n",
      "  Batch 100/938 - Training loss: 0.1140 - Average Test loss: 0.2410\n",
      "  Batch 200/938 - Training loss: 0.3000 - Average Test loss: 0.2392\n",
      "  Batch 300/938 - Training loss: 0.2027 - Average Test loss: 0.2388\n",
      "  Batch 400/938 - Training loss: 0.2441 - Average Test loss: 0.2394\n",
      "  Batch 500/938 - Training loss: 0.2817 - Average Test loss: 0.2391\n",
      "  Batch 600/938 - Training loss: 0.4195 - Average Test loss: 0.2377\n",
      "  Batch 700/938 - Training loss: 0.0899 - Average Test loss: 0.2383\n",
      "  Batch 800/938 - Training loss: 0.2803 - Average Test loss: 0.2380\n",
      "  Batch 900/938 - Training loss: 0.1976 - Average Test loss: 0.2386\n",
      "Epoch = 27\n",
      "  Batch 0/938 - Training loss: 0.1681 - Average Test loss: 0.2377\n",
      "  Batch 100/938 - Training loss: 0.1703 - Average Test loss: 0.2367\n",
      "  Batch 200/938 - Training loss: 0.1946 - Average Test loss: 0.2369\n",
      "  Batch 300/938 - Training loss: 0.3616 - Average Test loss: 0.2359\n",
      "  Batch 400/938 - Training loss: 0.4352 - Average Test loss: 0.2364\n",
      "  Batch 500/938 - Training loss: 0.1830 - Average Test loss: 0.2359\n",
      "  Batch 600/938 - Training loss: 0.2324 - Average Test loss: 0.2355\n",
      "  Batch 700/938 - Training loss: 0.3021 - Average Test loss: 0.2351\n",
      "  Batch 800/938 - Training loss: 0.1405 - Average Test loss: 0.2338\n",
      "  Batch 900/938 - Training loss: 0.2777 - Average Test loss: 0.2343\n",
      "Epoch = 28\n",
      "  Batch 0/938 - Training loss: 0.3164 - Average Test loss: 0.2342\n",
      "  Batch 100/938 - Training loss: 0.2593 - Average Test loss: 0.2341\n",
      "  Batch 200/938 - Training loss: 0.2961 - Average Test loss: 0.2340\n",
      "  Batch 300/938 - Training loss: 0.3132 - Average Test loss: 0.2326\n",
      "  Batch 400/938 - Training loss: 0.2062 - Average Test loss: 0.2331\n",
      "  Batch 500/938 - Training loss: 0.2075 - Average Test loss: 0.2335\n",
      "  Batch 600/938 - Training loss: 0.2542 - Average Test loss: 0.2321\n",
      "  Batch 700/938 - Training loss: 0.2830 - Average Test loss: 0.2326\n",
      "  Batch 800/938 - Training loss: 0.1283 - Average Test loss: 0.2317\n",
      "  Batch 900/938 - Training loss: 0.3472 - Average Test loss: 0.2309\n",
      "Epoch = 29\n",
      "  Batch 0/938 - Training loss: 0.2922 - Average Test loss: 0.2320\n",
      "  Batch 100/938 - Training loss: 0.2433 - Average Test loss: 0.2312\n",
      "  Batch 200/938 - Training loss: 0.1392 - Average Test loss: 0.2305\n",
      "  Batch 300/938 - Training loss: 0.2957 - Average Test loss: 0.2297\n",
      "  Batch 400/938 - Training loss: 0.3051 - Average Test loss: 0.2300\n",
      "  Batch 500/938 - Training loss: 0.3857 - Average Test loss: 0.2293\n",
      "  Batch 600/938 - Training loss: 0.2340 - Average Test loss: 0.2290\n",
      "  Batch 700/938 - Training loss: 0.2443 - Average Test loss: 0.2284\n",
      "  Batch 800/938 - Training loss: 0.0969 - Average Test loss: 0.2282\n",
      "  Batch 900/938 - Training loss: 0.2957 - Average Test loss: 0.2268\n",
      "Epoch = 30\n",
      "  Batch 0/938 - Training loss: 0.1942 - Average Test loss: 0.2282\n",
      "  Batch 100/938 - Training loss: 0.1732 - Average Test loss: 0.2272\n",
      "  Batch 200/938 - Training loss: 0.1654 - Average Test loss: 0.2266\n",
      "  Batch 300/938 - Training loss: 0.1643 - Average Test loss: 0.2263\n",
      "  Batch 400/938 - Training loss: 0.1826 - Average Test loss: 0.2271\n",
      "  Batch 500/938 - Training loss: 0.3035 - Average Test loss: 0.2268\n",
      "  Batch 600/938 - Training loss: 0.0576 - Average Test loss: 0.2248\n",
      "  Batch 700/938 - Training loss: 0.2424 - Average Test loss: 0.2256\n",
      "  Batch 800/938 - Training loss: 0.2237 - Average Test loss: 0.2247\n",
      "  Batch 900/938 - Training loss: 0.2463 - Average Test loss: 0.2242\n",
      "Epoch = 31\n",
      "  Batch 0/938 - Training loss: 0.1125 - Average Test loss: 0.2238\n",
      "  Batch 100/938 - Training loss: 0.3466 - Average Test loss: 0.2247\n",
      "  Batch 200/938 - Training loss: 0.2894 - Average Test loss: 0.2233\n",
      "  Batch 300/938 - Training loss: 0.2179 - Average Test loss: 0.2232\n",
      "  Batch 400/938 - Training loss: 0.2088 - Average Test loss: 0.2216\n",
      "  Batch 500/938 - Training loss: 0.0978 - Average Test loss: 0.2235\n",
      "  Batch 600/938 - Training loss: 0.1560 - Average Test loss: 0.2210\n",
      "  Batch 700/938 - Training loss: 0.5258 - Average Test loss: 0.2214\n",
      "  Batch 800/938 - Training loss: 0.1950 - Average Test loss: 0.2221\n",
      "  Batch 900/938 - Training loss: 0.1940 - Average Test loss: 0.2228\n",
      "Epoch = 32\n",
      "  Batch 0/938 - Training loss: 0.1978 - Average Test loss: 0.2226\n",
      "  Batch 100/938 - Training loss: 0.1438 - Average Test loss: 0.2200\n",
      "  Batch 200/938 - Training loss: 0.1878 - Average Test loss: 0.2212\n",
      "  Batch 300/938 - Training loss: 0.1988 - Average Test loss: 0.2203\n",
      "  Batch 400/938 - Training loss: 0.2516 - Average Test loss: 0.2214\n",
      "  Batch 500/938 - Training loss: 0.3646 - Average Test loss: 0.2197\n",
      "  Batch 600/938 - Training loss: 0.1847 - Average Test loss: 0.2190\n",
      "  Batch 700/938 - Training loss: 0.1234 - Average Test loss: 0.2186\n",
      "  Batch 800/938 - Training loss: 0.2365 - Average Test loss: 0.2206\n",
      "  Batch 900/938 - Training loss: 0.1509 - Average Test loss: 0.2177\n",
      "Epoch = 33\n",
      "  Batch 0/938 - Training loss: 0.3024 - Average Test loss: 0.2184\n",
      "  Batch 100/938 - Training loss: 0.3332 - Average Test loss: 0.2190\n",
      "  Batch 200/938 - Training loss: 0.3128 - Average Test loss: 0.2177\n",
      "  Batch 300/938 - Training loss: 0.2703 - Average Test loss: 0.2171\n",
      "  Batch 400/938 - Training loss: 0.1907 - Average Test loss: 0.2161\n",
      "  Batch 500/938 - Training loss: 0.5404 - Average Test loss: 0.2156\n",
      "  Batch 600/938 - Training loss: 0.2364 - Average Test loss: 0.2160\n",
      "  Batch 700/938 - Training loss: 0.1632 - Average Test loss: 0.2150\n",
      "  Batch 800/938 - Training loss: 0.2254 - Average Test loss: 0.2152\n",
      "  Batch 900/938 - Training loss: 0.1981 - Average Test loss: 0.2151\n",
      "Epoch = 34\n",
      "  Batch 0/938 - Training loss: 0.1406 - Average Test loss: 0.2145\n",
      "  Batch 100/938 - Training loss: 0.2657 - Average Test loss: 0.2155\n",
      "  Batch 200/938 - Training loss: 0.3107 - Average Test loss: 0.2151\n",
      "  Batch 300/938 - Training loss: 0.1723 - Average Test loss: 0.2138\n",
      "  Batch 400/938 - Training loss: 0.2294 - Average Test loss: 0.2140\n",
      "  Batch 500/938 - Training loss: 0.1999 - Average Test loss: 0.2132\n",
      "  Batch 600/938 - Training loss: 0.3163 - Average Test loss: 0.2145\n",
      "  Batch 700/938 - Training loss: 0.2647 - Average Test loss: 0.2140\n",
      "  Batch 800/938 - Training loss: 0.1578 - Average Test loss: 0.2119\n",
      "  Batch 900/938 - Training loss: 0.0889 - Average Test loss: 0.2123\n",
      "Epoch = 35\n",
      "  Batch 0/938 - Training loss: 0.3291 - Average Test loss: 0.2120\n",
      "  Batch 100/938 - Training loss: 0.1755 - Average Test loss: 0.2121\n",
      "  Batch 200/938 - Training loss: 0.3155 - Average Test loss: 0.2113\n",
      "  Batch 300/938 - Training loss: 0.2053 - Average Test loss: 0.2112\n",
      "  Batch 400/938 - Training loss: 0.4914 - Average Test loss: 0.2100\n",
      "  Batch 500/938 - Training loss: 0.2803 - Average Test loss: 0.2099\n",
      "  Batch 600/938 - Training loss: 0.3105 - Average Test loss: 0.2106\n",
      "  Batch 700/938 - Training loss: 0.3795 - Average Test loss: 0.2089\n",
      "  Batch 800/938 - Training loss: 0.1340 - Average Test loss: 0.2091\n",
      "  Batch 900/938 - Training loss: 0.1972 - Average Test loss: 0.2088\n",
      "Epoch = 36\n",
      "  Batch 0/938 - Training loss: 0.2801 - Average Test loss: 0.2089\n",
      "  Batch 100/938 - Training loss: 0.2130 - Average Test loss: 0.2099\n",
      "  Batch 200/938 - Training loss: 0.2423 - Average Test loss: 0.2092\n",
      "  Batch 300/938 - Training loss: 0.4284 - Average Test loss: 0.2093\n",
      "  Batch 400/938 - Training loss: 0.1069 - Average Test loss: 0.2107\n",
      "  Batch 500/938 - Training loss: 0.2360 - Average Test loss: 0.2093\n",
      "  Batch 600/938 - Training loss: 0.3127 - Average Test loss: 0.2060\n",
      "  Batch 700/938 - Training loss: 0.1270 - Average Test loss: 0.2072\n",
      "  Batch 800/938 - Training loss: 0.1253 - Average Test loss: 0.2064\n",
      "  Batch 900/938 - Training loss: 0.2412 - Average Test loss: 0.2074\n",
      "Epoch = 37\n",
      "  Batch 0/938 - Training loss: 0.4157 - Average Test loss: 0.2064\n",
      "  Batch 100/938 - Training loss: 0.1556 - Average Test loss: 0.2060\n",
      "  Batch 200/938 - Training loss: 0.2263 - Average Test loss: 0.2066\n",
      "  Batch 300/938 - Training loss: 0.1732 - Average Test loss: 0.2058\n",
      "  Batch 400/938 - Training loss: 0.3138 - Average Test loss: 0.2058\n",
      "  Batch 500/938 - Training loss: 0.1676 - Average Test loss: 0.2058\n",
      "  Batch 600/938 - Training loss: 0.1875 - Average Test loss: 0.2053\n",
      "  Batch 700/938 - Training loss: 0.1543 - Average Test loss: 0.2050\n",
      "  Batch 800/938 - Training loss: 0.2526 - Average Test loss: 0.2031\n",
      "  Batch 900/938 - Training loss: 0.2654 - Average Test loss: 0.2041\n",
      "Epoch = 38\n",
      "  Batch 0/938 - Training loss: 0.1530 - Average Test loss: 0.2035\n",
      "  Batch 100/938 - Training loss: 0.2556 - Average Test loss: 0.2031\n",
      "  Batch 200/938 - Training loss: 0.1361 - Average Test loss: 0.2032\n",
      "  Batch 300/938 - Training loss: 0.0965 - Average Test loss: 0.2020\n",
      "  Batch 400/938 - Training loss: 0.4576 - Average Test loss: 0.2013\n",
      "  Batch 500/938 - Training loss: 0.1671 - Average Test loss: 0.2021\n",
      "  Batch 600/938 - Training loss: 0.2814 - Average Test loss: 0.2039\n",
      "  Batch 700/938 - Training loss: 0.1567 - Average Test loss: 0.2017\n",
      "  Batch 800/938 - Training loss: 0.3629 - Average Test loss: 0.2013\n",
      "  Batch 900/938 - Training loss: 0.1578 - Average Test loss: 0.2017\n",
      "Epoch = 39\n",
      "  Batch 0/938 - Training loss: 0.1223 - Average Test loss: 0.2005\n",
      "  Batch 100/938 - Training loss: 0.1223 - Average Test loss: 0.2004\n",
      "  Batch 200/938 - Training loss: 0.3161 - Average Test loss: 0.2003\n",
      "  Batch 300/938 - Training loss: 0.2658 - Average Test loss: 0.1997\n",
      "  Batch 400/938 - Training loss: 0.1167 - Average Test loss: 0.2005\n",
      "  Batch 500/938 - Training loss: 0.2119 - Average Test loss: 0.2004\n",
      "  Batch 600/938 - Training loss: 0.2553 - Average Test loss: 0.1988\n",
      "  Batch 700/938 - Training loss: 0.1083 - Average Test loss: 0.1985\n",
      "  Batch 800/938 - Training loss: 0.2119 - Average Test loss: 0.1982\n",
      "  Batch 900/938 - Training loss: 0.2496 - Average Test loss: 0.1971\n",
      "Epoch = 40\n",
      "  Batch 0/938 - Training loss: 0.2674 - Average Test loss: 0.1978\n",
      "  Batch 100/938 - Training loss: 0.3579 - Average Test loss: 0.1982\n",
      "  Batch 200/938 - Training loss: 0.1076 - Average Test loss: 0.1976\n",
      "  Batch 300/938 - Training loss: 0.1567 - Average Test loss: 0.1978\n",
      "  Batch 400/938 - Training loss: 0.1367 - Average Test loss: 0.1979\n",
      "  Batch 500/938 - Training loss: 0.1954 - Average Test loss: 0.1978\n",
      "  Batch 600/938 - Training loss: 0.1819 - Average Test loss: 0.1977\n",
      "  Batch 700/938 - Training loss: 0.2293 - Average Test loss: 0.1958\n",
      "  Batch 800/938 - Training loss: 0.3184 - Average Test loss: 0.1963\n",
      "  Batch 900/938 - Training loss: 0.2400 - Average Test loss: 0.1948\n",
      "Epoch = 41\n",
      "  Batch 0/938 - Training loss: 0.2327 - Average Test loss: 0.1944\n",
      "  Batch 100/938 - Training loss: 0.2717 - Average Test loss: 0.1965\n",
      "  Batch 200/938 - Training loss: 0.1352 - Average Test loss: 0.1947\n",
      "  Batch 300/938 - Training loss: 0.1625 - Average Test loss: 0.1949\n",
      "  Batch 400/938 - Training loss: 0.2452 - Average Test loss: 0.1955\n",
      "  Batch 500/938 - Training loss: 0.1386 - Average Test loss: 0.1945\n",
      "  Batch 600/938 - Training loss: 0.1543 - Average Test loss: 0.1934\n",
      "  Batch 700/938 - Training loss: 0.1236 - Average Test loss: 0.1936\n",
      "  Batch 800/938 - Training loss: 0.1979 - Average Test loss: 0.1934\n",
      "  Batch 900/938 - Training loss: 0.1538 - Average Test loss: 0.1930\n",
      "Epoch = 42\n",
      "  Batch 0/938 - Training loss: 0.1562 - Average Test loss: 0.1936\n",
      "  Batch 100/938 - Training loss: 0.0695 - Average Test loss: 0.1916\n",
      "  Batch 200/938 - Training loss: 0.1356 - Average Test loss: 0.1936\n",
      "  Batch 300/938 - Training loss: 0.1957 - Average Test loss: 0.1914\n",
      "  Batch 400/938 - Training loss: 0.3032 - Average Test loss: 0.1912\n",
      "  Batch 500/938 - Training loss: 0.1422 - Average Test loss: 0.1907\n",
      "  Batch 600/938 - Training loss: 0.2360 - Average Test loss: 0.1926\n",
      "  Batch 700/938 - Training loss: 0.1866 - Average Test loss: 0.1915\n",
      "  Batch 800/938 - Training loss: 0.1546 - Average Test loss: 0.1901\n",
      "  Batch 900/938 - Training loss: 0.2776 - Average Test loss: 0.1910\n",
      "Epoch = 43\n",
      "  Batch 0/938 - Training loss: 0.2955 - Average Test loss: 0.1899\n",
      "  Batch 100/938 - Training loss: 0.1524 - Average Test loss: 0.1893\n",
      "  Batch 200/938 - Training loss: 0.2932 - Average Test loss: 0.1905\n",
      "  Batch 300/938 - Training loss: 0.2640 - Average Test loss: 0.1891\n",
      "  Batch 400/938 - Training loss: 0.1725 - Average Test loss: 0.1896\n",
      "  Batch 500/938 - Training loss: 0.1367 - Average Test loss: 0.1897\n",
      "  Batch 600/938 - Training loss: 0.1781 - Average Test loss: 0.1885\n",
      "  Batch 700/938 - Training loss: 0.1098 - Average Test loss: 0.1882\n",
      "  Batch 800/938 - Training loss: 0.1164 - Average Test loss: 0.1889\n",
      "  Batch 900/938 - Training loss: 0.0869 - Average Test loss: 0.1883\n",
      "Epoch = 44\n",
      "  Batch 0/938 - Training loss: 0.1374 - Average Test loss: 0.1884\n",
      "  Batch 100/938 - Training loss: 0.1892 - Average Test loss: 0.1878\n",
      "  Batch 200/938 - Training loss: 0.2952 - Average Test loss: 0.1872\n",
      "  Batch 300/938 - Training loss: 0.0846 - Average Test loss: 0.1878\n",
      "  Batch 400/938 - Training loss: 0.2301 - Average Test loss: 0.1870\n",
      "  Batch 500/938 - Training loss: 0.1188 - Average Test loss: 0.1854\n",
      "  Batch 600/938 - Training loss: 0.1940 - Average Test loss: 0.1855\n",
      "  Batch 700/938 - Training loss: 0.2413 - Average Test loss: 0.1849\n",
      "  Batch 800/938 - Training loss: 0.0883 - Average Test loss: 0.1851\n",
      "  Batch 900/938 - Training loss: 0.3150 - Average Test loss: 0.1849\n",
      "Epoch = 45\n",
      "  Batch 0/938 - Training loss: 0.1363 - Average Test loss: 0.1846\n",
      "  Batch 100/938 - Training loss: 0.1422 - Average Test loss: 0.1860\n",
      "  Batch 200/938 - Training loss: 0.1252 - Average Test loss: 0.1841\n",
      "  Batch 300/938 - Training loss: 0.2721 - Average Test loss: 0.1852\n",
      "  Batch 400/938 - Training loss: 0.0933 - Average Test loss: 0.1842\n",
      "  Batch 500/938 - Training loss: 0.0686 - Average Test loss: 0.1846\n",
      "  Batch 600/938 - Training loss: 0.0506 - Average Test loss: 0.1831\n",
      "  Batch 700/938 - Training loss: 0.1192 - Average Test loss: 0.1838\n",
      "  Batch 800/938 - Training loss: 0.1078 - Average Test loss: 0.1829\n",
      "  Batch 900/938 - Training loss: 0.1808 - Average Test loss: 0.1839\n",
      "Epoch = 46\n",
      "  Batch 0/938 - Training loss: 0.2361 - Average Test loss: 0.1828\n",
      "  Batch 100/938 - Training loss: 0.0577 - Average Test loss: 0.1822\n",
      "  Batch 200/938 - Training loss: 0.1213 - Average Test loss: 0.1824\n",
      "  Batch 300/938 - Training loss: 0.2953 - Average Test loss: 0.1814\n",
      "  Batch 400/938 - Training loss: 0.1964 - Average Test loss: 0.1818\n",
      "  Batch 500/938 - Training loss: 0.1222 - Average Test loss: 0.1822\n",
      "  Batch 600/938 - Training loss: 0.3373 - Average Test loss: 0.1805\n",
      "  Batch 700/938 - Training loss: 0.2156 - Average Test loss: 0.1811\n",
      "  Batch 800/938 - Training loss: 0.2137 - Average Test loss: 0.1804\n",
      "  Batch 900/938 - Training loss: 0.0783 - Average Test loss: 0.1808\n",
      "Epoch = 47\n",
      "  Batch 0/938 - Training loss: 0.1527 - Average Test loss: 0.1805\n",
      "  Batch 100/938 - Training loss: 0.2145 - Average Test loss: 0.1803\n",
      "  Batch 200/938 - Training loss: 0.3357 - Average Test loss: 0.1812\n",
      "  Batch 300/938 - Training loss: 0.1351 - Average Test loss: 0.1799\n",
      "  Batch 400/938 - Training loss: 0.1758 - Average Test loss: 0.1809\n",
      "  Batch 500/938 - Training loss: 0.2980 - Average Test loss: 0.1789\n",
      "  Batch 600/938 - Training loss: 0.1509 - Average Test loss: 0.1790\n",
      "  Batch 700/938 - Training loss: 0.0947 - Average Test loss: 0.1788\n",
      "  Batch 800/938 - Training loss: 0.1068 - Average Test loss: 0.1792\n",
      "  Batch 900/938 - Training loss: 0.3111 - Average Test loss: 0.1782\n",
      "Epoch = 48\n",
      "  Batch 0/938 - Training loss: 0.2323 - Average Test loss: 0.1781\n",
      "  Batch 100/938 - Training loss: 0.1986 - Average Test loss: 0.1779\n",
      "  Batch 200/938 - Training loss: 0.2998 - Average Test loss: 0.1774\n",
      "  Batch 300/938 - Training loss: 0.3046 - Average Test loss: 0.1795\n",
      "  Batch 400/938 - Training loss: 0.1786 - Average Test loss: 0.1775\n",
      "  Batch 500/938 - Training loss: 0.2232 - Average Test loss: 0.1772\n",
      "  Batch 600/938 - Training loss: 0.1920 - Average Test loss: 0.1776\n",
      "  Batch 700/938 - Training loss: 0.1803 - Average Test loss: 0.1770\n",
      "  Batch 800/938 - Training loss: 0.0717 - Average Test loss: 0.1765\n",
      "  Batch 900/938 - Training loss: 0.2276 - Average Test loss: 0.1760\n",
      "Epoch = 49\n",
      "  Batch 0/938 - Training loss: 0.1544 - Average Test loss: 0.1757\n",
      "  Batch 100/938 - Training loss: 0.1653 - Average Test loss: 0.1790\n",
      "  Batch 200/938 - Training loss: 0.3398 - Average Test loss: 0.1763\n",
      "  Batch 300/938 - Training loss: 0.1816 - Average Test loss: 0.1748\n",
      "  Batch 400/938 - Training loss: 0.0947 - Average Test loss: 0.1749\n",
      "  Batch 500/938 - Training loss: 0.0920 - Average Test loss: 0.1747\n",
      "  Batch 600/938 - Training loss: 0.2366 - Average Test loss: 0.1759\n",
      "  Batch 700/938 - Training loss: 0.1277 - Average Test loss: 0.1737\n",
      "  Batch 800/938 - Training loss: 0.2708 - Average Test loss: 0.1737\n",
      "  Batch 900/938 - Training loss: 0.1243 - Average Test loss: 0.1753\n",
      "Epoch = 50\n",
      "  Batch 0/938 - Training loss: 0.1878 - Average Test loss: 0.1742\n",
      "  Batch 100/938 - Training loss: 0.0794 - Average Test loss: 0.1744\n",
      "  Batch 200/938 - Training loss: 0.0940 - Average Test loss: 0.1739\n",
      "  Batch 300/938 - Training loss: 0.0980 - Average Test loss: 0.1741\n",
      "  Batch 400/938 - Training loss: 0.1159 - Average Test loss: 0.1731\n",
      "  Batch 500/938 - Training loss: 0.1430 - Average Test loss: 0.1728\n",
      "  Batch 600/938 - Training loss: 0.1021 - Average Test loss: 0.1728\n",
      "  Batch 700/938 - Training loss: 0.3098 - Average Test loss: 0.1731\n",
      "  Batch 800/938 - Training loss: 0.1152 - Average Test loss: 0.1722\n",
      "  Batch 900/938 - Training loss: 0.2357 - Average Test loss: 0.1718\n",
      "Epoch = 51\n",
      "  Batch 0/938 - Training loss: 0.2984 - Average Test loss: 0.1724\n",
      "  Batch 100/938 - Training loss: 0.2822 - Average Test loss: 0.1724\n",
      "  Batch 200/938 - Training loss: 0.0839 - Average Test loss: 0.1711\n",
      "  Batch 300/938 - Training loss: 0.2749 - Average Test loss: 0.1717\n",
      "  Batch 400/938 - Training loss: 0.1306 - Average Test loss: 0.1709\n",
      "  Batch 500/938 - Training loss: 0.3508 - Average Test loss: 0.1716\n",
      "  Batch 600/938 - Training loss: 0.1232 - Average Test loss: 0.1702\n",
      "  Batch 700/938 - Training loss: 0.2169 - Average Test loss: 0.1698\n",
      "  Batch 800/938 - Training loss: 0.1818 - Average Test loss: 0.1708\n",
      "  Batch 900/938 - Training loss: 0.1669 - Average Test loss: 0.1710\n",
      "Epoch = 52\n",
      "  Batch 0/938 - Training loss: 0.1043 - Average Test loss: 0.1712\n",
      "  Batch 100/938 - Training loss: 0.2968 - Average Test loss: 0.1691\n",
      "  Batch 200/938 - Training loss: 0.1772 - Average Test loss: 0.1695\n",
      "  Batch 300/938 - Training loss: 0.1330 - Average Test loss: 0.1689\n",
      "  Batch 400/938 - Training loss: 0.2032 - Average Test loss: 0.1688\n",
      "  Batch 500/938 - Training loss: 0.1894 - Average Test loss: 0.1684\n",
      "  Batch 600/938 - Training loss: 0.0890 - Average Test loss: 0.1676\n",
      "  Batch 700/938 - Training loss: 0.2308 - Average Test loss: 0.1687\n",
      "  Batch 800/938 - Training loss: 0.0900 - Average Test loss: 0.1679\n",
      "  Batch 900/938 - Training loss: 0.2069 - Average Test loss: 0.1691\n",
      "Epoch = 53\n",
      "  Batch 0/938 - Training loss: 0.2597 - Average Test loss: 0.1681\n",
      "  Batch 100/938 - Training loss: 0.1081 - Average Test loss: 0.1671\n",
      "  Batch 200/938 - Training loss: 0.0992 - Average Test loss: 0.1671\n",
      "  Batch 300/938 - Training loss: 0.4420 - Average Test loss: 0.1672\n",
      "  Batch 400/938 - Training loss: 0.0524 - Average Test loss: 0.1672\n",
      "  Batch 500/938 - Training loss: 0.0825 - Average Test loss: 0.1663\n",
      "  Batch 600/938 - Training loss: 0.1528 - Average Test loss: 0.1667\n",
      "  Batch 700/938 - Training loss: 0.1735 - Average Test loss: 0.1659\n",
      "  Batch 800/938 - Training loss: 0.2162 - Average Test loss: 0.1667\n",
      "  Batch 900/938 - Training loss: 0.2293 - Average Test loss: 0.1653\n",
      "Epoch = 54\n",
      "  Batch 0/938 - Training loss: 0.1850 - Average Test loss: 0.1663\n",
      "  Batch 100/938 - Training loss: 0.1607 - Average Test loss: 0.1652\n",
      "  Batch 200/938 - Training loss: 0.2045 - Average Test loss: 0.1657\n",
      "  Batch 300/938 - Training loss: 0.2630 - Average Test loss: 0.1662\n",
      "  Batch 400/938 - Training loss: 0.1691 - Average Test loss: 0.1648\n",
      "  Batch 500/938 - Training loss: 0.1352 - Average Test loss: 0.1653\n",
      "  Batch 600/938 - Training loss: 0.2452 - Average Test loss: 0.1649\n",
      "  Batch 700/938 - Training loss: 0.0888 - Average Test loss: 0.1647\n",
      "  Batch 800/938 - Training loss: 0.1423 - Average Test loss: 0.1647\n",
      "  Batch 900/938 - Training loss: 0.1768 - Average Test loss: 0.1639\n",
      "Epoch = 55\n",
      "  Batch 0/938 - Training loss: 0.1294 - Average Test loss: 0.1640\n",
      "  Batch 100/938 - Training loss: 0.1912 - Average Test loss: 0.1637\n",
      "  Batch 200/938 - Training loss: 0.1227 - Average Test loss: 0.1639\n",
      "  Batch 300/938 - Training loss: 0.2524 - Average Test loss: 0.1631\n",
      "  Batch 400/938 - Training loss: 0.2569 - Average Test loss: 0.1630\n",
      "  Batch 500/938 - Training loss: 0.1807 - Average Test loss: 0.1631\n",
      "  Batch 600/938 - Training loss: 0.0983 - Average Test loss: 0.1635\n",
      "  Batch 700/938 - Training loss: 0.1774 - Average Test loss: 0.1617\n",
      "  Batch 800/938 - Training loss: 0.1694 - Average Test loss: 0.1621\n",
      "  Batch 900/938 - Training loss: 0.1457 - Average Test loss: 0.1630\n",
      "Epoch = 56\n",
      "  Batch 0/938 - Training loss: 0.1881 - Average Test loss: 0.1625\n",
      "  Batch 100/938 - Training loss: 0.2405 - Average Test loss: 0.1627\n",
      "  Batch 200/938 - Training loss: 0.0931 - Average Test loss: 0.1618\n",
      "  Batch 300/938 - Training loss: 0.1163 - Average Test loss: 0.1629\n",
      "  Batch 400/938 - Training loss: 0.1669 - Average Test loss: 0.1617\n",
      "  Batch 500/938 - Training loss: 0.2146 - Average Test loss: 0.1618\n",
      "  Batch 600/938 - Training loss: 0.2649 - Average Test loss: 0.1611\n",
      "  Batch 700/938 - Training loss: 0.2935 - Average Test loss: 0.1602\n",
      "  Batch 800/938 - Training loss: 0.1588 - Average Test loss: 0.1604\n",
      "  Batch 900/938 - Training loss: 0.1528 - Average Test loss: 0.1615\n",
      "Epoch = 57\n",
      "  Batch 0/938 - Training loss: 0.0769 - Average Test loss: 0.1610\n",
      "  Batch 100/938 - Training loss: 0.1364 - Average Test loss: 0.1612\n",
      "  Batch 200/938 - Training loss: 0.1970 - Average Test loss: 0.1598\n",
      "  Batch 300/938 - Training loss: 0.1873 - Average Test loss: 0.1603\n",
      "  Batch 400/938 - Training loss: 0.1326 - Average Test loss: 0.1602\n",
      "  Batch 500/938 - Training loss: 0.0725 - Average Test loss: 0.1592\n",
      "  Batch 600/938 - Training loss: 0.1026 - Average Test loss: 0.1591\n",
      "  Batch 700/938 - Training loss: 0.0916 - Average Test loss: 0.1581\n",
      "  Batch 800/938 - Training loss: 0.2521 - Average Test loss: 0.1581\n",
      "  Batch 900/938 - Training loss: 0.0601 - Average Test loss: 0.1592\n",
      "Epoch = 58\n",
      "  Batch 0/938 - Training loss: 0.1173 - Average Test loss: 0.1582\n",
      "  Batch 100/938 - Training loss: 0.0579 - Average Test loss: 0.1578\n",
      "  Batch 200/938 - Training loss: 0.0917 - Average Test loss: 0.1586\n",
      "  Batch 300/938 - Training loss: 0.0852 - Average Test loss: 0.1581\n",
      "  Batch 400/938 - Training loss: 0.0622 - Average Test loss: 0.1576\n",
      "  Batch 500/938 - Training loss: 0.1348 - Average Test loss: 0.1574\n",
      "  Batch 600/938 - Training loss: 0.1466 - Average Test loss: 0.1568\n",
      "  Batch 700/938 - Training loss: 0.2064 - Average Test loss: 0.1569\n",
      "  Batch 800/938 - Training loss: 0.2870 - Average Test loss: 0.1575\n",
      "  Batch 900/938 - Training loss: 0.1273 - Average Test loss: 0.1572\n",
      "Epoch = 59\n",
      "  Batch 0/938 - Training loss: 0.1555 - Average Test loss: 0.1586\n",
      "  Batch 100/938 - Training loss: 0.1291 - Average Test loss: 0.1561\n",
      "  Batch 200/938 - Training loss: 0.2573 - Average Test loss: 0.1560\n",
      "  Batch 300/938 - Training loss: 0.1356 - Average Test loss: 0.1562\n",
      "  Batch 400/938 - Training loss: 0.1430 - Average Test loss: 0.1558\n",
      "  Batch 500/938 - Training loss: 0.1560 - Average Test loss: 0.1560\n",
      "  Batch 600/938 - Training loss: 0.1332 - Average Test loss: 0.1552\n",
      "  Batch 700/938 - Training loss: 0.1341 - Average Test loss: 0.1553\n",
      "  Batch 800/938 - Training loss: 0.1933 - Average Test loss: 0.1567\n",
      "  Batch 900/938 - Training loss: 0.1074 - Average Test loss: 0.1559\n",
      "Epoch = 60\n",
      "  Batch 0/938 - Training loss: 0.1167 - Average Test loss: 0.1557\n",
      "  Batch 100/938 - Training loss: 0.2460 - Average Test loss: 0.1550\n",
      "  Batch 200/938 - Training loss: 0.0739 - Average Test loss: 0.1544\n",
      "  Batch 300/938 - Training loss: 0.1419 - Average Test loss: 0.1543\n",
      "  Batch 400/938 - Training loss: 0.0765 - Average Test loss: 0.1543\n",
      "  Batch 500/938 - Training loss: 0.1495 - Average Test loss: 0.1550\n",
      "  Batch 600/938 - Training loss: 0.2730 - Average Test loss: 0.1541\n",
      "  Batch 700/938 - Training loss: 0.2192 - Average Test loss: 0.1542\n",
      "  Batch 800/938 - Training loss: 0.1556 - Average Test loss: 0.1535\n",
      "  Batch 900/938 - Training loss: 0.0846 - Average Test loss: 0.1533\n",
      "Epoch = 61\n",
      "  Batch 0/938 - Training loss: 0.0743 - Average Test loss: 0.1541\n",
      "  Batch 100/938 - Training loss: 0.1298 - Average Test loss: 0.1531\n",
      "  Batch 200/938 - Training loss: 0.1417 - Average Test loss: 0.1528\n",
      "  Batch 300/938 - Training loss: 0.1830 - Average Test loss: 0.1535\n",
      "  Batch 400/938 - Training loss: 0.0389 - Average Test loss: 0.1525\n",
      "  Batch 500/938 - Training loss: 0.1804 - Average Test loss: 0.1529\n",
      "  Batch 600/938 - Training loss: 0.0735 - Average Test loss: 0.1531\n",
      "  Batch 700/938 - Training loss: 0.1523 - Average Test loss: 0.1533\n",
      "  Batch 800/938 - Training loss: 0.1172 - Average Test loss: 0.1533\n",
      "  Batch 900/938 - Training loss: 0.1395 - Average Test loss: 0.1524\n",
      "Epoch = 62\n",
      "  Batch 0/938 - Training loss: 0.0984 - Average Test loss: 0.1512\n",
      "  Batch 100/938 - Training loss: 0.1090 - Average Test loss: 0.1516\n",
      "  Batch 200/938 - Training loss: 0.0855 - Average Test loss: 0.1516\n",
      "  Batch 300/938 - Training loss: 0.1237 - Average Test loss: 0.1519\n",
      "  Batch 400/938 - Training loss: 0.2726 - Average Test loss: 0.1513\n",
      "  Batch 500/938 - Training loss: 0.0672 - Average Test loss: 0.1512\n",
      "  Batch 600/938 - Training loss: 0.1758 - Average Test loss: 0.1506\n",
      "  Batch 700/938 - Training loss: 0.0566 - Average Test loss: 0.1511\n",
      "  Batch 800/938 - Training loss: 0.1429 - Average Test loss: 0.1507\n",
      "  Batch 900/938 - Training loss: 0.1278 - Average Test loss: 0.1505\n",
      "Epoch = 63\n",
      "  Batch 0/938 - Training loss: 0.1726 - Average Test loss: 0.1507\n",
      "  Batch 100/938 - Training loss: 0.2560 - Average Test loss: 0.1499\n",
      "  Batch 200/938 - Training loss: 0.1100 - Average Test loss: 0.1494\n",
      "  Batch 300/938 - Training loss: 0.1794 - Average Test loss: 0.1496\n",
      "  Batch 400/938 - Training loss: 0.1558 - Average Test loss: 0.1496\n",
      "  Batch 500/938 - Training loss: 0.1728 - Average Test loss: 0.1492\n",
      "  Batch 600/938 - Training loss: 0.2443 - Average Test loss: 0.1491\n",
      "  Batch 700/938 - Training loss: 0.1890 - Average Test loss: 0.1488\n",
      "  Batch 800/938 - Training loss: 0.1358 - Average Test loss: 0.1496\n",
      "  Batch 900/938 - Training loss: 0.0783 - Average Test loss: 0.1496\n",
      "Epoch = 64\n",
      "  Batch 0/938 - Training loss: 0.1424 - Average Test loss: 0.1492\n",
      "  Batch 100/938 - Training loss: 0.1813 - Average Test loss: 0.1491\n",
      "  Batch 200/938 - Training loss: 0.1555 - Average Test loss: 0.1482\n",
      "  Batch 300/938 - Training loss: 0.1006 - Average Test loss: 0.1479\n",
      "  Batch 400/938 - Training loss: 0.2937 - Average Test loss: 0.1485\n",
      "  Batch 500/938 - Training loss: 0.1378 - Average Test loss: 0.1478\n",
      "  Batch 600/938 - Training loss: 0.0610 - Average Test loss: 0.1488\n",
      "  Batch 700/938 - Training loss: 0.1603 - Average Test loss: 0.1484\n",
      "  Batch 800/938 - Training loss: 0.1506 - Average Test loss: 0.1476\n",
      "  Batch 900/938 - Training loss: 0.2474 - Average Test loss: 0.1470\n",
      "Epoch = 65\n",
      "  Batch 0/938 - Training loss: 0.2132 - Average Test loss: 0.1472\n",
      "  Batch 100/938 - Training loss: 0.1064 - Average Test loss: 0.1467\n",
      "  Batch 200/938 - Training loss: 0.1878 - Average Test loss: 0.1470\n",
      "  Batch 300/938 - Training loss: 0.1116 - Average Test loss: 0.1466\n",
      "  Batch 400/938 - Training loss: 0.1595 - Average Test loss: 0.1468\n",
      "  Batch 500/938 - Training loss: 0.2833 - Average Test loss: 0.1463\n",
      "  Batch 600/938 - Training loss: 0.1259 - Average Test loss: 0.1462\n",
      "  Batch 700/938 - Training loss: 0.2256 - Average Test loss: 0.1462\n",
      "  Batch 800/938 - Training loss: 0.0418 - Average Test loss: 0.1461\n",
      "  Batch 900/938 - Training loss: 0.0450 - Average Test loss: 0.1465\n",
      "Epoch = 66\n",
      "  Batch 0/938 - Training loss: 0.2846 - Average Test loss: 0.1460\n",
      "  Batch 100/938 - Training loss: 0.2858 - Average Test loss: 0.1463\n",
      "  Batch 200/938 - Training loss: 0.0606 - Average Test loss: 0.1460\n",
      "  Batch 300/938 - Training loss: 0.1410 - Average Test loss: 0.1449\n",
      "  Batch 400/938 - Training loss: 0.1124 - Average Test loss: 0.1449\n",
      "  Batch 500/938 - Training loss: 0.1292 - Average Test loss: 0.1445\n",
      "  Batch 600/938 - Training loss: 0.1878 - Average Test loss: 0.1455\n",
      "  Batch 700/938 - Training loss: 0.0835 - Average Test loss: 0.1456\n",
      "  Batch 800/938 - Training loss: 0.0399 - Average Test loss: 0.1456\n",
      "  Batch 900/938 - Training loss: 0.1727 - Average Test loss: 0.1448\n",
      "Epoch = 67\n",
      "  Batch 0/938 - Training loss: 0.2409 - Average Test loss: 0.1441\n",
      "  Batch 100/938 - Training loss: 0.0417 - Average Test loss: 0.1442\n",
      "  Batch 200/938 - Training loss: 0.1192 - Average Test loss: 0.1439\n",
      "  Batch 300/938 - Training loss: 0.2760 - Average Test loss: 0.1440\n",
      "  Batch 400/938 - Training loss: 0.1424 - Average Test loss: 0.1448\n",
      "  Batch 500/938 - Training loss: 0.1451 - Average Test loss: 0.1434\n",
      "  Batch 600/938 - Training loss: 0.1800 - Average Test loss: 0.1440\n",
      "  Batch 700/938 - Training loss: 0.1164 - Average Test loss: 0.1431\n",
      "  Batch 800/938 - Training loss: 0.1202 - Average Test loss: 0.1430\n",
      "  Batch 900/938 - Training loss: 0.1549 - Average Test loss: 0.1444\n",
      "Epoch = 68\n",
      "  Batch 0/938 - Training loss: 0.1660 - Average Test loss: 0.1443\n",
      "  Batch 100/938 - Training loss: 0.1812 - Average Test loss: 0.1432\n",
      "  Batch 200/938 - Training loss: 0.1415 - Average Test loss: 0.1434\n",
      "  Batch 300/938 - Training loss: 0.2797 - Average Test loss: 0.1425\n",
      "  Batch 400/938 - Training loss: 0.1270 - Average Test loss: 0.1434\n",
      "  Batch 500/938 - Training loss: 0.1018 - Average Test loss: 0.1431\n",
      "  Batch 600/938 - Training loss: 0.2187 - Average Test loss: 0.1427\n",
      "  Batch 700/938 - Training loss: 0.1978 - Average Test loss: 0.1422\n",
      "  Batch 800/938 - Training loss: 0.0952 - Average Test loss: 0.1420\n",
      "  Batch 900/938 - Training loss: 0.0662 - Average Test loss: 0.1421\n",
      "Epoch = 69\n",
      "  Batch 0/938 - Training loss: 0.0543 - Average Test loss: 0.1416\n",
      "  Batch 100/938 - Training loss: 0.2067 - Average Test loss: 0.1419\n",
      "  Batch 200/938 - Training loss: 0.1447 - Average Test loss: 0.1410\n",
      "  Batch 300/938 - Training loss: 0.0982 - Average Test loss: 0.1413\n",
      "  Batch 400/938 - Training loss: 0.1015 - Average Test loss: 0.1407\n",
      "  Batch 500/938 - Training loss: 0.1697 - Average Test loss: 0.1418\n",
      "  Batch 600/938 - Training loss: 0.0949 - Average Test loss: 0.1417\n",
      "  Batch 700/938 - Training loss: 0.1774 - Average Test loss: 0.1411\n",
      "  Batch 800/938 - Training loss: 0.1356 - Average Test loss: 0.1399\n",
      "  Batch 900/938 - Training loss: 0.0989 - Average Test loss: 0.1405\n",
      "Epoch = 70\n",
      "  Batch 0/938 - Training loss: 0.1800 - Average Test loss: 0.1400\n",
      "  Batch 100/938 - Training loss: 0.0765 - Average Test loss: 0.1415\n",
      "  Batch 200/938 - Training loss: 0.0638 - Average Test loss: 0.1400\n",
      "  Batch 300/938 - Training loss: 0.1156 - Average Test loss: 0.1402\n",
      "  Batch 400/938 - Training loss: 0.1235 - Average Test loss: 0.1398\n",
      "  Batch 500/938 - Training loss: 0.1078 - Average Test loss: 0.1398\n",
      "  Batch 600/938 - Training loss: 0.2503 - Average Test loss: 0.1399\n",
      "  Batch 700/938 - Training loss: 0.0379 - Average Test loss: 0.1399\n",
      "  Batch 800/938 - Training loss: 0.0734 - Average Test loss: 0.1396\n",
      "  Batch 900/938 - Training loss: 0.0958 - Average Test loss: 0.1393\n",
      "Epoch = 71\n",
      "  Batch 0/938 - Training loss: 0.2267 - Average Test loss: 0.1386\n",
      "  Batch 100/938 - Training loss: 0.1217 - Average Test loss: 0.1384\n",
      "  Batch 200/938 - Training loss: 0.1059 - Average Test loss: 0.1391\n",
      "  Batch 300/938 - Training loss: 0.1297 - Average Test loss: 0.1382\n",
      "  Batch 400/938 - Training loss: 0.2142 - Average Test loss: 0.1378\n",
      "  Batch 500/938 - Training loss: 0.0247 - Average Test loss: 0.1388\n",
      "  Batch 600/938 - Training loss: 0.0729 - Average Test loss: 0.1391\n",
      "  Batch 700/938 - Training loss: 0.1428 - Average Test loss: 0.1376\n",
      "  Batch 800/938 - Training loss: 0.1392 - Average Test loss: 0.1378\n",
      "  Batch 900/938 - Training loss: 0.1650 - Average Test loss: 0.1380\n",
      "Epoch = 72\n",
      "  Batch 0/938 - Training loss: 0.1446 - Average Test loss: 0.1387\n",
      "  Batch 100/938 - Training loss: 0.0818 - Average Test loss: 0.1380\n",
      "  Batch 200/938 - Training loss: 0.1229 - Average Test loss: 0.1382\n",
      "  Batch 300/938 - Training loss: 0.1160 - Average Test loss: 0.1375\n",
      "  Batch 400/938 - Training loss: 0.0655 - Average Test loss: 0.1377\n",
      "  Batch 500/938 - Training loss: 0.1073 - Average Test loss: 0.1386\n",
      "  Batch 600/938 - Training loss: 0.1855 - Average Test loss: 0.1371\n",
      "  Batch 700/938 - Training loss: 0.0828 - Average Test loss: 0.1373\n",
      "  Batch 800/938 - Training loss: 0.1530 - Average Test loss: 0.1366\n",
      "  Batch 900/938 - Training loss: 0.1729 - Average Test loss: 0.1370\n",
      "Epoch = 73\n",
      "  Batch 0/938 - Training loss: 0.1629 - Average Test loss: 0.1365\n",
      "  Batch 100/938 - Training loss: 0.0986 - Average Test loss: 0.1378\n",
      "  Batch 200/938 - Training loss: 0.1245 - Average Test loss: 0.1375\n",
      "  Batch 300/938 - Training loss: 0.1899 - Average Test loss: 0.1373\n",
      "  Batch 400/938 - Training loss: 0.1294 - Average Test loss: 0.1354\n",
      "  Batch 500/938 - Training loss: 0.0775 - Average Test loss: 0.1365\n",
      "  Batch 600/938 - Training loss: 0.0942 - Average Test loss: 0.1355\n",
      "  Batch 700/938 - Training loss: 0.1615 - Average Test loss: 0.1360\n",
      "  Batch 800/938 - Training loss: 0.0534 - Average Test loss: 0.1354\n",
      "  Batch 900/938 - Training loss: 0.2013 - Average Test loss: 0.1361\n",
      "Epoch = 74\n",
      "  Batch 0/938 - Training loss: 0.3044 - Average Test loss: 0.1356\n",
      "  Batch 100/938 - Training loss: 0.0380 - Average Test loss: 0.1351\n",
      "  Batch 200/938 - Training loss: 0.0899 - Average Test loss: 0.1354\n",
      "  Batch 300/938 - Training loss: 0.1112 - Average Test loss: 0.1349\n",
      "  Batch 400/938 - Training loss: 0.0413 - Average Test loss: 0.1347\n",
      "  Batch 500/938 - Training loss: 0.2532 - Average Test loss: 0.1350\n",
      "  Batch 600/938 - Training loss: 0.1808 - Average Test loss: 0.1362\n",
      "  Batch 700/938 - Training loss: 0.0714 - Average Test loss: 0.1344\n",
      "  Batch 800/938 - Training loss: 0.1477 - Average Test loss: 0.1349\n",
      "  Batch 900/938 - Training loss: 0.1335 - Average Test loss: 0.1345\n",
      "Epoch = 75\n",
      "  Batch 0/938 - Training loss: 0.1484 - Average Test loss: 0.1346\n",
      "  Batch 100/938 - Training loss: 0.0773 - Average Test loss: 0.1337\n",
      "  Batch 200/938 - Training loss: 0.1078 - Average Test loss: 0.1343\n",
      "  Batch 300/938 - Training loss: 0.1486 - Average Test loss: 0.1345\n",
      "  Batch 400/938 - Training loss: 0.2373 - Average Test loss: 0.1342\n",
      "  Batch 500/938 - Training loss: 0.0795 - Average Test loss: 0.1342\n",
      "  Batch 600/938 - Training loss: 0.1104 - Average Test loss: 0.1339\n",
      "  Batch 700/938 - Training loss: 0.0399 - Average Test loss: 0.1328\n",
      "  Batch 800/938 - Training loss: 0.0917 - Average Test loss: 0.1331\n",
      "  Batch 900/938 - Training loss: 0.1872 - Average Test loss: 0.1339\n",
      "Epoch = 76\n",
      "  Batch 0/938 - Training loss: 0.1810 - Average Test loss: 0.1331\n",
      "  Batch 100/938 - Training loss: 0.1076 - Average Test loss: 0.1328\n",
      "  Batch 200/938 - Training loss: 0.0894 - Average Test loss: 0.1336\n",
      "  Batch 300/938 - Training loss: 0.2048 - Average Test loss: 0.1326\n",
      "  Batch 400/938 - Training loss: 0.1431 - Average Test loss: 0.1328\n",
      "  Batch 500/938 - Training loss: 0.2305 - Average Test loss: 0.1341\n",
      "  Batch 600/938 - Training loss: 0.3288 - Average Test loss: 0.1320\n",
      "  Batch 700/938 - Training loss: 0.0499 - Average Test loss: 0.1322\n",
      "  Batch 800/938 - Training loss: 0.1383 - Average Test loss: 0.1328\n",
      "  Batch 900/938 - Training loss: 0.1635 - Average Test loss: 0.1319\n",
      "Epoch = 77\n",
      "  Batch 0/938 - Training loss: 0.0504 - Average Test loss: 0.1319\n",
      "  Batch 100/938 - Training loss: 0.2388 - Average Test loss: 0.1318\n",
      "  Batch 200/938 - Training loss: 0.0924 - Average Test loss: 0.1316\n",
      "  Batch 300/938 - Training loss: 0.0459 - Average Test loss: 0.1320\n",
      "  Batch 400/938 - Training loss: 0.0828 - Average Test loss: 0.1306\n",
      "  Batch 500/938 - Training loss: 0.0606 - Average Test loss: 0.1310\n",
      "  Batch 600/938 - Training loss: 0.0558 - Average Test loss: 0.1313\n",
      "  Batch 700/938 - Training loss: 0.0801 - Average Test loss: 0.1311\n",
      "  Batch 800/938 - Training loss: 0.0958 - Average Test loss: 0.1314\n",
      "  Batch 900/938 - Training loss: 0.2220 - Average Test loss: 0.1308\n",
      "Epoch = 78\n",
      "  Batch 0/938 - Training loss: 0.0868 - Average Test loss: 0.1310\n",
      "  Batch 100/938 - Training loss: 0.1060 - Average Test loss: 0.1303\n",
      "  Batch 200/938 - Training loss: 0.0481 - Average Test loss: 0.1316\n",
      "  Batch 300/938 - Training loss: 0.2543 - Average Test loss: 0.1311\n",
      "  Batch 400/938 - Training loss: 0.3391 - Average Test loss: 0.1297\n",
      "  Batch 500/938 - Training loss: 0.1112 - Average Test loss: 0.1297\n",
      "  Batch 600/938 - Training loss: 0.0469 - Average Test loss: 0.1299\n",
      "  Batch 700/938 - Training loss: 0.1367 - Average Test loss: 0.1311\n",
      "  Batch 800/938 - Training loss: 0.1225 - Average Test loss: 0.1300\n",
      "  Batch 900/938 - Training loss: 0.0680 - Average Test loss: 0.1302\n",
      "Epoch = 79\n",
      "  Batch 0/938 - Training loss: 0.0797 - Average Test loss: 0.1301\n",
      "  Batch 100/938 - Training loss: 0.1214 - Average Test loss: 0.1298\n",
      "  Batch 200/938 - Training loss: 0.1520 - Average Test loss: 0.1298\n",
      "  Batch 300/938 - Training loss: 0.0467 - Average Test loss: 0.1292\n",
      "  Batch 400/938 - Training loss: 0.1512 - Average Test loss: 0.1296\n",
      "  Batch 500/938 - Training loss: 0.1444 - Average Test loss: 0.1293\n",
      "  Batch 600/938 - Training loss: 0.1727 - Average Test loss: 0.1302\n",
      "  Batch 700/938 - Training loss: 0.1207 - Average Test loss: 0.1314\n",
      "  Batch 800/938 - Training loss: 0.0284 - Average Test loss: 0.1286\n",
      "  Batch 900/938 - Training loss: 0.0673 - Average Test loss: 0.1290\n",
      "Epoch = 80\n",
      "  Batch 0/938 - Training loss: 0.1134 - Average Test loss: 0.1282\n",
      "  Batch 100/938 - Training loss: 0.0915 - Average Test loss: 0.1291\n",
      "  Batch 200/938 - Training loss: 0.1189 - Average Test loss: 0.1287\n",
      "  Batch 300/938 - Training loss: 0.0541 - Average Test loss: 0.1289\n",
      "  Batch 400/938 - Training loss: 0.1194 - Average Test loss: 0.1285\n",
      "  Batch 500/938 - Training loss: 0.1243 - Average Test loss: 0.1306\n",
      "  Batch 600/938 - Training loss: 0.0506 - Average Test loss: 0.1285\n",
      "  Batch 700/938 - Training loss: 0.0523 - Average Test loss: 0.1286\n",
      "  Batch 800/938 - Training loss: 0.1672 - Average Test loss: 0.1278\n",
      "  Batch 900/938 - Training loss: 0.1519 - Average Test loss: 0.1274\n",
      "Epoch = 81\n",
      "  Batch 0/938 - Training loss: 0.1264 - Average Test loss: 0.1272\n",
      "  Batch 100/938 - Training loss: 0.0425 - Average Test loss: 0.1274\n",
      "  Batch 200/938 - Training loss: 0.2878 - Average Test loss: 0.1281\n",
      "  Batch 300/938 - Training loss: 0.0951 - Average Test loss: 0.1277\n",
      "  Batch 400/938 - Training loss: 0.1088 - Average Test loss: 0.1274\n",
      "  Batch 500/938 - Training loss: 0.1463 - Average Test loss: 0.1271\n",
      "  Batch 600/938 - Training loss: 0.1857 - Average Test loss: 0.1287\n",
      "  Batch 700/938 - Training loss: 0.0911 - Average Test loss: 0.1269\n",
      "  Batch 800/938 - Training loss: 0.2588 - Average Test loss: 0.1276\n",
      "  Batch 900/938 - Training loss: 0.2434 - Average Test loss: 0.1263\n",
      "Epoch = 82\n",
      "  Batch 0/938 - Training loss: 0.0556 - Average Test loss: 0.1283\n",
      "  Batch 100/938 - Training loss: 0.0454 - Average Test loss: 0.1265\n",
      "  Batch 200/938 - Training loss: 0.0691 - Average Test loss: 0.1264\n",
      "  Batch 300/938 - Training loss: 0.0599 - Average Test loss: 0.1272\n",
      "  Batch 400/938 - Training loss: 0.1261 - Average Test loss: 0.1263\n",
      "  Batch 500/938 - Training loss: 0.1752 - Average Test loss: 0.1265\n",
      "  Batch 600/938 - Training loss: 0.1827 - Average Test loss: 0.1276\n",
      "  Batch 700/938 - Training loss: 0.0309 - Average Test loss: 0.1258\n",
      "  Batch 800/938 - Training loss: 0.0943 - Average Test loss: 0.1266\n",
      "  Batch 900/938 - Training loss: 0.2839 - Average Test loss: 0.1255\n",
      "Epoch = 83\n",
      "  Batch 0/938 - Training loss: 0.1334 - Average Test loss: 0.1258\n",
      "  Batch 100/938 - Training loss: 0.2449 - Average Test loss: 0.1257\n",
      "  Batch 200/938 - Training loss: 0.1055 - Average Test loss: 0.1254\n",
      "  Batch 300/938 - Training loss: 0.0990 - Average Test loss: 0.1257\n",
      "  Batch 400/938 - Training loss: 0.0956 - Average Test loss: 0.1256\n",
      "  Batch 500/938 - Training loss: 0.1130 - Average Test loss: 0.1252\n",
      "  Batch 600/938 - Training loss: 0.0652 - Average Test loss: 0.1253\n",
      "  Batch 700/938 - Training loss: 0.0247 - Average Test loss: 0.1247\n",
      "  Batch 800/938 - Training loss: 0.1019 - Average Test loss: 0.1252\n",
      "  Batch 900/938 - Training loss: 0.0549 - Average Test loss: 0.1252\n",
      "Epoch = 84\n",
      "  Batch 0/938 - Training loss: 0.0795 - Average Test loss: 0.1251\n",
      "  Batch 100/938 - Training loss: 0.2057 - Average Test loss: 0.1244\n",
      "  Batch 200/938 - Training loss: 0.1041 - Average Test loss: 0.1256\n",
      "  Batch 300/938 - Training loss: 0.1529 - Average Test loss: 0.1244\n",
      "  Batch 400/938 - Training loss: 0.1200 - Average Test loss: 0.1253\n",
      "  Batch 500/938 - Training loss: 0.1270 - Average Test loss: 0.1236\n",
      "  Batch 600/938 - Training loss: 0.0698 - Average Test loss: 0.1243\n",
      "  Batch 700/938 - Training loss: 0.1882 - Average Test loss: 0.1239\n",
      "  Batch 800/938 - Training loss: 0.1571 - Average Test loss: 0.1241\n",
      "  Batch 900/938 - Training loss: 0.1418 - Average Test loss: 0.1241\n",
      "Epoch = 85\n",
      "  Batch 0/938 - Training loss: 0.0642 - Average Test loss: 0.1241\n",
      "  Batch 100/938 - Training loss: 0.3230 - Average Test loss: 0.1237\n",
      "  Batch 200/938 - Training loss: 0.1834 - Average Test loss: 0.1241\n",
      "  Batch 300/938 - Training loss: 0.0990 - Average Test loss: 0.1244\n",
      "  Batch 400/938 - Training loss: 0.1399 - Average Test loss: 0.1251\n",
      "  Batch 500/938 - Training loss: 0.1085 - Average Test loss: 0.1230\n",
      "  Batch 600/938 - Training loss: 0.1043 - Average Test loss: 0.1229\n",
      "  Batch 700/938 - Training loss: 0.0982 - Average Test loss: 0.1231\n",
      "  Batch 800/938 - Training loss: 0.0698 - Average Test loss: 0.1231\n",
      "  Batch 900/938 - Training loss: 0.0819 - Average Test loss: 0.1235\n",
      "Epoch = 86\n",
      "  Batch 0/938 - Training loss: 0.1446 - Average Test loss: 0.1227\n",
      "  Batch 100/938 - Training loss: 0.0567 - Average Test loss: 0.1225\n",
      "  Batch 200/938 - Training loss: 0.0715 - Average Test loss: 0.1228\n",
      "  Batch 300/938 - Training loss: 0.1160 - Average Test loss: 0.1226\n",
      "  Batch 400/938 - Training loss: 0.0754 - Average Test loss: 0.1228\n",
      "  Batch 500/938 - Training loss: 0.0682 - Average Test loss: 0.1227\n",
      "  Batch 600/938 - Training loss: 0.0256 - Average Test loss: 0.1230\n",
      "  Batch 700/938 - Training loss: 0.0568 - Average Test loss: 0.1232\n",
      "  Batch 800/938 - Training loss: 0.1178 - Average Test loss: 0.1221\n",
      "  Batch 900/938 - Training loss: 0.1108 - Average Test loss: 0.1223\n",
      "Epoch = 87\n",
      "  Batch 0/938 - Training loss: 0.0776 - Average Test loss: 0.1216\n",
      "  Batch 100/938 - Training loss: 0.0611 - Average Test loss: 0.1217\n",
      "  Batch 200/938 - Training loss: 0.2691 - Average Test loss: 0.1216\n",
      "  Batch 300/938 - Training loss: 0.1045 - Average Test loss: 0.1210\n",
      "  Batch 400/938 - Training loss: 0.1579 - Average Test loss: 0.1209\n",
      "  Batch 500/938 - Training loss: 0.0868 - Average Test loss: 0.1223\n",
      "  Batch 600/938 - Training loss: 0.2051 - Average Test loss: 0.1217\n",
      "  Batch 700/938 - Training loss: 0.0655 - Average Test loss: 0.1216\n",
      "  Batch 800/938 - Training loss: 0.0402 - Average Test loss: 0.1211\n",
      "  Batch 900/938 - Training loss: 0.1327 - Average Test loss: 0.1223\n",
      "Epoch = 88\n",
      "  Batch 0/938 - Training loss: 0.0781 - Average Test loss: 0.1216\n",
      "  Batch 100/938 - Training loss: 0.1013 - Average Test loss: 0.1212\n",
      "  Batch 200/938 - Training loss: 0.1386 - Average Test loss: 0.1221\n",
      "  Batch 300/938 - Training loss: 0.1163 - Average Test loss: 0.1213\n",
      "  Batch 400/938 - Training loss: 0.1198 - Average Test loss: 0.1211\n",
      "  Batch 500/938 - Training loss: 0.0832 - Average Test loss: 0.1208\n",
      "  Batch 600/938 - Training loss: 0.1364 - Average Test loss: 0.1207\n",
      "  Batch 700/938 - Training loss: 0.1088 - Average Test loss: 0.1207\n",
      "  Batch 800/938 - Training loss: 0.0537 - Average Test loss: 0.1201\n",
      "  Batch 900/938 - Training loss: 0.1863 - Average Test loss: 0.1210\n",
      "Epoch = 89\n",
      "  Batch 0/938 - Training loss: 0.1149 - Average Test loss: 0.1203\n",
      "  Batch 100/938 - Training loss: 0.0927 - Average Test loss: 0.1199\n",
      "  Batch 200/938 - Training loss: 0.1560 - Average Test loss: 0.1201\n",
      "  Batch 300/938 - Training loss: 0.0536 - Average Test loss: 0.1207\n",
      "  Batch 400/938 - Training loss: 0.0919 - Average Test loss: 0.1197\n",
      "  Batch 500/938 - Training loss: 0.0422 - Average Test loss: 0.1197\n",
      "  Batch 600/938 - Training loss: 0.0529 - Average Test loss: 0.1201\n",
      "  Batch 700/938 - Training loss: 0.0806 - Average Test loss: 0.1196\n",
      "  Batch 800/938 - Training loss: 0.0793 - Average Test loss: 0.1194\n",
      "  Batch 900/938 - Training loss: 0.0485 - Average Test loss: 0.1199\n",
      "Epoch = 90\n",
      "  Batch 0/938 - Training loss: 0.0409 - Average Test loss: 0.1214\n",
      "  Batch 100/938 - Training loss: 0.1746 - Average Test loss: 0.1197\n",
      "  Batch 200/938 - Training loss: 0.0916 - Average Test loss: 0.1190\n",
      "  Batch 300/938 - Training loss: 0.1043 - Average Test loss: 0.1188\n",
      "  Batch 400/938 - Training loss: 0.0775 - Average Test loss: 0.1194\n",
      "  Batch 500/938 - Training loss: 0.0695 - Average Test loss: 0.1187\n",
      "  Batch 600/938 - Training loss: 0.1835 - Average Test loss: 0.1201\n",
      "  Batch 700/938 - Training loss: 0.1054 - Average Test loss: 0.1184\n",
      "  Batch 800/938 - Training loss: 0.0886 - Average Test loss: 0.1200\n",
      "  Batch 900/938 - Training loss: 0.0867 - Average Test loss: 0.1185\n",
      "Epoch = 91\n",
      "  Batch 0/938 - Training loss: 0.0728 - Average Test loss: 0.1192\n",
      "  Batch 100/938 - Training loss: 0.1311 - Average Test loss: 0.1187\n",
      "  Batch 200/938 - Training loss: 0.0465 - Average Test loss: 0.1187\n",
      "  Batch 300/938 - Training loss: 0.0975 - Average Test loss: 0.1189\n",
      "  Batch 400/938 - Training loss: 0.1579 - Average Test loss: 0.1192\n",
      "  Batch 500/938 - Training loss: 0.1494 - Average Test loss: 0.1192\n",
      "  Batch 600/938 - Training loss: 0.0586 - Average Test loss: 0.1187\n",
      "  Batch 700/938 - Training loss: 0.2388 - Average Test loss: 0.1171\n",
      "  Batch 800/938 - Training loss: 0.1845 - Average Test loss: 0.1174\n",
      "  Batch 900/938 - Training loss: 0.2098 - Average Test loss: 0.1176\n",
      "Epoch = 92\n",
      "  Batch 0/938 - Training loss: 0.1151 - Average Test loss: 0.1174\n",
      "  Batch 100/938 - Training loss: 0.1284 - Average Test loss: 0.1176\n",
      "  Batch 200/938 - Training loss: 0.1469 - Average Test loss: 0.1170\n",
      "  Batch 300/938 - Training loss: 0.1770 - Average Test loss: 0.1180\n",
      "  Batch 400/938 - Training loss: 0.0887 - Average Test loss: 0.1172\n",
      "  Batch 500/938 - Training loss: 0.0760 - Average Test loss: 0.1167\n",
      "  Batch 600/938 - Training loss: 0.1842 - Average Test loss: 0.1183\n",
      "  Batch 700/938 - Training loss: 0.1084 - Average Test loss: 0.1173\n",
      "  Batch 800/938 - Training loss: 0.0523 - Average Test loss: 0.1169\n",
      "  Batch 900/938 - Training loss: 0.1985 - Average Test loss: 0.1172\n",
      "Epoch = 93\n",
      "  Batch 0/938 - Training loss: 0.0825 - Average Test loss: 0.1185\n",
      "  Batch 100/938 - Training loss: 0.1029 - Average Test loss: 0.1189\n",
      "  Batch 200/938 - Training loss: 0.1734 - Average Test loss: 0.1163\n",
      "  Batch 300/938 - Training loss: 0.1810 - Average Test loss: 0.1165\n",
      "  Batch 400/938 - Training loss: 0.0462 - Average Test loss: 0.1161\n",
      "  Batch 500/938 - Training loss: 0.1036 - Average Test loss: 0.1172\n",
      "  Batch 600/938 - Training loss: 0.0849 - Average Test loss: 0.1170\n",
      "  Batch 700/938 - Training loss: 0.2589 - Average Test loss: 0.1163\n",
      "  Batch 800/938 - Training loss: 0.1007 - Average Test loss: 0.1168\n",
      "  Batch 900/938 - Training loss: 0.0394 - Average Test loss: 0.1163\n",
      "Epoch = 94\n",
      "  Batch 0/938 - Training loss: 0.0797 - Average Test loss: 0.1160\n",
      "  Batch 100/938 - Training loss: 0.1074 - Average Test loss: 0.1164\n",
      "  Batch 200/938 - Training loss: 0.0745 - Average Test loss: 0.1162\n",
      "  Batch 300/938 - Training loss: 0.1030 - Average Test loss: 0.1157\n",
      "  Batch 400/938 - Training loss: 0.0630 - Average Test loss: 0.1161\n",
      "  Batch 500/938 - Training loss: 0.1409 - Average Test loss: 0.1160\n",
      "  Batch 600/938 - Training loss: 0.1303 - Average Test loss: 0.1155\n",
      "  Batch 700/938 - Training loss: 0.0482 - Average Test loss: 0.1159\n",
      "  Batch 800/938 - Training loss: 0.0654 - Average Test loss: 0.1148\n",
      "  Batch 900/938 - Training loss: 0.2264 - Average Test loss: 0.1155\n",
      "Epoch = 95\n",
      "  Batch 0/938 - Training loss: 0.1273 - Average Test loss: 0.1154\n",
      "  Batch 100/938 - Training loss: 0.0946 - Average Test loss: 0.1159\n",
      "  Batch 200/938 - Training loss: 0.2171 - Average Test loss: 0.1153\n",
      "  Batch 300/938 - Training loss: 0.1062 - Average Test loss: 0.1149\n",
      "  Batch 400/938 - Training loss: 0.1039 - Average Test loss: 0.1149\n",
      "  Batch 500/938 - Training loss: 0.1213 - Average Test loss: 0.1168\n",
      "  Batch 600/938 - Training loss: 0.0956 - Average Test loss: 0.1148\n",
      "  Batch 700/938 - Training loss: 0.1026 - Average Test loss: 0.1151\n",
      "  Batch 800/938 - Training loss: 0.0866 - Average Test loss: 0.1148\n",
      "  Batch 900/938 - Training loss: 0.0943 - Average Test loss: 0.1144\n",
      "Epoch = 96\n",
      "  Batch 0/938 - Training loss: 0.1372 - Average Test loss: 0.1147\n",
      "  Batch 100/938 - Training loss: 0.0841 - Average Test loss: 0.1153\n",
      "  Batch 200/938 - Training loss: 0.0963 - Average Test loss: 0.1148\n",
      "  Batch 300/938 - Training loss: 0.0790 - Average Test loss: 0.1142\n",
      "  Batch 400/938 - Training loss: 0.1927 - Average Test loss: 0.1145\n",
      "  Batch 500/938 - Training loss: 0.1005 - Average Test loss: 0.1139\n",
      "  Batch 600/938 - Training loss: 0.0569 - Average Test loss: 0.1141\n",
      "  Batch 700/938 - Training loss: 0.0322 - Average Test loss: 0.1141\n",
      "  Batch 800/938 - Training loss: 0.1727 - Average Test loss: 0.1139\n",
      "  Batch 900/938 - Training loss: 0.1322 - Average Test loss: 0.1144\n",
      "Epoch = 97\n",
      "  Batch 0/938 - Training loss: 0.2609 - Average Test loss: 0.1146\n",
      "  Batch 100/938 - Training loss: 0.2084 - Average Test loss: 0.1143\n",
      "  Batch 200/938 - Training loss: 0.1678 - Average Test loss: 0.1148\n",
      "  Batch 300/938 - Training loss: 0.0621 - Average Test loss: 0.1132\n",
      "  Batch 400/938 - Training loss: 0.1132 - Average Test loss: 0.1143\n",
      "  Batch 500/938 - Training loss: 0.0276 - Average Test loss: 0.1133\n",
      "  Batch 600/938 - Training loss: 0.0775 - Average Test loss: 0.1138\n",
      "  Batch 700/938 - Training loss: 0.1123 - Average Test loss: 0.1133\n",
      "  Batch 800/938 - Training loss: 0.0304 - Average Test loss: 0.1129\n",
      "  Batch 900/938 - Training loss: 0.1446 - Average Test loss: 0.1130\n",
      "Epoch = 98\n",
      "  Batch 0/938 - Training loss: 0.0764 - Average Test loss: 0.1133\n",
      "  Batch 100/938 - Training loss: 0.1069 - Average Test loss: 0.1130\n",
      "  Batch 200/938 - Training loss: 0.0351 - Average Test loss: 0.1133\n",
      "  Batch 300/938 - Training loss: 0.0425 - Average Test loss: 0.1127\n",
      "  Batch 400/938 - Training loss: 0.0773 - Average Test loss: 0.1130\n",
      "  Batch 500/938 - Training loss: 0.1453 - Average Test loss: 0.1142\n",
      "  Batch 600/938 - Training loss: 0.0494 - Average Test loss: 0.1124\n",
      "  Batch 700/938 - Training loss: 0.1068 - Average Test loss: 0.1136\n",
      "  Batch 800/938 - Training loss: 0.0558 - Average Test loss: 0.1122\n",
      "  Batch 900/938 - Training loss: 0.0836 - Average Test loss: 0.1120\n",
      "Epoch = 99\n",
      "  Batch 0/938 - Training loss: 0.2051 - Average Test loss: 0.1125\n",
      "  Batch 100/938 - Training loss: 0.1731 - Average Test loss: 0.1126\n",
      "  Batch 200/938 - Training loss: 0.1532 - Average Test loss: 0.1122\n",
      "  Batch 300/938 - Training loss: 0.0724 - Average Test loss: 0.1129\n",
      "  Batch 400/938 - Training loss: 0.0529 - Average Test loss: 0.1118\n",
      "  Batch 500/938 - Training loss: 0.1277 - Average Test loss: 0.1118\n",
      "  Batch 600/938 - Training loss: 0.0731 - Average Test loss: 0.1122\n",
      "  Batch 700/938 - Training loss: 0.1669 - Average Test loss: 0.1115\n",
      "  Batch 800/938 - Training loss: 0.1476 - Average Test loss: 0.1126\n",
      "  Batch 900/938 - Training loss: 0.1797 - Average Test loss: 0.1111\n",
      "Epoch = 100\n",
      "  Batch 0/938 - Training loss: 0.1005 - Average Test loss: 0.1115\n",
      "  Batch 100/938 - Training loss: 0.0268 - Average Test loss: 0.1124\n",
      "  Batch 200/938 - Training loss: 0.0563 - Average Test loss: 0.1118\n",
      "  Batch 300/938 - Training loss: 0.0706 - Average Test loss: 0.1110\n",
      "  Batch 400/938 - Training loss: 0.1477 - Average Test loss: 0.1112\n",
      "  Batch 500/938 - Training loss: 0.0232 - Average Test loss: 0.1124\n",
      "  Batch 600/938 - Training loss: 0.1048 - Average Test loss: 0.1118\n",
      "  Batch 700/938 - Training loss: 0.1415 - Average Test loss: 0.1119\n",
      "  Batch 800/938 - Training loss: 0.0332 - Average Test loss: 0.1114\n",
      "  Batch 900/938 - Training loss: 0.1109 - Average Test loss: 0.1122\n",
      "Epoch = 101\n",
      "  Batch 0/938 - Training loss: 0.1764 - Average Test loss: 0.1121\n",
      "  Batch 100/938 - Training loss: 0.0876 - Average Test loss: 0.1106\n",
      "  Batch 200/938 - Training loss: 0.1016 - Average Test loss: 0.1113\n",
      "  Batch 300/938 - Training loss: 0.0656 - Average Test loss: 0.1109\n",
      "  Batch 400/938 - Training loss: 0.0316 - Average Test loss: 0.1101\n",
      "  Batch 500/938 - Training loss: 0.2049 - Average Test loss: 0.1111\n",
      "  Batch 600/938 - Training loss: 0.0700 - Average Test loss: 0.1103\n",
      "  Batch 700/938 - Training loss: 0.0740 - Average Test loss: 0.1105\n",
      "  Batch 800/938 - Training loss: 0.1423 - Average Test loss: 0.1099\n",
      "  Batch 900/938 - Training loss: 0.0786 - Average Test loss: 0.1116\n",
      "Epoch = 102\n",
      "  Batch 0/938 - Training loss: 0.0490 - Average Test loss: 0.1122\n",
      "  Batch 100/938 - Training loss: 0.0573 - Average Test loss: 0.1103\n",
      "  Batch 200/938 - Training loss: 0.0862 - Average Test loss: 0.1102\n",
      "  Batch 300/938 - Training loss: 0.1166 - Average Test loss: 0.1094\n",
      "  Batch 400/938 - Training loss: 0.1602 - Average Test loss: 0.1111\n",
      "  Batch 500/938 - Training loss: 0.0808 - Average Test loss: 0.1100\n",
      "  Batch 600/938 - Training loss: 0.0310 - Average Test loss: 0.1108\n",
      "  Batch 700/938 - Training loss: 0.0395 - Average Test loss: 0.1098\n",
      "  Batch 800/938 - Training loss: 0.0505 - Average Test loss: 0.1102\n",
      "  Batch 900/938 - Training loss: 0.1327 - Average Test loss: 0.1102\n",
      "Epoch = 103\n",
      "  Batch 0/938 - Training loss: 0.0708 - Average Test loss: 0.1101\n",
      "  Batch 100/938 - Training loss: 0.1171 - Average Test loss: 0.1099\n",
      "  Batch 200/938 - Training loss: 0.0818 - Average Test loss: 0.1095\n",
      "  Batch 300/938 - Training loss: 0.1078 - Average Test loss: 0.1092\n",
      "  Batch 400/938 - Training loss: 0.1211 - Average Test loss: 0.1093\n",
      "  Batch 500/938 - Training loss: 0.0337 - Average Test loss: 0.1090\n",
      "  Batch 600/938 - Training loss: 0.0670 - Average Test loss: 0.1091\n",
      "  Batch 700/938 - Training loss: 0.0362 - Average Test loss: 0.1090\n",
      "  Batch 800/938 - Training loss: 0.0696 - Average Test loss: 0.1093\n",
      "  Batch 900/938 - Training loss: 0.0703 - Average Test loss: 0.1098\n",
      "Epoch = 104\n",
      "  Batch 0/938 - Training loss: 0.1710 - Average Test loss: 0.1095\n",
      "  Batch 100/938 - Training loss: 0.0648 - Average Test loss: 0.1107\n",
      "  Batch 200/938 - Training loss: 0.0585 - Average Test loss: 0.1087\n",
      "  Batch 300/938 - Training loss: 0.0808 - Average Test loss: 0.1090\n",
      "  Batch 400/938 - Training loss: 0.0804 - Average Test loss: 0.1085\n",
      "  Batch 500/938 - Training loss: 0.0918 - Average Test loss: 0.1086\n",
      "  Batch 600/938 - Training loss: 0.0452 - Average Test loss: 0.1086\n",
      "  Batch 700/938 - Training loss: 0.0632 - Average Test loss: 0.1084\n",
      "  Batch 800/938 - Training loss: 0.1019 - Average Test loss: 0.1085\n",
      "  Batch 900/938 - Training loss: 0.0704 - Average Test loss: 0.1087\n",
      "Epoch = 105\n",
      "  Batch 0/938 - Training loss: 0.0660 - Average Test loss: 0.1086\n",
      "  Batch 100/938 - Training loss: 0.0733 - Average Test loss: 0.1086\n",
      "  Batch 200/938 - Training loss: 0.1909 - Average Test loss: 0.1085\n",
      "  Batch 300/938 - Training loss: 0.0263 - Average Test loss: 0.1086\n",
      "  Batch 400/938 - Training loss: 0.0472 - Average Test loss: 0.1092\n",
      "  Batch 500/938 - Training loss: 0.1028 - Average Test loss: 0.1086\n",
      "  Batch 600/938 - Training loss: 0.1222 - Average Test loss: 0.1077\n",
      "  Batch 700/938 - Training loss: 0.0428 - Average Test loss: 0.1084\n",
      "  Batch 800/938 - Training loss: 0.1397 - Average Test loss: 0.1085\n",
      "  Batch 900/938 - Training loss: 0.0249 - Average Test loss: 0.1072\n",
      "Epoch = 106\n",
      "  Batch 0/938 - Training loss: 0.1845 - Average Test loss: 0.1075\n",
      "  Batch 100/938 - Training loss: 0.1142 - Average Test loss: 0.1073\n",
      "  Batch 200/938 - Training loss: 0.1594 - Average Test loss: 0.1078\n",
      "  Batch 300/938 - Training loss: 0.0531 - Average Test loss: 0.1077\n",
      "  Batch 400/938 - Training loss: 0.0442 - Average Test loss: 0.1071\n",
      "  Batch 500/938 - Training loss: 0.1131 - Average Test loss: 0.1074\n",
      "  Batch 600/938 - Training loss: 0.1623 - Average Test loss: 0.1072\n",
      "  Batch 700/938 - Training loss: 0.0287 - Average Test loss: 0.1071\n",
      "  Batch 800/938 - Training loss: 0.1202 - Average Test loss: 0.1075\n",
      "  Batch 900/938 - Training loss: 0.0353 - Average Test loss: 0.1072\n",
      "Epoch = 107\n",
      "  Batch 0/938 - Training loss: 0.1141 - Average Test loss: 0.1080\n",
      "  Batch 100/938 - Training loss: 0.1195 - Average Test loss: 0.1070\n",
      "  Batch 200/938 - Training loss: 0.0367 - Average Test loss: 0.1071\n",
      "  Batch 300/938 - Training loss: 0.0589 - Average Test loss: 0.1068\n",
      "  Batch 400/938 - Training loss: 0.0779 - Average Test loss: 0.1073\n",
      "  Batch 500/938 - Training loss: 0.1695 - Average Test loss: 0.1068\n",
      "  Batch 600/938 - Training loss: 0.0532 - Average Test loss: 0.1064\n",
      "  Batch 700/938 - Training loss: 0.0459 - Average Test loss: 0.1072\n",
      "  Batch 800/938 - Training loss: 0.0451 - Average Test loss: 0.1063\n",
      "  Batch 900/938 - Training loss: 0.0968 - Average Test loss: 0.1067\n",
      "Epoch = 108\n",
      "  Batch 0/938 - Training loss: 0.0951 - Average Test loss: 0.1071\n",
      "  Batch 100/938 - Training loss: 0.1390 - Average Test loss: 0.1064\n",
      "  Batch 200/938 - Training loss: 0.1665 - Average Test loss: 0.1063\n",
      "  Batch 300/938 - Training loss: 0.0583 - Average Test loss: 0.1057\n",
      "  Batch 400/938 - Training loss: 0.1255 - Average Test loss: 0.1060\n",
      "  Batch 500/938 - Training loss: 0.0701 - Average Test loss: 0.1061\n",
      "  Batch 600/938 - Training loss: 0.1223 - Average Test loss: 0.1062\n",
      "  Batch 700/938 - Training loss: 0.0768 - Average Test loss: 0.1068\n",
      "  Batch 800/938 - Training loss: 0.0673 - Average Test loss: 0.1063\n",
      "  Batch 900/938 - Training loss: 0.1267 - Average Test loss: 0.1083\n",
      "Epoch = 109\n",
      "  Batch 0/938 - Training loss: 0.0356 - Average Test loss: 0.1063\n",
      "  Batch 100/938 - Training loss: 0.0419 - Average Test loss: 0.1057\n",
      "  Batch 200/938 - Training loss: 0.0435 - Average Test loss: 0.1062\n",
      "  Batch 300/938 - Training loss: 0.0407 - Average Test loss: 0.1056\n",
      "  Batch 400/938 - Training loss: 0.0856 - Average Test loss: 0.1064\n",
      "  Batch 500/938 - Training loss: 0.0631 - Average Test loss: 0.1061\n",
      "  Batch 600/938 - Training loss: 0.0186 - Average Test loss: 0.1058\n",
      "  Batch 700/938 - Training loss: 0.1510 - Average Test loss: 0.1053\n",
      "  Batch 800/938 - Training loss: 0.0443 - Average Test loss: 0.1064\n",
      "  Batch 900/938 - Training loss: 0.1488 - Average Test loss: 0.1058\n",
      "Epoch = 110\n",
      "  Batch 0/938 - Training loss: 0.1136 - Average Test loss: 0.1056\n",
      "  Batch 100/938 - Training loss: 0.0864 - Average Test loss: 0.1059\n",
      "  Batch 200/938 - Training loss: 0.1073 - Average Test loss: 0.1056\n",
      "  Batch 300/938 - Training loss: 0.1078 - Average Test loss: 0.1054\n",
      "  Batch 400/938 - Training loss: 0.1521 - Average Test loss: 0.1049\n",
      "  Batch 500/938 - Training loss: 0.0542 - Average Test loss: 0.1049\n",
      "  Batch 600/938 - Training loss: 0.0820 - Average Test loss: 0.1049\n",
      "  Batch 700/938 - Training loss: 0.0672 - Average Test loss: 0.1054\n",
      "  Batch 800/938 - Training loss: 0.0887 - Average Test loss: 0.1051\n",
      "  Batch 900/938 - Training loss: 0.1000 - Average Test loss: 0.1047\n",
      "Epoch = 111\n",
      "  Batch 0/938 - Training loss: 0.0630 - Average Test loss: 0.1046\n",
      "  Batch 100/938 - Training loss: 0.0687 - Average Test loss: 0.1047\n",
      "  Batch 200/938 - Training loss: 0.0620 - Average Test loss: 0.1043\n",
      "  Batch 300/938 - Training loss: 0.0772 - Average Test loss: 0.1041\n",
      "  Batch 400/938 - Training loss: 0.0530 - Average Test loss: 0.1047\n",
      "  Batch 500/938 - Training loss: 0.0375 - Average Test loss: 0.1042\n",
      "  Batch 600/938 - Training loss: 0.1087 - Average Test loss: 0.1046\n",
      "  Batch 700/938 - Training loss: 0.0596 - Average Test loss: 0.1056\n",
      "  Batch 800/938 - Training loss: 0.0424 - Average Test loss: 0.1043\n",
      "  Batch 900/938 - Training loss: 0.0623 - Average Test loss: 0.1052\n",
      "Epoch = 112\n",
      "  Batch 0/938 - Training loss: 0.0623 - Average Test loss: 0.1042\n",
      "  Batch 100/938 - Training loss: 0.0430 - Average Test loss: 0.1048\n",
      "  Batch 200/938 - Training loss: 0.0633 - Average Test loss: 0.1058\n",
      "  Batch 300/938 - Training loss: 0.2756 - Average Test loss: 0.1043\n",
      "  Batch 400/938 - Training loss: 0.1342 - Average Test loss: 0.1039\n",
      "  Batch 500/938 - Training loss: 0.0968 - Average Test loss: 0.1037\n",
      "  Batch 600/938 - Training loss: 0.0962 - Average Test loss: 0.1042\n",
      "  Batch 700/938 - Training loss: 0.0358 - Average Test loss: 0.1049\n",
      "  Batch 800/938 - Training loss: 0.0556 - Average Test loss: 0.1045\n",
      "  Batch 900/938 - Training loss: 0.0526 - Average Test loss: 0.1037\n",
      "Epoch = 113\n",
      "  Batch 0/938 - Training loss: 0.0263 - Average Test loss: 0.1035\n",
      "  Batch 100/938 - Training loss: 0.0252 - Average Test loss: 0.1041\n",
      "  Batch 200/938 - Training loss: 0.0682 - Average Test loss: 0.1050\n",
      "  Batch 300/938 - Training loss: 0.0861 - Average Test loss: 0.1035\n",
      "  Batch 400/938 - Training loss: 0.0772 - Average Test loss: 0.1029\n",
      "  Batch 500/938 - Training loss: 0.0675 - Average Test loss: 0.1043\n",
      "  Batch 600/938 - Training loss: 0.1624 - Average Test loss: 0.1035\n",
      "  Batch 700/938 - Training loss: 0.0485 - Average Test loss: 0.1030\n",
      "  Batch 800/938 - Training loss: 0.0397 - Average Test loss: 0.1025\n",
      "  Batch 900/938 - Training loss: 0.0958 - Average Test loss: 0.1026\n",
      "Epoch = 114\n",
      "  Batch 0/938 - Training loss: 0.0582 - Average Test loss: 0.1029\n",
      "  Batch 100/938 - Training loss: 0.1079 - Average Test loss: 0.1032\n",
      "  Batch 200/938 - Training loss: 0.0572 - Average Test loss: 0.1028\n",
      "  Batch 300/938 - Training loss: 0.0608 - Average Test loss: 0.1029\n",
      "  Batch 400/938 - Training loss: 0.0887 - Average Test loss: 0.1034\n",
      "  Batch 500/938 - Training loss: 0.0660 - Average Test loss: 0.1031\n",
      "  Batch 600/938 - Training loss: 0.0918 - Average Test loss: 0.1026\n",
      "  Batch 700/938 - Training loss: 0.0849 - Average Test loss: 0.1035\n",
      "  Batch 800/938 - Training loss: 0.1837 - Average Test loss: 0.1035\n",
      "  Batch 900/938 - Training loss: 0.0312 - Average Test loss: 0.1020\n",
      "Epoch = 115\n",
      "  Batch 0/938 - Training loss: 0.0474 - Average Test loss: 0.1031\n",
      "  Batch 100/938 - Training loss: 0.1991 - Average Test loss: 0.1020\n",
      "  Batch 200/938 - Training loss: 0.1447 - Average Test loss: 0.1026\n",
      "  Batch 300/938 - Training loss: 0.0646 - Average Test loss: 0.1023\n",
      "  Batch 400/938 - Training loss: 0.1401 - Average Test loss: 0.1023\n",
      "  Batch 500/938 - Training loss: 0.1048 - Average Test loss: 0.1024\n",
      "  Batch 600/938 - Training loss: 0.0405 - Average Test loss: 0.1030\n",
      "  Batch 700/938 - Training loss: 0.1657 - Average Test loss: 0.1020\n",
      "  Batch 800/938 - Training loss: 0.1399 - Average Test loss: 0.1025\n",
      "  Batch 900/938 - Training loss: 0.1481 - Average Test loss: 0.1020\n",
      "Epoch = 116\n",
      "  Batch 0/938 - Training loss: 0.1106 - Average Test loss: 0.1018\n",
      "  Batch 100/938 - Training loss: 0.0486 - Average Test loss: 0.1019\n",
      "  Batch 200/938 - Training loss: 0.3396 - Average Test loss: 0.1022\n",
      "  Batch 300/938 - Training loss: 0.0141 - Average Test loss: 0.1025\n",
      "  Batch 400/938 - Training loss: 0.0928 - Average Test loss: 0.1019\n",
      "  Batch 500/938 - Training loss: 0.0880 - Average Test loss: 0.1014\n",
      "  Batch 600/938 - Training loss: 0.0798 - Average Test loss: 0.1021\n",
      "  Batch 700/938 - Training loss: 0.0613 - Average Test loss: 0.1018\n",
      "  Batch 800/938 - Training loss: 0.0468 - Average Test loss: 0.1011\n",
      "  Batch 900/938 - Training loss: 0.0561 - Average Test loss: 0.1018\n",
      "Epoch = 117\n",
      "  Batch 0/938 - Training loss: 0.0308 - Average Test loss: 0.1013\n",
      "  Batch 100/938 - Training loss: 0.0417 - Average Test loss: 0.1013\n",
      "  Batch 200/938 - Training loss: 0.2101 - Average Test loss: 0.1017\n",
      "  Batch 300/938 - Training loss: 0.0997 - Average Test loss: 0.1016\n",
      "  Batch 400/938 - Training loss: 0.1035 - Average Test loss: 0.1020\n",
      "  Batch 500/938 - Training loss: 0.0127 - Average Test loss: 0.1016\n",
      "  Batch 600/938 - Training loss: 0.0642 - Average Test loss: 0.1019\n",
      "  Batch 700/938 - Training loss: 0.1597 - Average Test loss: 0.1012\n",
      "  Batch 800/938 - Training loss: 0.0436 - Average Test loss: 0.1006\n",
      "  Batch 900/938 - Training loss: 0.0443 - Average Test loss: 0.1009\n",
      "Epoch = 118\n",
      "  Batch 0/938 - Training loss: 0.0591 - Average Test loss: 0.1008\n",
      "  Batch 100/938 - Training loss: 0.0768 - Average Test loss: 0.1014\n",
      "  Batch 200/938 - Training loss: 0.0457 - Average Test loss: 0.1017\n",
      "  Batch 300/938 - Training loss: 0.0353 - Average Test loss: 0.1013\n",
      "  Batch 400/938 - Training loss: 0.0556 - Average Test loss: 0.1007\n",
      "  Batch 500/938 - Training loss: 0.0178 - Average Test loss: 0.1015\n",
      "  Batch 600/938 - Training loss: 0.0477 - Average Test loss: 0.1010\n",
      "  Batch 700/938 - Training loss: 0.0776 - Average Test loss: 0.1004\n",
      "  Batch 800/938 - Training loss: 0.1195 - Average Test loss: 0.1002\n",
      "  Batch 900/938 - Training loss: 0.0603 - Average Test loss: 0.1013\n",
      "Epoch = 119\n",
      "  Batch 0/938 - Training loss: 0.0826 - Average Test loss: 0.1002\n",
      "  Batch 100/938 - Training loss: 0.1425 - Average Test loss: 0.1008\n",
      "  Batch 200/938 - Training loss: 0.1119 - Average Test loss: 0.1002\n",
      "  Batch 300/938 - Training loss: 0.0447 - Average Test loss: 0.1005\n",
      "  Batch 400/938 - Training loss: 0.0570 - Average Test loss: 0.1013\n",
      "  Batch 500/938 - Training loss: 0.1037 - Average Test loss: 0.1007\n",
      "  Batch 600/938 - Training loss: 0.0930 - Average Test loss: 0.0999\n",
      "  Batch 700/938 - Training loss: 0.1710 - Average Test loss: 0.1002\n",
      "  Batch 800/938 - Training loss: 0.0610 - Average Test loss: 0.1003\n",
      "  Batch 900/938 - Training loss: 0.0259 - Average Test loss: 0.0995\n",
      "Epoch = 120\n",
      "  Batch 0/938 - Training loss: 0.1750 - Average Test loss: 0.1001\n",
      "  Batch 100/938 - Training loss: 0.1598 - Average Test loss: 0.0995\n",
      "  Batch 200/938 - Training loss: 0.0701 - Average Test loss: 0.0999\n",
      "  Batch 300/938 - Training loss: 0.0605 - Average Test loss: 0.0996\n",
      "  Batch 400/938 - Training loss: 0.0886 - Average Test loss: 0.0999\n",
      "  Batch 500/938 - Training loss: 0.1610 - Average Test loss: 0.1002\n",
      "  Batch 600/938 - Training loss: 0.0603 - Average Test loss: 0.0994\n",
      "  Batch 700/938 - Training loss: 0.1673 - Average Test loss: 0.0991\n",
      "  Batch 800/938 - Training loss: 0.0383 - Average Test loss: 0.0993\n",
      "  Batch 900/938 - Training loss: 0.0547 - Average Test loss: 0.0999\n",
      "Epoch = 121\n",
      "  Batch 0/938 - Training loss: 0.1820 - Average Test loss: 0.0997\n",
      "  Batch 100/938 - Training loss: 0.1285 - Average Test loss: 0.0997\n",
      "  Batch 200/938 - Training loss: 0.1345 - Average Test loss: 0.0999\n",
      "  Batch 300/938 - Training loss: 0.1028 - Average Test loss: 0.0994\n",
      "  Batch 400/938 - Training loss: 0.0982 - Average Test loss: 0.0991\n",
      "  Batch 500/938 - Training loss: 0.0195 - Average Test loss: 0.0987\n",
      "  Batch 600/938 - Training loss: 0.0478 - Average Test loss: 0.0988\n",
      "  Batch 700/938 - Training loss: 0.1124 - Average Test loss: 0.0997\n",
      "  Batch 800/938 - Training loss: 0.0623 - Average Test loss: 0.0993\n",
      "  Batch 900/938 - Training loss: 0.0743 - Average Test loss: 0.0989\n",
      "Epoch = 122\n",
      "  Batch 0/938 - Training loss: 0.0238 - Average Test loss: 0.0993\n",
      "  Batch 100/938 - Training loss: 0.0260 - Average Test loss: 0.0991\n",
      "  Batch 200/938 - Training loss: 0.0996 - Average Test loss: 0.0998\n",
      "  Batch 300/938 - Training loss: 0.0605 - Average Test loss: 0.0991\n",
      "  Batch 400/938 - Training loss: 0.0563 - Average Test loss: 0.0991\n",
      "  Batch 500/938 - Training loss: 0.3792 - Average Test loss: 0.0985\n",
      "  Batch 600/938 - Training loss: 0.1032 - Average Test loss: 0.0988\n",
      "  Batch 700/938 - Training loss: 0.1516 - Average Test loss: 0.0992\n",
      "  Batch 800/938 - Training loss: 0.0404 - Average Test loss: 0.0988\n",
      "  Batch 900/938 - Training loss: 0.0857 - Average Test loss: 0.0988\n",
      "Epoch = 123\n",
      "  Batch 0/938 - Training loss: 0.0514 - Average Test loss: 0.0988\n",
      "  Batch 100/938 - Training loss: 0.1331 - Average Test loss: 0.0983\n",
      "  Batch 200/938 - Training loss: 0.0542 - Average Test loss: 0.0989\n",
      "  Batch 300/938 - Training loss: 0.0650 - Average Test loss: 0.0979\n",
      "  Batch 400/938 - Training loss: 0.0366 - Average Test loss: 0.0984\n",
      "  Batch 500/938 - Training loss: 0.0687 - Average Test loss: 0.0983\n",
      "  Batch 600/938 - Training loss: 0.2688 - Average Test loss: 0.0986\n",
      "  Batch 700/938 - Training loss: 0.0221 - Average Test loss: 0.0986\n",
      "  Batch 800/938 - Training loss: 0.1950 - Average Test loss: 0.0979\n",
      "  Batch 900/938 - Training loss: 0.0294 - Average Test loss: 0.0978\n",
      "Epoch = 124\n",
      "  Batch 0/938 - Training loss: 0.1106 - Average Test loss: 0.0979\n",
      "  Batch 100/938 - Training loss: 0.2204 - Average Test loss: 0.0988\n",
      "  Batch 200/938 - Training loss: 0.0713 - Average Test loss: 0.0980\n",
      "  Batch 300/938 - Training loss: 0.0945 - Average Test loss: 0.0978\n",
      "  Batch 400/938 - Training loss: 0.1643 - Average Test loss: 0.0978\n",
      "  Batch 500/938 - Training loss: 0.1086 - Average Test loss: 0.0997\n",
      "  Batch 600/938 - Training loss: 0.1214 - Average Test loss: 0.0986\n",
      "  Batch 700/938 - Training loss: 0.1114 - Average Test loss: 0.0974\n",
      "  Batch 800/938 - Training loss: 0.2112 - Average Test loss: 0.0979\n",
      "  Batch 900/938 - Training loss: 0.1208 - Average Test loss: 0.0973\n",
      "Epoch = 125\n",
      "  Batch 0/938 - Training loss: 0.1226 - Average Test loss: 0.0980\n",
      "  Batch 100/938 - Training loss: 0.0267 - Average Test loss: 0.0976\n",
      "  Batch 200/938 - Training loss: 0.0909 - Average Test loss: 0.0971\n",
      "  Batch 300/938 - Training loss: 0.1486 - Average Test loss: 0.0971\n",
      "  Batch 400/938 - Training loss: 0.0629 - Average Test loss: 0.0977\n",
      "  Batch 500/938 - Training loss: 0.1217 - Average Test loss: 0.0987\n",
      "  Batch 600/938 - Training loss: 0.0497 - Average Test loss: 0.0976\n",
      "  Batch 700/938 - Training loss: 0.0732 - Average Test loss: 0.0978\n",
      "  Batch 800/938 - Training loss: 0.0595 - Average Test loss: 0.0983\n",
      "  Batch 900/938 - Training loss: 0.1357 - Average Test loss: 0.0975\n",
      "Epoch = 126\n",
      "  Batch 0/938 - Training loss: 0.1188 - Average Test loss: 0.0980\n",
      "  Batch 100/938 - Training loss: 0.0710 - Average Test loss: 0.0974\n",
      "  Batch 200/938 - Training loss: 0.1550 - Average Test loss: 0.0976\n",
      "  Batch 300/938 - Training loss: 0.1222 - Average Test loss: 0.0968\n",
      "  Batch 400/938 - Training loss: 0.0888 - Average Test loss: 0.0966\n",
      "  Batch 500/938 - Training loss: 0.0825 - Average Test loss: 0.0968\n",
      "  Batch 600/938 - Training loss: 0.0324 - Average Test loss: 0.0969\n",
      "  Batch 700/938 - Training loss: 0.0543 - Average Test loss: 0.0975\n",
      "  Batch 800/938 - Training loss: 0.1210 - Average Test loss: 0.0973\n",
      "  Batch 900/938 - Training loss: 0.0288 - Average Test loss: 0.0969\n",
      "Epoch = 127\n",
      "  Batch 0/938 - Training loss: 0.0919 - Average Test loss: 0.0970\n",
      "  Batch 100/938 - Training loss: 0.0746 - Average Test loss: 0.0975\n",
      "  Batch 200/938 - Training loss: 0.0906 - Average Test loss: 0.0986\n",
      "  Batch 300/938 - Training loss: 0.0564 - Average Test loss: 0.0971\n",
      "  Batch 400/938 - Training loss: 0.0447 - Average Test loss: 0.0963\n",
      "  Batch 500/938 - Training loss: 0.0787 - Average Test loss: 0.0968\n",
      "  Batch 600/938 - Training loss: 0.0332 - Average Test loss: 0.0964\n",
      "  Batch 700/938 - Training loss: 0.2097 - Average Test loss: 0.0967\n",
      "  Batch 800/938 - Training loss: 0.0622 - Average Test loss: 0.0959\n",
      "  Batch 900/938 - Training loss: 0.0470 - Average Test loss: 0.0960\n",
      "Epoch = 128\n",
      "  Batch 0/938 - Training loss: 0.0457 - Average Test loss: 0.0964\n",
      "  Batch 100/938 - Training loss: 0.0688 - Average Test loss: 0.0960\n",
      "  Batch 200/938 - Training loss: 0.1049 - Average Test loss: 0.0961\n",
      "  Batch 300/938 - Training loss: 0.0511 - Average Test loss: 0.0964\n",
      "  Batch 400/938 - Training loss: 0.0706 - Average Test loss: 0.0970\n",
      "  Batch 500/938 - Training loss: 0.0578 - Average Test loss: 0.0963\n",
      "  Batch 600/938 - Training loss: 0.0620 - Average Test loss: 0.0958\n",
      "  Batch 700/938 - Training loss: 0.1320 - Average Test loss: 0.0962\n",
      "  Batch 800/938 - Training loss: 0.0943 - Average Test loss: 0.0953\n",
      "  Batch 900/938 - Training loss: 0.0318 - Average Test loss: 0.0960\n",
      "Epoch = 129\n",
      "  Batch 0/938 - Training loss: 0.0468 - Average Test loss: 0.0960\n",
      "  Batch 100/938 - Training loss: 0.0492 - Average Test loss: 0.0960\n",
      "  Batch 200/938 - Training loss: 0.1548 - Average Test loss: 0.0961\n",
      "  Batch 300/938 - Training loss: 0.0703 - Average Test loss: 0.0959\n",
      "  Batch 400/938 - Training loss: 0.2247 - Average Test loss: 0.0962\n",
      "  Batch 500/938 - Training loss: 0.0512 - Average Test loss: 0.0955\n",
      "  Batch 600/938 - Training loss: 0.0450 - Average Test loss: 0.0956\n",
      "  Batch 700/938 - Training loss: 0.0720 - Average Test loss: 0.0956\n",
      "  Batch 800/938 - Training loss: 0.1915 - Average Test loss: 0.0955\n",
      "  Batch 900/938 - Training loss: 0.0282 - Average Test loss: 0.0955\n",
      "Epoch = 130\n",
      "  Batch 0/938 - Training loss: 0.0651 - Average Test loss: 0.0955\n",
      "  Batch 100/938 - Training loss: 0.1144 - Average Test loss: 0.0953\n",
      "  Batch 200/938 - Training loss: 0.0462 - Average Test loss: 0.0957\n",
      "  Batch 300/938 - Training loss: 0.0935 - Average Test loss: 0.0954\n",
      "  Batch 400/938 - Training loss: 0.0448 - Average Test loss: 0.0954\n",
      "  Batch 500/938 - Training loss: 0.0347 - Average Test loss: 0.0953\n",
      "  Batch 600/938 - Training loss: 0.1972 - Average Test loss: 0.0950\n",
      "  Batch 700/938 - Training loss: 0.0571 - Average Test loss: 0.0946\n",
      "  Batch 800/938 - Training loss: 0.0302 - Average Test loss: 0.0957\n",
      "  Batch 900/938 - Training loss: 0.1608 - Average Test loss: 0.0954\n",
      "Epoch = 131\n",
      "  Batch 0/938 - Training loss: 0.1306 - Average Test loss: 0.0946\n",
      "  Batch 100/938 - Training loss: 0.0217 - Average Test loss: 0.0949\n",
      "  Batch 200/938 - Training loss: 0.0281 - Average Test loss: 0.0957\n",
      "  Batch 300/938 - Training loss: 0.0575 - Average Test loss: 0.0955\n",
      "  Batch 400/938 - Training loss: 0.0339 - Average Test loss: 0.0948\n",
      "  Batch 500/938 - Training loss: 0.1209 - Average Test loss: 0.0951\n",
      "  Batch 600/938 - Training loss: 0.2019 - Average Test loss: 0.0950\n",
      "  Batch 700/938 - Training loss: 0.0277 - Average Test loss: 0.0948\n",
      "  Batch 800/938 - Training loss: 0.0667 - Average Test loss: 0.0944\n",
      "  Batch 900/938 - Training loss: 0.0550 - Average Test loss: 0.0942\n",
      "Epoch = 132\n",
      "  Batch 0/938 - Training loss: 0.0276 - Average Test loss: 0.0941\n",
      "  Batch 100/938 - Training loss: 0.0149 - Average Test loss: 0.0957\n",
      "  Batch 200/938 - Training loss: 0.0332 - Average Test loss: 0.0953\n",
      "  Batch 300/938 - Training loss: 0.1031 - Average Test loss: 0.0944\n",
      "  Batch 400/938 - Training loss: 0.0421 - Average Test loss: 0.0941\n",
      "  Batch 500/938 - Training loss: 0.0934 - Average Test loss: 0.0951\n",
      "  Batch 600/938 - Training loss: 0.0520 - Average Test loss: 0.0944\n",
      "  Batch 700/938 - Training loss: 0.0866 - Average Test loss: 0.0940\n",
      "  Batch 800/938 - Training loss: 0.0952 - Average Test loss: 0.0943\n",
      "  Batch 900/938 - Training loss: 0.0647 - Average Test loss: 0.0943\n",
      "Epoch = 133\n",
      "  Batch 0/938 - Training loss: 0.0734 - Average Test loss: 0.0950\n",
      "  Batch 100/938 - Training loss: 0.0675 - Average Test loss: 0.0938\n",
      "  Batch 200/938 - Training loss: 0.0515 - Average Test loss: 0.0943\n",
      "  Batch 300/938 - Training loss: 0.0657 - Average Test loss: 0.0940\n",
      "  Batch 400/938 - Training loss: 0.0550 - Average Test loss: 0.0940\n",
      "  Batch 500/938 - Training loss: 0.0628 - Average Test loss: 0.0940\n",
      "  Batch 600/938 - Training loss: 0.0259 - Average Test loss: 0.0938\n",
      "  Batch 700/938 - Training loss: 0.1404 - Average Test loss: 0.0935\n",
      "  Batch 800/938 - Training loss: 0.0653 - Average Test loss: 0.0940\n",
      "  Batch 900/938 - Training loss: 0.0529 - Average Test loss: 0.0941\n",
      "Epoch = 134\n",
      "  Batch 0/938 - Training loss: 0.0676 - Average Test loss: 0.0938\n",
      "  Batch 100/938 - Training loss: 0.0570 - Average Test loss: 0.0943\n",
      "  Batch 200/938 - Training loss: 0.0393 - Average Test loss: 0.0935\n",
      "  Batch 300/938 - Training loss: 0.0530 - Average Test loss: 0.0936\n",
      "  Batch 400/938 - Training loss: 0.0338 - Average Test loss: 0.0938\n",
      "  Batch 500/938 - Training loss: 0.1544 - Average Test loss: 0.0933\n",
      "  Batch 600/938 - Training loss: 0.0462 - Average Test loss: 0.0937\n",
      "  Batch 700/938 - Training loss: 0.0208 - Average Test loss: 0.0930\n",
      "  Batch 800/938 - Training loss: 0.0606 - Average Test loss: 0.0933\n",
      "  Batch 900/938 - Training loss: 0.0328 - Average Test loss: 0.0937\n",
      "Epoch = 135\n",
      "  Batch 0/938 - Training loss: 0.0768 - Average Test loss: 0.0940\n",
      "  Batch 100/938 - Training loss: 0.0846 - Average Test loss: 0.0932\n",
      "  Batch 200/938 - Training loss: 0.0200 - Average Test loss: 0.0936\n",
      "  Batch 300/938 - Training loss: 0.0338 - Average Test loss: 0.0938\n",
      "  Batch 400/938 - Training loss: 0.2157 - Average Test loss: 0.0933\n",
      "  Batch 500/938 - Training loss: 0.1926 - Average Test loss: 0.0932\n",
      "  Batch 600/938 - Training loss: 0.2415 - Average Test loss: 0.0931\n",
      "  Batch 700/938 - Training loss: 0.0740 - Average Test loss: 0.0933\n",
      "  Batch 800/938 - Training loss: 0.2443 - Average Test loss: 0.0940\n",
      "  Batch 900/938 - Training loss: 0.0416 - Average Test loss: 0.0930\n",
      "Epoch = 136\n",
      "  Batch 0/938 - Training loss: 0.0353 - Average Test loss: 0.0933\n",
      "  Batch 100/938 - Training loss: 0.0454 - Average Test loss: 0.0936\n",
      "  Batch 200/938 - Training loss: 0.0337 - Average Test loss: 0.0932\n",
      "  Batch 300/938 - Training loss: 0.0507 - Average Test loss: 0.0929\n",
      "  Batch 400/938 - Training loss: 0.0776 - Average Test loss: 0.0923\n",
      "  Batch 500/938 - Training loss: 0.1032 - Average Test loss: 0.0924\n",
      "  Batch 600/938 - Training loss: 0.0812 - Average Test loss: 0.0937\n",
      "  Batch 700/938 - Training loss: 0.0227 - Average Test loss: 0.0930\n",
      "  Batch 800/938 - Training loss: 0.1741 - Average Test loss: 0.0931\n",
      "  Batch 900/938 - Training loss: 0.0544 - Average Test loss: 0.0927\n",
      "Epoch = 137\n",
      "  Batch 0/938 - Training loss: 0.0425 - Average Test loss: 0.0922\n",
      "  Batch 100/938 - Training loss: 0.0226 - Average Test loss: 0.0929\n",
      "  Batch 200/938 - Training loss: 0.0333 - Average Test loss: 0.0925\n",
      "  Batch 300/938 - Training loss: 0.1402 - Average Test loss: 0.0923\n",
      "  Batch 400/938 - Training loss: 0.0507 - Average Test loss: 0.0926\n",
      "  Batch 500/938 - Training loss: 0.0384 - Average Test loss: 0.0926\n",
      "  Batch 600/938 - Training loss: 0.1013 - Average Test loss: 0.0924\n",
      "  Batch 700/938 - Training loss: 0.1068 - Average Test loss: 0.0930\n",
      "  Batch 800/938 - Training loss: 0.0582 - Average Test loss: 0.0926\n",
      "  Batch 900/938 - Training loss: 0.0464 - Average Test loss: 0.0922\n",
      "Epoch = 138\n",
      "  Batch 0/938 - Training loss: 0.1079 - Average Test loss: 0.0922\n",
      "  Batch 100/938 - Training loss: 0.0497 - Average Test loss: 0.0924\n",
      "  Batch 200/938 - Training loss: 0.0952 - Average Test loss: 0.0930\n",
      "  Batch 300/938 - Training loss: 0.0745 - Average Test loss: 0.0926\n",
      "  Batch 400/938 - Training loss: 0.0720 - Average Test loss: 0.0921\n",
      "  Batch 500/938 - Training loss: 0.0401 - Average Test loss: 0.0917\n",
      "  Batch 600/938 - Training loss: 0.0679 - Average Test loss: 0.0921\n",
      "  Batch 700/938 - Training loss: 0.0390 - Average Test loss: 0.0917\n",
      "  Batch 800/938 - Training loss: 0.0340 - Average Test loss: 0.0918\n",
      "  Batch 900/938 - Training loss: 0.1187 - Average Test loss: 0.0917\n",
      "Epoch = 139\n",
      "  Batch 0/938 - Training loss: 0.0723 - Average Test loss: 0.0914\n",
      "  Batch 100/938 - Training loss: 0.0536 - Average Test loss: 0.0920\n",
      "  Batch 200/938 - Training loss: 0.0423 - Average Test loss: 0.0920\n",
      "  Batch 300/938 - Training loss: 0.0528 - Average Test loss: 0.0921\n",
      "  Batch 400/938 - Training loss: 0.0685 - Average Test loss: 0.0918\n",
      "  Batch 500/938 - Training loss: 0.0459 - Average Test loss: 0.0916\n",
      "  Batch 600/938 - Training loss: 0.0738 - Average Test loss: 0.0914\n",
      "  Batch 700/938 - Training loss: 0.0414 - Average Test loss: 0.0920\n",
      "  Batch 800/938 - Training loss: 0.1356 - Average Test loss: 0.0913\n",
      "  Batch 900/938 - Training loss: 0.1967 - Average Test loss: 0.0915\n",
      "Epoch = 140\n",
      "  Batch 0/938 - Training loss: 0.0631 - Average Test loss: 0.0917\n",
      "  Batch 100/938 - Training loss: 0.1006 - Average Test loss: 0.0913\n",
      "  Batch 200/938 - Training loss: 0.0632 - Average Test loss: 0.0916\n",
      "  Batch 300/938 - Training loss: 0.0623 - Average Test loss: 0.0912\n",
      "  Batch 400/938 - Training loss: 0.1134 - Average Test loss: 0.0912\n",
      "  Batch 500/938 - Training loss: 0.0440 - Average Test loss: 0.0915\n",
      "  Batch 600/938 - Training loss: 0.0856 - Average Test loss: 0.0913\n",
      "  Batch 700/938 - Training loss: 0.0220 - Average Test loss: 0.0915\n",
      "  Batch 800/938 - Training loss: 0.0490 - Average Test loss: 0.0919\n",
      "  Batch 900/938 - Training loss: 0.1201 - Average Test loss: 0.0920\n",
      "Epoch = 141\n",
      "  Batch 0/938 - Training loss: 0.0376 - Average Test loss: 0.0909\n",
      "  Batch 100/938 - Training loss: 0.0392 - Average Test loss: 0.0910\n",
      "  Batch 200/938 - Training loss: 0.0229 - Average Test loss: 0.0906\n",
      "  Batch 300/938 - Training loss: 0.0757 - Average Test loss: 0.0909\n",
      "  Batch 400/938 - Training loss: 0.0226 - Average Test loss: 0.0911\n",
      "  Batch 500/938 - Training loss: 0.1228 - Average Test loss: 0.0914\n",
      "  Batch 600/938 - Training loss: 0.0664 - Average Test loss: 0.0909\n",
      "  Batch 700/938 - Training loss: 0.0865 - Average Test loss: 0.0911\n",
      "  Batch 800/938 - Training loss: 0.0741 - Average Test loss: 0.0911\n",
      "  Batch 900/938 - Training loss: 0.1478 - Average Test loss: 0.0909\n",
      "Epoch = 142\n",
      "  Batch 0/938 - Training loss: 0.0896 - Average Test loss: 0.0910\n",
      "  Batch 100/938 - Training loss: 0.1237 - Average Test loss: 0.0901\n",
      "  Batch 200/938 - Training loss: 0.0388 - Average Test loss: 0.0902\n",
      "  Batch 300/938 - Training loss: 0.0361 - Average Test loss: 0.0901\n",
      "  Batch 400/938 - Training loss: 0.1148 - Average Test loss: 0.0907\n",
      "  Batch 500/938 - Training loss: 0.0216 - Average Test loss: 0.0909\n",
      "  Batch 600/938 - Training loss: 0.0740 - Average Test loss: 0.0918\n",
      "  Batch 700/938 - Training loss: 0.0874 - Average Test loss: 0.0902\n",
      "  Batch 800/938 - Training loss: 0.0439 - Average Test loss: 0.0902\n",
      "  Batch 900/938 - Training loss: 0.0703 - Average Test loss: 0.0902\n",
      "Epoch = 143\n",
      "  Batch 0/938 - Training loss: 0.0402 - Average Test loss: 0.0901\n",
      "  Batch 100/938 - Training loss: 0.0348 - Average Test loss: 0.0904\n",
      "  Batch 200/938 - Training loss: 0.0528 - Average Test loss: 0.0900\n",
      "  Batch 300/938 - Training loss: 0.0647 - Average Test loss: 0.0905\n",
      "  Batch 400/938 - Training loss: 0.0918 - Average Test loss: 0.0902\n",
      "  Batch 500/938 - Training loss: 0.0570 - Average Test loss: 0.0900\n",
      "  Batch 600/938 - Training loss: 0.0536 - Average Test loss: 0.0904\n",
      "  Batch 700/938 - Training loss: 0.0226 - Average Test loss: 0.0905\n",
      "  Batch 800/938 - Training loss: 0.0684 - Average Test loss: 0.0897\n",
      "  Batch 900/938 - Training loss: 0.0599 - Average Test loss: 0.0899\n",
      "Epoch = 144\n",
      "  Batch 0/938 - Training loss: 0.0292 - Average Test loss: 0.0901\n",
      "  Batch 100/938 - Training loss: 0.0638 - Average Test loss: 0.0901\n",
      "  Batch 200/938 - Training loss: 0.0445 - Average Test loss: 0.0904\n",
      "  Batch 300/938 - Training loss: 0.0694 - Average Test loss: 0.0902\n",
      "  Batch 400/938 - Training loss: 0.0583 - Average Test loss: 0.0907\n",
      "  Batch 500/938 - Training loss: 0.0231 - Average Test loss: 0.0901\n",
      "  Batch 600/938 - Training loss: 0.0792 - Average Test loss: 0.0897\n",
      "  Batch 700/938 - Training loss: 0.0219 - Average Test loss: 0.0904\n",
      "  Batch 800/938 - Training loss: 0.0604 - Average Test loss: 0.0896\n",
      "  Batch 900/938 - Training loss: 0.0788 - Average Test loss: 0.0894\n",
      "Epoch = 145\n",
      "  Batch 0/938 - Training loss: 0.0387 - Average Test loss: 0.0896\n",
      "  Batch 100/938 - Training loss: 0.0417 - Average Test loss: 0.0902\n",
      "  Batch 200/938 - Training loss: 0.0798 - Average Test loss: 0.0903\n",
      "  Batch 300/938 - Training loss: 0.0944 - Average Test loss: 0.0901\n",
      "  Batch 400/938 - Training loss: 0.0810 - Average Test loss: 0.0903\n",
      "  Batch 500/938 - Training loss: 0.0475 - Average Test loss: 0.0898\n",
      "  Batch 600/938 - Training loss: 0.0423 - Average Test loss: 0.0901\n",
      "  Batch 700/938 - Training loss: 0.1673 - Average Test loss: 0.0897\n",
      "  Batch 800/938 - Training loss: 0.0372 - Average Test loss: 0.0894\n",
      "  Batch 900/938 - Training loss: 0.0680 - Average Test loss: 0.0890\n",
      "Epoch = 146\n",
      "  Batch 0/938 - Training loss: 0.1466 - Average Test loss: 0.0890\n",
      "  Batch 100/938 - Training loss: 0.0264 - Average Test loss: 0.0891\n",
      "  Batch 200/938 - Training loss: 0.0505 - Average Test loss: 0.0891\n",
      "  Batch 300/938 - Training loss: 0.1062 - Average Test loss: 0.0898\n",
      "  Batch 400/938 - Training loss: 0.0259 - Average Test loss: 0.0895\n",
      "  Batch 500/938 - Training loss: 0.1081 - Average Test loss: 0.0894\n",
      "  Batch 600/938 - Training loss: 0.0913 - Average Test loss: 0.0891\n",
      "  Batch 700/938 - Training loss: 0.0339 - Average Test loss: 0.0893\n",
      "  Batch 800/938 - Training loss: 0.0954 - Average Test loss: 0.0892\n",
      "  Batch 900/938 - Training loss: 0.0405 - Average Test loss: 0.0894\n",
      "Epoch = 147\n",
      "  Batch 0/938 - Training loss: 0.0648 - Average Test loss: 0.0886\n",
      "  Batch 100/938 - Training loss: 0.0698 - Average Test loss: 0.0890\n",
      "  Batch 200/938 - Training loss: 0.0377 - Average Test loss: 0.0887\n",
      "  Batch 300/938 - Training loss: 0.0314 - Average Test loss: 0.0885\n",
      "  Batch 400/938 - Training loss: 0.1387 - Average Test loss: 0.0889\n",
      "  Batch 500/938 - Training loss: 0.1024 - Average Test loss: 0.0896\n",
      "  Batch 600/938 - Training loss: 0.0624 - Average Test loss: 0.0888\n",
      "  Batch 700/938 - Training loss: 0.0405 - Average Test loss: 0.0889\n",
      "  Batch 800/938 - Training loss: 0.0829 - Average Test loss: 0.0887\n",
      "  Batch 900/938 - Training loss: 0.1492 - Average Test loss: 0.0893\n",
      "Epoch = 148\n",
      "  Batch 0/938 - Training loss: 0.0486 - Average Test loss: 0.0892\n",
      "  Batch 100/938 - Training loss: 0.0256 - Average Test loss: 0.0894\n",
      "  Batch 200/938 - Training loss: 0.1732 - Average Test loss: 0.0889\n",
      "  Batch 300/938 - Training loss: 0.0645 - Average Test loss: 0.0888\n",
      "  Batch 400/938 - Training loss: 0.0775 - Average Test loss: 0.0892\n",
      "  Batch 500/938 - Training loss: 0.0285 - Average Test loss: 0.0889\n",
      "  Batch 600/938 - Training loss: 0.0573 - Average Test loss: 0.0891\n",
      "  Batch 700/938 - Training loss: 0.1186 - Average Test loss: 0.0888\n",
      "  Batch 800/938 - Training loss: 0.0790 - Average Test loss: 0.0890\n",
      "  Batch 900/938 - Training loss: 0.0450 - Average Test loss: 0.0884\n",
      "Epoch = 149\n",
      "  Batch 0/938 - Training loss: 0.0282 - Average Test loss: 0.0890\n",
      "  Batch 100/938 - Training loss: 0.0331 - Average Test loss: 0.0881\n",
      "  Batch 200/938 - Training loss: 0.0300 - Average Test loss: 0.0881\n",
      "  Batch 300/938 - Training loss: 0.0390 - Average Test loss: 0.0879\n",
      "  Batch 400/938 - Training loss: 0.0230 - Average Test loss: 0.0882\n",
      "  Batch 500/938 - Training loss: 0.0281 - Average Test loss: 0.0882\n",
      "  Batch 600/938 - Training loss: 0.0736 - Average Test loss: 0.0891\n",
      "  Batch 700/938 - Training loss: 0.0661 - Average Test loss: 0.0883\n",
      "  Batch 800/938 - Training loss: 0.0531 - Average Test loss: 0.0879\n",
      "  Batch 900/938 - Training loss: 0.0752 - Average Test loss: 0.0884\n",
      "Epoch = 150\n",
      "  Batch 0/938 - Training loss: 0.0794 - Average Test loss: 0.0888\n",
      "  Batch 100/938 - Training loss: 0.0168 - Average Test loss: 0.0880\n",
      "  Batch 200/938 - Training loss: 0.0497 - Average Test loss: 0.0877\n",
      "  Batch 300/938 - Training loss: 0.0367 - Average Test loss: 0.0881\n",
      "  Batch 400/938 - Training loss: 0.1531 - Average Test loss: 0.0885\n",
      "  Batch 500/938 - Training loss: 0.0606 - Average Test loss: 0.0881\n",
      "  Batch 600/938 - Training loss: 0.0774 - Average Test loss: 0.0879\n",
      "  Batch 700/938 - Training loss: 0.0148 - Average Test loss: 0.0879\n",
      "  Batch 800/938 - Training loss: 0.0314 - Average Test loss: 0.0880\n",
      "  Batch 900/938 - Training loss: 0.1268 - Average Test loss: 0.0881\n",
      "Epoch = 151\n",
      "  Batch 0/938 - Training loss: 0.0449 - Average Test loss: 0.0885\n",
      "  Batch 100/938 - Training loss: 0.0564 - Average Test loss: 0.0878\n",
      "  Batch 200/938 - Training loss: 0.0306 - Average Test loss: 0.0876\n",
      "  Batch 300/938 - Training loss: 0.0839 - Average Test loss: 0.0883\n",
      "  Batch 400/938 - Training loss: 0.0183 - Average Test loss: 0.0881\n",
      "  Batch 500/938 - Training loss: 0.0846 - Average Test loss: 0.0875\n",
      "  Batch 600/938 - Training loss: 0.0829 - Average Test loss: 0.0873\n",
      "  Batch 700/938 - Training loss: 0.0327 - Average Test loss: 0.0875\n",
      "  Batch 800/938 - Training loss: 0.0703 - Average Test loss: 0.0879\n",
      "  Batch 900/938 - Training loss: 0.0748 - Average Test loss: 0.0875\n",
      "Epoch = 152\n",
      "  Batch 0/938 - Training loss: 0.0560 - Average Test loss: 0.0878\n",
      "  Batch 100/938 - Training loss: 0.0417 - Average Test loss: 0.0870\n",
      "  Batch 200/938 - Training loss: 0.0481 - Average Test loss: 0.0876\n",
      "  Batch 300/938 - Training loss: 0.0584 - Average Test loss: 0.0882\n",
      "  Batch 400/938 - Training loss: 0.0820 - Average Test loss: 0.0873\n",
      "  Batch 500/938 - Training loss: 0.0855 - Average Test loss: 0.0875\n",
      "  Batch 600/938 - Training loss: 0.0734 - Average Test loss: 0.0874\n",
      "  Batch 700/938 - Training loss: 0.0293 - Average Test loss: 0.0875\n",
      "  Batch 800/938 - Training loss: 0.0734 - Average Test loss: 0.0871\n",
      "  Batch 900/938 - Training loss: 0.1436 - Average Test loss: 0.0880\n",
      "Epoch = 153\n",
      "  Batch 0/938 - Training loss: 0.0848 - Average Test loss: 0.0872\n",
      "  Batch 100/938 - Training loss: 0.1371 - Average Test loss: 0.0879\n",
      "  Batch 200/938 - Training loss: 0.0605 - Average Test loss: 0.0873\n",
      "  Batch 300/938 - Training loss: 0.0338 - Average Test loss: 0.0871\n",
      "  Batch 400/938 - Training loss: 0.0523 - Average Test loss: 0.0870\n",
      "  Batch 500/938 - Training loss: 0.0414 - Average Test loss: 0.0872\n",
      "  Batch 600/938 - Training loss: 0.1075 - Average Test loss: 0.0870\n",
      "  Batch 700/938 - Training loss: 0.0157 - Average Test loss: 0.0880\n",
      "  Batch 800/938 - Training loss: 0.0461 - Average Test loss: 0.0877\n",
      "  Batch 900/938 - Training loss: 0.0143 - Average Test loss: 0.0873\n",
      "Epoch = 154\n",
      "  Batch 0/938 - Training loss: 0.0369 - Average Test loss: 0.0871\n",
      "  Batch 100/938 - Training loss: 0.0766 - Average Test loss: 0.0867\n",
      "  Batch 200/938 - Training loss: 0.0399 - Average Test loss: 0.0870\n",
      "  Batch 300/938 - Training loss: 0.1516 - Average Test loss: 0.0867\n",
      "  Batch 400/938 - Training loss: 0.0349 - Average Test loss: 0.0868\n",
      "  Batch 500/938 - Training loss: 0.0291 - Average Test loss: 0.0875\n",
      "  Batch 600/938 - Training loss: 0.1154 - Average Test loss: 0.0869\n",
      "  Batch 700/938 - Training loss: 0.0820 - Average Test loss: 0.0869\n",
      "  Batch 800/938 - Training loss: 0.0632 - Average Test loss: 0.0862\n",
      "  Batch 900/938 - Training loss: 0.0583 - Average Test loss: 0.0867\n",
      "Epoch = 155\n",
      "  Batch 0/938 - Training loss: 0.0315 - Average Test loss: 0.0864\n",
      "  Batch 100/938 - Training loss: 0.0218 - Average Test loss: 0.0868\n",
      "  Batch 200/938 - Training loss: 0.0666 - Average Test loss: 0.0863\n",
      "  Batch 300/938 - Training loss: 0.0759 - Average Test loss: 0.0864\n",
      "  Batch 400/938 - Training loss: 0.0363 - Average Test loss: 0.0863\n",
      "  Batch 500/938 - Training loss: 0.0588 - Average Test loss: 0.0864\n",
      "  Batch 600/938 - Training loss: 0.0409 - Average Test loss: 0.0866\n",
      "  Batch 700/938 - Training loss: 0.0285 - Average Test loss: 0.0861\n",
      "  Batch 800/938 - Training loss: 0.0891 - Average Test loss: 0.0863\n",
      "  Batch 900/938 - Training loss: 0.0563 - Average Test loss: 0.0864\n",
      "Epoch = 156\n",
      "  Batch 0/938 - Training loss: 0.0730 - Average Test loss: 0.0865\n",
      "  Batch 100/938 - Training loss: 0.0249 - Average Test loss: 0.0870\n",
      "  Batch 200/938 - Training loss: 0.0452 - Average Test loss: 0.0865\n",
      "  Batch 300/938 - Training loss: 0.0941 - Average Test loss: 0.0863\n",
      "  Batch 400/938 - Training loss: 0.0688 - Average Test loss: 0.0863\n",
      "  Batch 500/938 - Training loss: 0.0258 - Average Test loss: 0.0870\n",
      "  Batch 600/938 - Training loss: 0.0243 - Average Test loss: 0.0864\n",
      "  Batch 700/938 - Training loss: 0.0538 - Average Test loss: 0.0862\n",
      "  Batch 800/938 - Training loss: 0.0336 - Average Test loss: 0.0859\n",
      "  Batch 900/938 - Training loss: 0.0376 - Average Test loss: 0.0859\n",
      "Epoch = 157\n",
      "  Batch 0/938 - Training loss: 0.0527 - Average Test loss: 0.0858\n",
      "  Batch 100/938 - Training loss: 0.0947 - Average Test loss: 0.0861\n",
      "  Batch 200/938 - Training loss: 0.0595 - Average Test loss: 0.0855\n",
      "  Batch 300/938 - Training loss: 0.0553 - Average Test loss: 0.0865\n",
      "  Batch 400/938 - Training loss: 0.1221 - Average Test loss: 0.0854\n",
      "  Batch 500/938 - Training loss: 0.0414 - Average Test loss: 0.0857\n",
      "  Batch 600/938 - Training loss: 0.0890 - Average Test loss: 0.0859\n",
      "  Batch 700/938 - Training loss: 0.0679 - Average Test loss: 0.0861\n",
      "  Batch 800/938 - Training loss: 0.2085 - Average Test loss: 0.0855\n",
      "  Batch 900/938 - Training loss: 0.0149 - Average Test loss: 0.0857\n",
      "Epoch = 158\n",
      "  Batch 0/938 - Training loss: 0.0089 - Average Test loss: 0.0861\n",
      "  Batch 100/938 - Training loss: 0.0181 - Average Test loss: 0.0861\n",
      "  Batch 200/938 - Training loss: 0.0385 - Average Test loss: 0.0859\n",
      "  Batch 300/938 - Training loss: 0.0641 - Average Test loss: 0.0853\n",
      "  Batch 400/938 - Training loss: 0.0867 - Average Test loss: 0.0855\n",
      "  Batch 500/938 - Training loss: 0.0526 - Average Test loss: 0.0858\n",
      "  Batch 600/938 - Training loss: 0.0502 - Average Test loss: 0.0859\n",
      "  Batch 700/938 - Training loss: 0.1397 - Average Test loss: 0.0857\n",
      "  Batch 800/938 - Training loss: 0.0769 - Average Test loss: 0.0854\n",
      "  Batch 900/938 - Training loss: 0.0305 - Average Test loss: 0.0860\n",
      "Epoch = 159\n",
      "  Batch 0/938 - Training loss: 0.0327 - Average Test loss: 0.0857\n",
      "  Batch 100/938 - Training loss: 0.0449 - Average Test loss: 0.0852\n",
      "  Batch 200/938 - Training loss: 0.0756 - Average Test loss: 0.0854\n",
      "  Batch 300/938 - Training loss: 0.0625 - Average Test loss: 0.0857\n",
      "  Batch 400/938 - Training loss: 0.0726 - Average Test loss: 0.0864\n",
      "  Batch 500/938 - Training loss: 0.0230 - Average Test loss: 0.0854\n",
      "  Batch 600/938 - Training loss: 0.1112 - Average Test loss: 0.0851\n",
      "  Batch 700/938 - Training loss: 0.1802 - Average Test loss: 0.0855\n",
      "  Batch 800/938 - Training loss: 0.0212 - Average Test loss: 0.0851\n",
      "  Batch 900/938 - Training loss: 0.0452 - Average Test loss: 0.0850\n",
      "Epoch = 160\n",
      "  Batch 0/938 - Training loss: 0.0260 - Average Test loss: 0.0849\n",
      "  Batch 100/938 - Training loss: 0.0738 - Average Test loss: 0.0855\n",
      "  Batch 200/938 - Training loss: 0.0249 - Average Test loss: 0.0853\n",
      "  Batch 300/938 - Training loss: 0.1168 - Average Test loss: 0.0855\n",
      "  Batch 400/938 - Training loss: 0.0270 - Average Test loss: 0.0847\n",
      "  Batch 500/938 - Training loss: 0.0264 - Average Test loss: 0.0855\n",
      "  Batch 600/938 - Training loss: 0.1111 - Average Test loss: 0.0853\n",
      "  Batch 700/938 - Training loss: 0.1186 - Average Test loss: 0.0852\n",
      "  Batch 800/938 - Training loss: 0.0439 - Average Test loss: 0.0850\n",
      "  Batch 900/938 - Training loss: 0.1507 - Average Test loss: 0.0847\n",
      "Epoch = 161\n",
      "  Batch 0/938 - Training loss: 0.0407 - Average Test loss: 0.0844\n",
      "  Batch 100/938 - Training loss: 0.0088 - Average Test loss: 0.0847\n",
      "  Batch 200/938 - Training loss: 0.0493 - Average Test loss: 0.0848\n",
      "  Batch 300/938 - Training loss: 0.0401 - Average Test loss: 0.0852\n",
      "  Batch 400/938 - Training loss: 0.0186 - Average Test loss: 0.0860\n",
      "  Batch 500/938 - Training loss: 0.0721 - Average Test loss: 0.0849\n",
      "  Batch 600/938 - Training loss: 0.0592 - Average Test loss: 0.0852\n",
      "  Batch 700/938 - Training loss: 0.0470 - Average Test loss: 0.0843\n",
      "  Batch 800/938 - Training loss: 0.0373 - Average Test loss: 0.0843\n",
      "  Batch 900/938 - Training loss: 0.0541 - Average Test loss: 0.0846\n",
      "Epoch = 162\n",
      "  Batch 0/938 - Training loss: 0.0954 - Average Test loss: 0.0853\n",
      "  Batch 100/938 - Training loss: 0.0261 - Average Test loss: 0.0847\n",
      "  Batch 200/938 - Training loss: 0.0278 - Average Test loss: 0.0848\n",
      "  Batch 300/938 - Training loss: 0.0950 - Average Test loss: 0.0842\n",
      "  Batch 400/938 - Training loss: 0.0263 - Average Test loss: 0.0838\n",
      "  Batch 500/938 - Training loss: 0.0842 - Average Test loss: 0.0844\n",
      "  Batch 600/938 - Training loss: 0.0480 - Average Test loss: 0.0840\n",
      "  Batch 700/938 - Training loss: 0.0637 - Average Test loss: 0.0841\n",
      "  Batch 800/938 - Training loss: 0.0419 - Average Test loss: 0.0846\n",
      "  Batch 900/938 - Training loss: 0.0516 - Average Test loss: 0.0843\n",
      "Epoch = 163\n",
      "  Batch 0/938 - Training loss: 0.0521 - Average Test loss: 0.0845\n",
      "  Batch 100/938 - Training loss: 0.0169 - Average Test loss: 0.0842\n",
      "  Batch 200/938 - Training loss: 0.0410 - Average Test loss: 0.0841\n",
      "  Batch 300/938 - Training loss: 0.0559 - Average Test loss: 0.0846\n",
      "  Batch 400/938 - Training loss: 0.0429 - Average Test loss: 0.0849\n",
      "  Batch 500/938 - Training loss: 0.0349 - Average Test loss: 0.0840\n",
      "  Batch 600/938 - Training loss: 0.0375 - Average Test loss: 0.0841\n",
      "  Batch 700/938 - Training loss: 0.0377 - Average Test loss: 0.0841\n",
      "  Batch 800/938 - Training loss: 0.0316 - Average Test loss: 0.0846\n",
      "  Batch 900/938 - Training loss: 0.0337 - Average Test loss: 0.0840\n",
      "Epoch = 164\n",
      "  Batch 0/938 - Training loss: 0.0158 - Average Test loss: 0.0838\n",
      "  Batch 100/938 - Training loss: 0.0236 - Average Test loss: 0.0838\n",
      "  Batch 200/938 - Training loss: 0.0265 - Average Test loss: 0.0840\n",
      "  Batch 300/938 - Training loss: 0.0793 - Average Test loss: 0.0842\n",
      "  Batch 400/938 - Training loss: 0.0646 - Average Test loss: 0.0840\n",
      "  Batch 500/938 - Training loss: 0.0407 - Average Test loss: 0.0843\n",
      "  Batch 600/938 - Training loss: 0.0909 - Average Test loss: 0.0841\n",
      "  Batch 700/938 - Training loss: 0.0172 - Average Test loss: 0.0841\n",
      "  Batch 800/938 - Training loss: 0.0625 - Average Test loss: 0.0838\n",
      "  Batch 900/938 - Training loss: 0.0685 - Average Test loss: 0.0840\n",
      "Epoch = 165\n",
      "  Batch 0/938 - Training loss: 0.0582 - Average Test loss: 0.0835\n",
      "  Batch 100/938 - Training loss: 0.0643 - Average Test loss: 0.0833\n",
      "  Batch 200/938 - Training loss: 0.0889 - Average Test loss: 0.0841\n",
      "  Batch 300/938 - Training loss: 0.1167 - Average Test loss: 0.0838\n",
      "  Batch 400/938 - Training loss: 0.1015 - Average Test loss: 0.0840\n",
      "  Batch 500/938 - Training loss: 0.0553 - Average Test loss: 0.0842\n",
      "  Batch 600/938 - Training loss: 0.0348 - Average Test loss: 0.0846\n",
      "  Batch 700/938 - Training loss: 0.0552 - Average Test loss: 0.0836\n",
      "  Batch 800/938 - Training loss: 0.0323 - Average Test loss: 0.0841\n",
      "  Batch 900/938 - Training loss: 0.0906 - Average Test loss: 0.0836\n",
      "Epoch = 166\n",
      "  Batch 0/938 - Training loss: 0.0651 - Average Test loss: 0.0835\n",
      "  Batch 100/938 - Training loss: 0.0864 - Average Test loss: 0.0837\n",
      "  Batch 200/938 - Training loss: 0.0617 - Average Test loss: 0.0838\n",
      "  Batch 300/938 - Training loss: 0.0412 - Average Test loss: 0.0839\n",
      "  Batch 400/938 - Training loss: 0.0253 - Average Test loss: 0.0836\n",
      "  Batch 500/938 - Training loss: 0.0459 - Average Test loss: 0.0834\n",
      "  Batch 600/938 - Training loss: 0.0535 - Average Test loss: 0.0834\n",
      "  Batch 700/938 - Training loss: 0.0442 - Average Test loss: 0.0833\n",
      "  Batch 800/938 - Training loss: 0.0354 - Average Test loss: 0.0832\n",
      "  Batch 900/938 - Training loss: 0.0556 - Average Test loss: 0.0832\n",
      "Epoch = 167\n",
      "  Batch 0/938 - Training loss: 0.0112 - Average Test loss: 0.0830\n",
      "  Batch 100/938 - Training loss: 0.0594 - Average Test loss: 0.0834\n",
      "  Batch 200/938 - Training loss: 0.0525 - Average Test loss: 0.0836\n",
      "  Batch 300/938 - Training loss: 0.0126 - Average Test loss: 0.0833\n",
      "  Batch 400/938 - Training loss: 0.0475 - Average Test loss: 0.0831\n",
      "  Batch 500/938 - Training loss: 0.0447 - Average Test loss: 0.0829\n",
      "  Batch 600/938 - Training loss: 0.1569 - Average Test loss: 0.0834\n",
      "  Batch 700/938 - Training loss: 0.1317 - Average Test loss: 0.0830\n",
      "  Batch 800/938 - Training loss: 0.0389 - Average Test loss: 0.0836\n",
      "  Batch 900/938 - Training loss: 0.0376 - Average Test loss: 0.0833\n",
      "Epoch = 168\n",
      "  Batch 0/938 - Training loss: 0.0271 - Average Test loss: 0.0835\n",
      "  Batch 100/938 - Training loss: 0.1339 - Average Test loss: 0.0834\n",
      "  Batch 200/938 - Training loss: 0.0503 - Average Test loss: 0.0831\n",
      "  Batch 300/938 - Training loss: 0.0722 - Average Test loss: 0.0826\n",
      "  Batch 400/938 - Training loss: 0.0147 - Average Test loss: 0.0829\n",
      "  Batch 500/938 - Training loss: 0.0382 - Average Test loss: 0.0827\n",
      "  Batch 600/938 - Training loss: 0.0382 - Average Test loss: 0.0826\n",
      "  Batch 700/938 - Training loss: 0.1195 - Average Test loss: 0.0826\n",
      "  Batch 800/938 - Training loss: 0.0434 - Average Test loss: 0.0833\n",
      "  Batch 900/938 - Training loss: 0.0206 - Average Test loss: 0.0831\n",
      "Epoch = 169\n",
      "  Batch 0/938 - Training loss: 0.1145 - Average Test loss: 0.0827\n",
      "  Batch 100/938 - Training loss: 0.0831 - Average Test loss: 0.0829\n",
      "  Batch 200/938 - Training loss: 0.0512 - Average Test loss: 0.0827\n",
      "  Batch 300/938 - Training loss: 0.0752 - Average Test loss: 0.0832\n",
      "  Batch 400/938 - Training loss: 0.0175 - Average Test loss: 0.0826\n",
      "  Batch 500/938 - Training loss: 0.0224 - Average Test loss: 0.0827\n",
      "  Batch 600/938 - Training loss: 0.2150 - Average Test loss: 0.0823\n",
      "  Batch 700/938 - Training loss: 0.0455 - Average Test loss: 0.0827\n",
      "  Batch 800/938 - Training loss: 0.0383 - Average Test loss: 0.0831\n",
      "  Batch 900/938 - Training loss: 0.0539 - Average Test loss: 0.0823\n",
      "Epoch = 170\n",
      "  Batch 0/938 - Training loss: 0.0316 - Average Test loss: 0.0827\n",
      "  Batch 100/938 - Training loss: 0.0622 - Average Test loss: 0.0830\n",
      "  Batch 200/938 - Training loss: 0.0135 - Average Test loss: 0.0829\n",
      "  Batch 300/938 - Training loss: 0.0321 - Average Test loss: 0.0827\n",
      "  Batch 400/938 - Training loss: 0.0940 - Average Test loss: 0.0827\n",
      "  Batch 500/938 - Training loss: 0.0347 - Average Test loss: 0.0827\n",
      "  Batch 600/938 - Training loss: 0.0774 - Average Test loss: 0.0828\n",
      "  Batch 700/938 - Training loss: 0.0518 - Average Test loss: 0.0822\n",
      "  Batch 800/938 - Training loss: 0.0773 - Average Test loss: 0.0826\n",
      "  Batch 900/938 - Training loss: 0.0396 - Average Test loss: 0.0821\n",
      "Epoch = 171\n",
      "  Batch 0/938 - Training loss: 0.0098 - Average Test loss: 0.0828\n",
      "  Batch 100/938 - Training loss: 0.0481 - Average Test loss: 0.0822\n",
      "  Batch 200/938 - Training loss: 0.0352 - Average Test loss: 0.0822\n",
      "  Batch 300/938 - Training loss: 0.0860 - Average Test loss: 0.0825\n",
      "  Batch 400/938 - Training loss: 0.0364 - Average Test loss: 0.0820\n",
      "  Batch 500/938 - Training loss: 0.0814 - Average Test loss: 0.0824\n",
      "  Batch 600/938 - Training loss: 0.0394 - Average Test loss: 0.0817\n",
      "  Batch 700/938 - Training loss: 0.0465 - Average Test loss: 0.0821\n",
      "  Batch 800/938 - Training loss: 0.1044 - Average Test loss: 0.0830\n",
      "  Batch 900/938 - Training loss: 0.1342 - Average Test loss: 0.0820\n",
      "Epoch = 172\n",
      "  Batch 0/938 - Training loss: 0.0528 - Average Test loss: 0.0820\n",
      "  Batch 100/938 - Training loss: 0.0125 - Average Test loss: 0.0821\n",
      "  Batch 200/938 - Training loss: 0.1212 - Average Test loss: 0.0826\n",
      "  Batch 300/938 - Training loss: 0.1136 - Average Test loss: 0.0821\n",
      "  Batch 400/938 - Training loss: 0.0467 - Average Test loss: 0.0820\n",
      "  Batch 500/938 - Training loss: 0.0183 - Average Test loss: 0.0823\n",
      "  Batch 600/938 - Training loss: 0.0179 - Average Test loss: 0.0821\n",
      "  Batch 700/938 - Training loss: 0.0242 - Average Test loss: 0.0823\n",
      "  Batch 800/938 - Training loss: 0.1082 - Average Test loss: 0.0824\n",
      "  Batch 900/938 - Training loss: 0.0206 - Average Test loss: 0.0827\n",
      "Epoch = 173\n",
      "  Batch 0/938 - Training loss: 0.0143 - Average Test loss: 0.0817\n",
      "  Batch 100/938 - Training loss: 0.0861 - Average Test loss: 0.0819\n",
      "  Batch 200/938 - Training loss: 0.0883 - Average Test loss: 0.0821\n",
      "  Batch 300/938 - Training loss: 0.0257 - Average Test loss: 0.0820\n",
      "  Batch 400/938 - Training loss: 0.0600 - Average Test loss: 0.0817\n",
      "  Batch 500/938 - Training loss: 0.0237 - Average Test loss: 0.0817\n",
      "  Batch 600/938 - Training loss: 0.0211 - Average Test loss: 0.0815\n",
      "  Batch 700/938 - Training loss: 0.0423 - Average Test loss: 0.0821\n",
      "  Batch 800/938 - Training loss: 0.0836 - Average Test loss: 0.0812\n",
      "  Batch 900/938 - Training loss: 0.0386 - Average Test loss: 0.0816\n",
      "Epoch = 174\n",
      "  Batch 0/938 - Training loss: 0.1310 - Average Test loss: 0.0823\n",
      "  Batch 100/938 - Training loss: 0.0302 - Average Test loss: 0.0813\n",
      "  Batch 200/938 - Training loss: 0.0397 - Average Test loss: 0.0817\n",
      "  Batch 300/938 - Training loss: 0.0535 - Average Test loss: 0.0824\n",
      "  Batch 400/938 - Training loss: 0.0465 - Average Test loss: 0.0817\n",
      "  Batch 500/938 - Training loss: 0.0580 - Average Test loss: 0.0815\n",
      "  Batch 600/938 - Training loss: 0.0715 - Average Test loss: 0.0809\n",
      "  Batch 700/938 - Training loss: 0.0231 - Average Test loss: 0.0810\n",
      "  Batch 800/938 - Training loss: 0.0762 - Average Test loss: 0.0815\n",
      "  Batch 900/938 - Training loss: 0.0861 - Average Test loss: 0.0813\n",
      "Epoch = 175\n",
      "  Batch 0/938 - Training loss: 0.0356 - Average Test loss: 0.0814\n",
      "  Batch 100/938 - Training loss: 0.0802 - Average Test loss: 0.0819\n",
      "  Batch 200/938 - Training loss: 0.0148 - Average Test loss: 0.0815\n",
      "  Batch 300/938 - Training loss: 0.0540 - Average Test loss: 0.0810\n",
      "  Batch 400/938 - Training loss: 0.0400 - Average Test loss: 0.0816\n",
      "  Batch 500/938 - Training loss: 0.0258 - Average Test loss: 0.0815\n",
      "  Batch 600/938 - Training loss: 0.0306 - Average Test loss: 0.0814\n",
      "  Batch 700/938 - Training loss: 0.0779 - Average Test loss: 0.0816\n",
      "  Batch 800/938 - Training loss: 0.0241 - Average Test loss: 0.0809\n",
      "  Batch 900/938 - Training loss: 0.0354 - Average Test loss: 0.0813\n",
      "Epoch = 176\n",
      "  Batch 0/938 - Training loss: 0.0619 - Average Test loss: 0.0810\n",
      "  Batch 100/938 - Training loss: 0.0599 - Average Test loss: 0.0812\n",
      "  Batch 200/938 - Training loss: 0.0549 - Average Test loss: 0.0811\n",
      "  Batch 300/938 - Training loss: 0.0179 - Average Test loss: 0.0812\n",
      "  Batch 400/938 - Training loss: 0.0361 - Average Test loss: 0.0816\n",
      "  Batch 500/938 - Training loss: 0.0289 - Average Test loss: 0.0817\n",
      "  Batch 600/938 - Training loss: 0.0239 - Average Test loss: 0.0814\n",
      "  Batch 700/938 - Training loss: 0.0372 - Average Test loss: 0.0811\n",
      "  Batch 800/938 - Training loss: 0.0391 - Average Test loss: 0.0807\n",
      "  Batch 900/938 - Training loss: 0.1102 - Average Test loss: 0.0812\n",
      "Epoch = 177\n",
      "  Batch 0/938 - Training loss: 0.1211 - Average Test loss: 0.0807\n",
      "  Batch 100/938 - Training loss: 0.0299 - Average Test loss: 0.0808\n",
      "  Batch 200/938 - Training loss: 0.0616 - Average Test loss: 0.0807\n",
      "  Batch 300/938 - Training loss: 0.0670 - Average Test loss: 0.0806\n",
      "  Batch 400/938 - Training loss: 0.0214 - Average Test loss: 0.0805\n",
      "  Batch 500/938 - Training loss: 0.0581 - Average Test loss: 0.0815\n",
      "  Batch 600/938 - Training loss: 0.0152 - Average Test loss: 0.0810\n",
      "  Batch 700/938 - Training loss: 0.0264 - Average Test loss: 0.0808\n",
      "  Batch 800/938 - Training loss: 0.0678 - Average Test loss: 0.0820\n",
      "  Batch 900/938 - Training loss: 0.0295 - Average Test loss: 0.0806\n",
      "Epoch = 178\n",
      "  Batch 0/938 - Training loss: 0.0280 - Average Test loss: 0.0804\n",
      "  Batch 100/938 - Training loss: 0.0892 - Average Test loss: 0.0812\n",
      "  Batch 200/938 - Training loss: 0.0397 - Average Test loss: 0.0807\n",
      "  Batch 300/938 - Training loss: 0.0511 - Average Test loss: 0.0815\n",
      "  Batch 400/938 - Training loss: 0.0748 - Average Test loss: 0.0802\n",
      "  Batch 500/938 - Training loss: 0.0992 - Average Test loss: 0.0801\n",
      "  Batch 600/938 - Training loss: 0.0518 - Average Test loss: 0.0804\n",
      "  Batch 700/938 - Training loss: 0.1084 - Average Test loss: 0.0808\n",
      "  Batch 800/938 - Training loss: 0.0421 - Average Test loss: 0.0802\n",
      "  Batch 900/938 - Training loss: 0.0190 - Average Test loss: 0.0799\n",
      "Epoch = 179\n",
      "  Batch 0/938 - Training loss: 0.0580 - Average Test loss: 0.0806\n",
      "  Batch 100/938 - Training loss: 0.0529 - Average Test loss: 0.0804\n",
      "  Batch 200/938 - Training loss: 0.0290 - Average Test loss: 0.0809\n",
      "  Batch 300/938 - Training loss: 0.0241 - Average Test loss: 0.0799\n",
      "  Batch 400/938 - Training loss: 0.0596 - Average Test loss: 0.0803\n",
      "  Batch 500/938 - Training loss: 0.0417 - Average Test loss: 0.0803\n",
      "  Batch 600/938 - Training loss: 0.0434 - Average Test loss: 0.0804\n",
      "  Batch 700/938 - Training loss: 0.0251 - Average Test loss: 0.0801\n",
      "  Batch 800/938 - Training loss: 0.0889 - Average Test loss: 0.0805\n",
      "  Batch 900/938 - Training loss: 0.0360 - Average Test loss: 0.0800\n",
      "Epoch = 180\n",
      "  Batch 0/938 - Training loss: 0.0877 - Average Test loss: 0.0801\n",
      "  Batch 100/938 - Training loss: 0.0533 - Average Test loss: 0.0804\n",
      "  Batch 200/938 - Training loss: 0.0580 - Average Test loss: 0.0805\n",
      "  Batch 300/938 - Training loss: 0.0673 - Average Test loss: 0.0801\n",
      "  Batch 400/938 - Training loss: 0.0709 - Average Test loss: 0.0806\n",
      "  Batch 500/938 - Training loss: 0.0272 - Average Test loss: 0.0799\n",
      "  Batch 600/938 - Training loss: 0.0753 - Average Test loss: 0.0808\n",
      "  Batch 700/938 - Training loss: 0.0965 - Average Test loss: 0.0801\n",
      "  Batch 800/938 - Training loss: 0.0384 - Average Test loss: 0.0803\n",
      "  Batch 900/938 - Training loss: 0.0113 - Average Test loss: 0.0806\n",
      "Epoch = 181\n",
      "  Batch 0/938 - Training loss: 0.0550 - Average Test loss: 0.0800\n",
      "  Batch 100/938 - Training loss: 0.0693 - Average Test loss: 0.0809\n",
      "  Batch 200/938 - Training loss: 0.1111 - Average Test loss: 0.0799\n",
      "  Batch 300/938 - Training loss: 0.0555 - Average Test loss: 0.0798\n",
      "  Batch 400/938 - Training loss: 0.0218 - Average Test loss: 0.0800\n",
      "  Batch 500/938 - Training loss: 0.0350 - Average Test loss: 0.0804\n",
      "  Batch 600/938 - Training loss: 0.0121 - Average Test loss: 0.0798\n",
      "  Batch 700/938 - Training loss: 0.0386 - Average Test loss: 0.0801\n",
      "  Batch 800/938 - Training loss: 0.0700 - Average Test loss: 0.0801\n",
      "  Batch 900/938 - Training loss: 0.0799 - Average Test loss: 0.0795\n",
      "Epoch = 182\n",
      "  Batch 0/938 - Training loss: 0.0327 - Average Test loss: 0.0794\n",
      "  Batch 100/938 - Training loss: 0.0741 - Average Test loss: 0.0793\n",
      "  Batch 200/938 - Training loss: 0.0223 - Average Test loss: 0.0802\n",
      "  Batch 300/938 - Training loss: 0.0258 - Average Test loss: 0.0796\n",
      "  Batch 400/938 - Training loss: 0.0870 - Average Test loss: 0.0793\n",
      "  Batch 500/938 - Training loss: 0.0489 - Average Test loss: 0.0800\n",
      "  Batch 600/938 - Training loss: 0.0445 - Average Test loss: 0.0796\n",
      "  Batch 700/938 - Training loss: 0.1284 - Average Test loss: 0.0800\n",
      "  Batch 800/938 - Training loss: 0.0604 - Average Test loss: 0.0803\n",
      "  Batch 900/938 - Training loss: 0.0759 - Average Test loss: 0.0794\n",
      "Epoch = 183\n",
      "  Batch 0/938 - Training loss: 0.0290 - Average Test loss: 0.0795\n",
      "  Batch 100/938 - Training loss: 0.0403 - Average Test loss: 0.0791\n",
      "  Batch 200/938 - Training loss: 0.0314 - Average Test loss: 0.0799\n",
      "  Batch 300/938 - Training loss: 0.1213 - Average Test loss: 0.0797\n",
      "  Batch 400/938 - Training loss: 0.1316 - Average Test loss: 0.0796\n",
      "  Batch 500/938 - Training loss: 0.0342 - Average Test loss: 0.0795\n",
      "  Batch 600/938 - Training loss: 0.1013 - Average Test loss: 0.0793\n",
      "  Batch 700/938 - Training loss: 0.0208 - Average Test loss: 0.0795\n",
      "  Batch 800/938 - Training loss: 0.0579 - Average Test loss: 0.0792\n",
      "  Batch 900/938 - Training loss: 0.1005 - Average Test loss: 0.0794\n",
      "Epoch = 184\n",
      "  Batch 0/938 - Training loss: 0.0278 - Average Test loss: 0.0794\n",
      "  Batch 100/938 - Training loss: 0.0380 - Average Test loss: 0.0799\n",
      "  Batch 200/938 - Training loss: 0.1183 - Average Test loss: 0.0795\n",
      "  Batch 300/938 - Training loss: 0.0698 - Average Test loss: 0.0790\n",
      "  Batch 400/938 - Training loss: 0.0359 - Average Test loss: 0.0794\n",
      "  Batch 500/938 - Training loss: 0.1056 - Average Test loss: 0.0790\n",
      "  Batch 600/938 - Training loss: 0.0825 - Average Test loss: 0.0793\n",
      "  Batch 700/938 - Training loss: 0.0116 - Average Test loss: 0.0794\n",
      "  Batch 800/938 - Training loss: 0.0657 - Average Test loss: 0.0792\n",
      "  Batch 900/938 - Training loss: 0.0281 - Average Test loss: 0.0791\n",
      "Epoch = 185\n",
      "  Batch 0/938 - Training loss: 0.0276 - Average Test loss: 0.0790\n",
      "  Batch 100/938 - Training loss: 0.0824 - Average Test loss: 0.0787\n",
      "  Batch 200/938 - Training loss: 0.0214 - Average Test loss: 0.0792\n",
      "  Batch 300/938 - Training loss: 0.0629 - Average Test loss: 0.0791\n",
      "  Batch 400/938 - Training loss: 0.0135 - Average Test loss: 0.0793\n",
      "  Batch 500/938 - Training loss: 0.0294 - Average Test loss: 0.0791\n",
      "  Batch 600/938 - Training loss: 0.0858 - Average Test loss: 0.0805\n",
      "  Batch 700/938 - Training loss: 0.0294 - Average Test loss: 0.0798\n",
      "  Batch 800/938 - Training loss: 0.0338 - Average Test loss: 0.0790\n",
      "  Batch 900/938 - Training loss: 0.0198 - Average Test loss: 0.0786\n",
      "Epoch = 186\n",
      "  Batch 0/938 - Training loss: 0.0395 - Average Test loss: 0.0787\n",
      "  Batch 100/938 - Training loss: 0.1028 - Average Test loss: 0.0789\n",
      "  Batch 200/938 - Training loss: 0.0998 - Average Test loss: 0.0800\n",
      "  Batch 300/938 - Training loss: 0.0962 - Average Test loss: 0.0794\n",
      "  Batch 400/938 - Training loss: 0.0421 - Average Test loss: 0.0790\n",
      "  Batch 500/938 - Training loss: 0.0453 - Average Test loss: 0.0790\n",
      "  Batch 600/938 - Training loss: 0.0439 - Average Test loss: 0.0785\n",
      "  Batch 700/938 - Training loss: 0.0287 - Average Test loss: 0.0788\n",
      "  Batch 800/938 - Training loss: 0.0401 - Average Test loss: 0.0787\n",
      "  Batch 900/938 - Training loss: 0.0333 - Average Test loss: 0.0786\n",
      "Epoch = 187\n",
      "  Batch 0/938 - Training loss: 0.0280 - Average Test loss: 0.0787\n",
      "  Batch 100/938 - Training loss: 0.0538 - Average Test loss: 0.0787\n",
      "  Batch 200/938 - Training loss: 0.0481 - Average Test loss: 0.0789\n",
      "  Batch 300/938 - Training loss: 0.0343 - Average Test loss: 0.0782\n",
      "  Batch 400/938 - Training loss: 0.0753 - Average Test loss: 0.0790\n",
      "  Batch 500/938 - Training loss: 0.1191 - Average Test loss: 0.0786\n",
      "  Batch 600/938 - Training loss: 0.0445 - Average Test loss: 0.0784\n",
      "  Batch 700/938 - Training loss: 0.1316 - Average Test loss: 0.0783\n",
      "  Batch 800/938 - Training loss: 0.0214 - Average Test loss: 0.0783\n",
      "  Batch 900/938 - Training loss: 0.0288 - Average Test loss: 0.0791\n",
      "Epoch = 188\n",
      "  Batch 0/938 - Training loss: 0.0239 - Average Test loss: 0.0791\n",
      "  Batch 100/938 - Training loss: 0.0738 - Average Test loss: 0.0781\n",
      "  Batch 200/938 - Training loss: 0.0596 - Average Test loss: 0.0790\n",
      "  Batch 300/938 - Training loss: 0.0447 - Average Test loss: 0.0785\n",
      "  Batch 400/938 - Training loss: 0.0208 - Average Test loss: 0.0787\n",
      "  Batch 500/938 - Training loss: 0.0389 - Average Test loss: 0.0784\n",
      "  Batch 600/938 - Training loss: 0.0264 - Average Test loss: 0.0785\n",
      "  Batch 700/938 - Training loss: 0.1742 - Average Test loss: 0.0790\n",
      "  Batch 800/938 - Training loss: 0.0371 - Average Test loss: 0.0788\n",
      "  Batch 900/938 - Training loss: 0.0595 - Average Test loss: 0.0795\n",
      "Epoch = 189\n",
      "  Batch 0/938 - Training loss: 0.1282 - Average Test loss: 0.0789\n",
      "  Batch 100/938 - Training loss: 0.0157 - Average Test loss: 0.0793\n",
      "  Batch 200/938 - Training loss: 0.0329 - Average Test loss: 0.0789\n",
      "  Batch 300/938 - Training loss: 0.0239 - Average Test loss: 0.0788\n",
      "  Batch 400/938 - Training loss: 0.0539 - Average Test loss: 0.0790\n",
      "  Batch 500/938 - Training loss: 0.0476 - Average Test loss: 0.0796\n",
      "  Batch 600/938 - Training loss: 0.0314 - Average Test loss: 0.0785\n",
      "  Batch 700/938 - Training loss: 0.0605 - Average Test loss: 0.0777\n",
      "  Batch 800/938 - Training loss: 0.0458 - Average Test loss: 0.0781\n",
      "  Batch 900/938 - Training loss: 0.0311 - Average Test loss: 0.0780\n",
      "Epoch = 190\n",
      "  Batch 0/938 - Training loss: 0.0660 - Average Test loss: 0.0779\n",
      "  Batch 100/938 - Training loss: 0.0622 - Average Test loss: 0.0781\n",
      "  Batch 200/938 - Training loss: 0.1269 - Average Test loss: 0.0778\n",
      "  Batch 300/938 - Training loss: 0.0560 - Average Test loss: 0.0782\n",
      "  Batch 400/938 - Training loss: 0.0941 - Average Test loss: 0.0785\n",
      "  Batch 500/938 - Training loss: 0.0591 - Average Test loss: 0.0784\n",
      "  Batch 600/938 - Training loss: 0.0193 - Average Test loss: 0.0780\n",
      "  Batch 700/938 - Training loss: 0.2071 - Average Test loss: 0.0780\n",
      "  Batch 800/938 - Training loss: 0.0137 - Average Test loss: 0.0779\n",
      "  Batch 900/938 - Training loss: 0.0327 - Average Test loss: 0.0783\n",
      "Epoch = 191\n",
      "  Batch 0/938 - Training loss: 0.0250 - Average Test loss: 0.0786\n",
      "  Batch 100/938 - Training loss: 0.0170 - Average Test loss: 0.0781\n",
      "  Batch 200/938 - Training loss: 0.0406 - Average Test loss: 0.0778\n",
      "  Batch 300/938 - Training loss: 0.0746 - Average Test loss: 0.0780\n",
      "  Batch 400/938 - Training loss: 0.0250 - Average Test loss: 0.0780\n",
      "  Batch 500/938 - Training loss: 0.0171 - Average Test loss: 0.0789\n",
      "  Batch 600/938 - Training loss: 0.0106 - Average Test loss: 0.0778\n",
      "  Batch 700/938 - Training loss: 0.0621 - Average Test loss: 0.0781\n",
      "  Batch 800/938 - Training loss: 0.0302 - Average Test loss: 0.0785\n",
      "  Batch 900/938 - Training loss: 0.0190 - Average Test loss: 0.0779\n",
      "Epoch = 192\n",
      "  Batch 0/938 - Training loss: 0.0966 - Average Test loss: 0.0786\n",
      "  Batch 100/938 - Training loss: 0.1279 - Average Test loss: 0.0781\n",
      "  Batch 200/938 - Training loss: 0.0328 - Average Test loss: 0.0778\n",
      "  Batch 300/938 - Training loss: 0.0533 - Average Test loss: 0.0777\n",
      "  Batch 400/938 - Training loss: 0.0317 - Average Test loss: 0.0782\n",
      "  Batch 500/938 - Training loss: 0.0754 - Average Test loss: 0.0777\n",
      "  Batch 600/938 - Training loss: 0.0282 - Average Test loss: 0.0777\n",
      "  Batch 700/938 - Training loss: 0.0276 - Average Test loss: 0.0783\n",
      "  Batch 800/938 - Training loss: 0.1395 - Average Test loss: 0.0777\n",
      "  Batch 900/938 - Training loss: 0.0250 - Average Test loss: 0.0774\n",
      "Epoch = 193\n",
      "  Batch 0/938 - Training loss: 0.1066 - Average Test loss: 0.0778\n",
      "  Batch 100/938 - Training loss: 0.0738 - Average Test loss: 0.0778\n",
      "  Batch 200/938 - Training loss: 0.0278 - Average Test loss: 0.0779\n",
      "  Batch 300/938 - Training loss: 0.0800 - Average Test loss: 0.0777\n",
      "  Batch 400/938 - Training loss: 0.0274 - Average Test loss: 0.0778\n",
      "  Batch 500/938 - Training loss: 0.0115 - Average Test loss: 0.0775\n",
      "  Batch 600/938 - Training loss: 0.0269 - Average Test loss: 0.0773\n",
      "  Batch 700/938 - Training loss: 0.0489 - Average Test loss: 0.0775\n",
      "  Batch 800/938 - Training loss: 0.0239 - Average Test loss: 0.0774\n",
      "  Batch 900/938 - Training loss: 0.0233 - Average Test loss: 0.0774\n",
      "Epoch = 194\n",
      "  Batch 0/938 - Training loss: 0.0382 - Average Test loss: 0.0773\n",
      "  Batch 100/938 - Training loss: 0.0379 - Average Test loss: 0.0777\n",
      "  Batch 200/938 - Training loss: 0.0371 - Average Test loss: 0.0777\n",
      "  Batch 300/938 - Training loss: 0.0436 - Average Test loss: 0.0773\n",
      "  Batch 400/938 - Training loss: 0.1491 - Average Test loss: 0.0776\n",
      "  Batch 500/938 - Training loss: 0.0917 - Average Test loss: 0.0773\n",
      "  Batch 600/938 - Training loss: 0.1222 - Average Test loss: 0.0777\n",
      "  Batch 700/938 - Training loss: 0.0672 - Average Test loss: 0.0781\n",
      "  Batch 800/938 - Training loss: 0.0314 - Average Test loss: 0.0782\n",
      "  Batch 900/938 - Training loss: 0.0721 - Average Test loss: 0.0769\n",
      "Epoch = 195\n",
      "  Batch 0/938 - Training loss: 0.0150 - Average Test loss: 0.0769\n",
      "  Batch 100/938 - Training loss: 0.0407 - Average Test loss: 0.0770\n",
      "  Batch 200/938 - Training loss: 0.0103 - Average Test loss: 0.0774\n",
      "  Batch 300/938 - Training loss: 0.0913 - Average Test loss: 0.0772\n",
      "  Batch 400/938 - Training loss: 0.0384 - Average Test loss: 0.0773\n",
      "  Batch 500/938 - Training loss: 0.0357 - Average Test loss: 0.0770\n",
      "  Batch 600/938 - Training loss: 0.0356 - Average Test loss: 0.0775\n",
      "  Batch 700/938 - Training loss: 0.1251 - Average Test loss: 0.0772\n",
      "  Batch 800/938 - Training loss: 0.1281 - Average Test loss: 0.0772\n",
      "  Batch 900/938 - Training loss: 0.0134 - Average Test loss: 0.0777\n",
      "Epoch = 196\n",
      "  Batch 0/938 - Training loss: 0.0539 - Average Test loss: 0.0771\n",
      "  Batch 100/938 - Training loss: 0.0442 - Average Test loss: 0.0771\n",
      "  Batch 200/938 - Training loss: 0.0944 - Average Test loss: 0.0770\n",
      "  Batch 300/938 - Training loss: 0.0364 - Average Test loss: 0.0768\n",
      "  Batch 400/938 - Training loss: 0.0371 - Average Test loss: 0.0767\n",
      "  Batch 500/938 - Training loss: 0.0577 - Average Test loss: 0.0771\n",
      "  Batch 600/938 - Training loss: 0.0284 - Average Test loss: 0.0774\n",
      "  Batch 700/938 - Training loss: 0.0715 - Average Test loss: 0.0774\n",
      "  Batch 800/938 - Training loss: 0.0431 - Average Test loss: 0.0773\n",
      "  Batch 900/938 - Training loss: 0.0173 - Average Test loss: 0.0771\n",
      "Epoch = 197\n",
      "  Batch 0/938 - Training loss: 0.1106 - Average Test loss: 0.0769\n",
      "  Batch 100/938 - Training loss: 0.0525 - Average Test loss: 0.0770\n",
      "  Batch 200/938 - Training loss: 0.1034 - Average Test loss: 0.0768\n",
      "  Batch 300/938 - Training loss: 0.0281 - Average Test loss: 0.0771\n",
      "  Batch 400/938 - Training loss: 0.0591 - Average Test loss: 0.0769\n",
      "  Batch 500/938 - Training loss: 0.0571 - Average Test loss: 0.0770\n",
      "  Batch 600/938 - Training loss: 0.0294 - Average Test loss: 0.0766\n",
      "  Batch 700/938 - Training loss: 0.0534 - Average Test loss: 0.0766\n",
      "  Batch 800/938 - Training loss: 0.0443 - Average Test loss: 0.0768\n",
      "  Batch 900/938 - Training loss: 0.0159 - Average Test loss: 0.0771\n",
      "Epoch = 198\n",
      "  Batch 0/938 - Training loss: 0.0787 - Average Test loss: 0.0773\n",
      "  Batch 100/938 - Training loss: 0.0742 - Average Test loss: 0.0766\n",
      "  Batch 200/938 - Training loss: 0.0264 - Average Test loss: 0.0770\n",
      "  Batch 300/938 - Training loss: 0.0489 - Average Test loss: 0.0767\n",
      "  Batch 400/938 - Training loss: 0.0145 - Average Test loss: 0.0766\n",
      "  Batch 500/938 - Training loss: 0.0381 - Average Test loss: 0.0765\n",
      "  Batch 600/938 - Training loss: 0.0814 - Average Test loss: 0.0765\n",
      "  Batch 700/938 - Training loss: 0.0569 - Average Test loss: 0.0771\n",
      "  Batch 800/938 - Training loss: 0.0499 - Average Test loss: 0.0768\n",
      "  Batch 900/938 - Training loss: 0.0064 - Average Test loss: 0.0766\n",
      "Epoch = 199\n",
      "  Batch 0/938 - Training loss: 0.1555 - Average Test loss: 0.0764\n",
      "  Batch 100/938 - Training loss: 0.0627 - Average Test loss: 0.0770\n",
      "  Batch 200/938 - Training loss: 0.0323 - Average Test loss: 0.0773\n",
      "  Batch 300/938 - Training loss: 0.0841 - Average Test loss: 0.0764\n",
      "  Batch 400/938 - Training loss: 0.0166 - Average Test loss: 0.0767\n",
      "  Batch 500/938 - Training loss: 0.0558 - Average Test loss: 0.0765\n",
      "  Batch 600/938 - Training loss: 0.1299 - Average Test loss: 0.0767\n",
      "  Batch 700/938 - Training loss: 0.0344 - Average Test loss: 0.0770\n",
      "  Batch 800/938 - Training loss: 0.0411 - Average Test loss: 0.0767\n",
      "  Batch 900/938 - Training loss: 0.0788 - Average Test loss: 0.0767\n",
      "Epoch = 200\n",
      "  Batch 0/938 - Training loss: 0.0307 - Average Test loss: 0.0762\n",
      "  Batch 100/938 - Training loss: 0.0397 - Average Test loss: 0.0765\n",
      "  Batch 200/938 - Training loss: 0.1175 - Average Test loss: 0.0765\n",
      "  Batch 300/938 - Training loss: 0.0395 - Average Test loss: 0.0762\n",
      "  Batch 400/938 - Training loss: 0.0176 - Average Test loss: 0.0769\n",
      "  Batch 500/938 - Training loss: 0.0429 - Average Test loss: 0.0764\n",
      "  Batch 600/938 - Training loss: 0.0748 - Average Test loss: 0.0761\n",
      "  Batch 700/938 - Training loss: 0.1102 - Average Test loss: 0.0762\n",
      "  Batch 800/938 - Training loss: 0.0605 - Average Test loss: 0.0760\n",
      "  Batch 900/938 - Training loss: 0.0141 - Average Test loss: 0.0763\n",
      "Epoch = 201\n",
      "  Batch 0/938 - Training loss: 0.0265 - Average Test loss: 0.0761\n",
      "  Batch 100/938 - Training loss: 0.0233 - Average Test loss: 0.0769\n",
      "  Batch 200/938 - Training loss: 0.0174 - Average Test loss: 0.0762\n",
      "  Batch 300/938 - Training loss: 0.0954 - Average Test loss: 0.0771\n",
      "  Batch 400/938 - Training loss: 0.0723 - Average Test loss: 0.0765\n",
      "  Batch 500/938 - Training loss: 0.1052 - Average Test loss: 0.0759\n",
      "  Batch 600/938 - Training loss: 0.0416 - Average Test loss: 0.0764\n",
      "  Batch 700/938 - Training loss: 0.0441 - Average Test loss: 0.0765\n",
      "  Batch 800/938 - Training loss: 0.0203 - Average Test loss: 0.0761\n",
      "  Batch 900/938 - Training loss: 0.0826 - Average Test loss: 0.0758\n",
      "Epoch = 202\n",
      "  Batch 0/938 - Training loss: 0.0365 - Average Test loss: 0.0762\n",
      "  Batch 100/938 - Training loss: 0.0336 - Average Test loss: 0.0761\n",
      "  Batch 200/938 - Training loss: 0.0485 - Average Test loss: 0.0758\n",
      "  Batch 300/938 - Training loss: 0.0248 - Average Test loss: 0.0759\n",
      "  Batch 400/938 - Training loss: 0.0182 - Average Test loss: 0.0765\n",
      "  Batch 500/938 - Training loss: 0.0197 - Average Test loss: 0.0764\n",
      "  Batch 600/938 - Training loss: 0.0490 - Average Test loss: 0.0762\n",
      "  Batch 700/938 - Training loss: 0.0701 - Average Test loss: 0.0764\n",
      "  Batch 800/938 - Training loss: 0.0214 - Average Test loss: 0.0764\n",
      "  Batch 900/938 - Training loss: 0.0157 - Average Test loss: 0.0761\n",
      "Epoch = 203\n",
      "  Batch 0/938 - Training loss: 0.0756 - Average Test loss: 0.0764\n",
      "  Batch 100/938 - Training loss: 0.0348 - Average Test loss: 0.0758\n",
      "  Batch 200/938 - Training loss: 0.0433 - Average Test loss: 0.0754\n",
      "  Batch 300/938 - Training loss: 0.0716 - Average Test loss: 0.0762\n",
      "  Batch 400/938 - Training loss: 0.1420 - Average Test loss: 0.0758\n",
      "  Batch 500/938 - Training loss: 0.0503 - Average Test loss: 0.0763\n",
      "  Batch 600/938 - Training loss: 0.0238 - Average Test loss: 0.0758\n",
      "  Batch 700/938 - Training loss: 0.0332 - Average Test loss: 0.0756\n",
      "  Batch 800/938 - Training loss: 0.0122 - Average Test loss: 0.0760\n",
      "  Batch 900/938 - Training loss: 0.0247 - Average Test loss: 0.0757\n",
      "Epoch = 204\n",
      "  Batch 0/938 - Training loss: 0.0846 - Average Test loss: 0.0759\n",
      "  Batch 100/938 - Training loss: 0.0793 - Average Test loss: 0.0756\n",
      "  Batch 200/938 - Training loss: 0.0737 - Average Test loss: 0.0756\n",
      "  Batch 300/938 - Training loss: 0.0352 - Average Test loss: 0.0757\n",
      "  Batch 400/938 - Training loss: 0.0324 - Average Test loss: 0.0765\n",
      "  Batch 500/938 - Training loss: 0.0323 - Average Test loss: 0.0757\n",
      "  Batch 600/938 - Training loss: 0.0458 - Average Test loss: 0.0757\n",
      "  Batch 700/938 - Training loss: 0.0303 - Average Test loss: 0.0758\n",
      "  Batch 800/938 - Training loss: 0.0089 - Average Test loss: 0.0753\n",
      "  Batch 900/938 - Training loss: 0.0933 - Average Test loss: 0.0754\n",
      "Epoch = 205\n",
      "  Batch 0/938 - Training loss: 0.0322 - Average Test loss: 0.0755\n",
      "  Batch 100/938 - Training loss: 0.0378 - Average Test loss: 0.0756\n",
      "  Batch 200/938 - Training loss: 0.0926 - Average Test loss: 0.0751\n",
      "  Batch 300/938 - Training loss: 0.0113 - Average Test loss: 0.0758\n",
      "  Batch 400/938 - Training loss: 0.0147 - Average Test loss: 0.0754\n",
      "  Batch 500/938 - Training loss: 0.1861 - Average Test loss: 0.0752\n",
      "  Batch 600/938 - Training loss: 0.0771 - Average Test loss: 0.0755\n",
      "  Batch 700/938 - Training loss: 0.0460 - Average Test loss: 0.0754\n",
      "  Batch 800/938 - Training loss: 0.0590 - Average Test loss: 0.0758\n",
      "  Batch 900/938 - Training loss: 0.0149 - Average Test loss: 0.0751\n",
      "Epoch = 206\n",
      "  Batch 0/938 - Training loss: 0.0352 - Average Test loss: 0.0753\n",
      "  Batch 100/938 - Training loss: 0.0154 - Average Test loss: 0.0753\n",
      "  Batch 200/938 - Training loss: 0.0211 - Average Test loss: 0.0750\n",
      "  Batch 300/938 - Training loss: 0.0183 - Average Test loss: 0.0754\n",
      "  Batch 400/938 - Training loss: 0.0417 - Average Test loss: 0.0756\n",
      "  Batch 500/938 - Training loss: 0.0228 - Average Test loss: 0.0755\n",
      "  Batch 600/938 - Training loss: 0.0234 - Average Test loss: 0.0757\n",
      "  Batch 700/938 - Training loss: 0.0410 - Average Test loss: 0.0756\n",
      "  Batch 800/938 - Training loss: 0.0409 - Average Test loss: 0.0754\n",
      "  Batch 900/938 - Training loss: 0.0529 - Average Test loss: 0.0752\n",
      "Epoch = 207\n",
      "  Batch 0/938 - Training loss: 0.0895 - Average Test loss: 0.0754\n",
      "  Batch 100/938 - Training loss: 0.0454 - Average Test loss: 0.0752\n",
      "  Batch 200/938 - Training loss: 0.0569 - Average Test loss: 0.0754\n",
      "  Batch 300/938 - Training loss: 0.0361 - Average Test loss: 0.0753\n",
      "  Batch 400/938 - Training loss: 0.1060 - Average Test loss: 0.0751\n",
      "  Batch 500/938 - Training loss: 0.0218 - Average Test loss: 0.0752\n",
      "  Batch 600/938 - Training loss: 0.0728 - Average Test loss: 0.0748\n",
      "  Batch 700/938 - Training loss: 0.0910 - Average Test loss: 0.0752\n",
      "  Batch 800/938 - Training loss: 0.0195 - Average Test loss: 0.0759\n",
      "  Batch 900/938 - Training loss: 0.0174 - Average Test loss: 0.0751\n",
      "Epoch = 208\n",
      "  Batch 0/938 - Training loss: 0.0897 - Average Test loss: 0.0755\n",
      "  Batch 100/938 - Training loss: 0.0236 - Average Test loss: 0.0753\n",
      "  Batch 200/938 - Training loss: 0.0638 - Average Test loss: 0.0751\n",
      "  Batch 300/938 - Training loss: 0.0109 - Average Test loss: 0.0753\n",
      "  Batch 400/938 - Training loss: 0.0187 - Average Test loss: 0.0752\n",
      "  Batch 500/938 - Training loss: 0.0314 - Average Test loss: 0.0755\n",
      "  Batch 600/938 - Training loss: 0.0713 - Average Test loss: 0.0757\n",
      "  Batch 700/938 - Training loss: 0.0381 - Average Test loss: 0.0748\n",
      "  Batch 800/938 - Training loss: 0.0218 - Average Test loss: 0.0752\n",
      "  Batch 900/938 - Training loss: 0.0353 - Average Test loss: 0.0754\n",
      "Epoch = 209\n",
      "  Batch 0/938 - Training loss: 0.0523 - Average Test loss: 0.0748\n",
      "  Batch 100/938 - Training loss: 0.0498 - Average Test loss: 0.0749\n",
      "  Batch 200/938 - Training loss: 0.0237 - Average Test loss: 0.0744\n",
      "  Batch 300/938 - Training loss: 0.0150 - Average Test loss: 0.0749\n",
      "  Batch 400/938 - Training loss: 0.0760 - Average Test loss: 0.0750\n",
      "  Batch 500/938 - Training loss: 0.0909 - Average Test loss: 0.0752\n",
      "  Batch 600/938 - Training loss: 0.0268 - Average Test loss: 0.0756\n",
      "  Batch 700/938 - Training loss: 0.0202 - Average Test loss: 0.0756\n",
      "  Batch 800/938 - Training loss: 0.0272 - Average Test loss: 0.0748\n",
      "  Batch 900/938 - Training loss: 0.0378 - Average Test loss: 0.0749\n",
      "Epoch = 210\n",
      "  Batch 0/938 - Training loss: 0.0556 - Average Test loss: 0.0752\n",
      "  Batch 100/938 - Training loss: 0.0426 - Average Test loss: 0.0751\n",
      "  Batch 200/938 - Training loss: 0.0190 - Average Test loss: 0.0747\n",
      "  Batch 300/938 - Training loss: 0.0229 - Average Test loss: 0.0754\n",
      "  Batch 400/938 - Training loss: 0.1111 - Average Test loss: 0.0746\n",
      "  Batch 500/938 - Training loss: 0.0476 - Average Test loss: 0.0745\n",
      "  Batch 600/938 - Training loss: 0.0981 - Average Test loss: 0.0754\n",
      "  Batch 700/938 - Training loss: 0.0270 - Average Test loss: 0.0748\n",
      "  Batch 800/938 - Training loss: 0.0250 - Average Test loss: 0.0745\n",
      "  Batch 900/938 - Training loss: 0.0855 - Average Test loss: 0.0747\n",
      "Epoch = 211\n",
      "  Batch 0/938 - Training loss: 0.0275 - Average Test loss: 0.0751\n",
      "  Batch 100/938 - Training loss: 0.0168 - Average Test loss: 0.0751\n",
      "  Batch 200/938 - Training loss: 0.0506 - Average Test loss: 0.0748\n",
      "  Batch 300/938 - Training loss: 0.0943 - Average Test loss: 0.0746\n",
      "  Batch 400/938 - Training loss: 0.0160 - Average Test loss: 0.0745\n",
      "  Batch 500/938 - Training loss: 0.0096 - Average Test loss: 0.0742\n",
      "  Batch 600/938 - Training loss: 0.0179 - Average Test loss: 0.0742\n",
      "  Batch 700/938 - Training loss: 0.1358 - Average Test loss: 0.0744\n",
      "  Batch 800/938 - Training loss: 0.0665 - Average Test loss: 0.0752\n",
      "  Batch 900/938 - Training loss: 0.0694 - Average Test loss: 0.0748\n",
      "Epoch = 212\n",
      "  Batch 0/938 - Training loss: 0.0485 - Average Test loss: 0.0746\n",
      "  Batch 100/938 - Training loss: 0.0891 - Average Test loss: 0.0746\n",
      "  Batch 200/938 - Training loss: 0.0166 - Average Test loss: 0.0745\n",
      "  Batch 300/938 - Training loss: 0.1011 - Average Test loss: 0.0742\n",
      "  Batch 400/938 - Training loss: 0.0354 - Average Test loss: 0.0741\n",
      "  Batch 500/938 - Training loss: 0.0269 - Average Test loss: 0.0742\n",
      "  Batch 600/938 - Training loss: 0.0381 - Average Test loss: 0.0745\n",
      "  Batch 700/938 - Training loss: 0.0364 - Average Test loss: 0.0747\n",
      "  Batch 800/938 - Training loss: 0.0516 - Average Test loss: 0.0753\n",
      "  Batch 900/938 - Training loss: 0.0099 - Average Test loss: 0.0742\n",
      "Epoch = 213\n",
      "  Batch 0/938 - Training loss: 0.0282 - Average Test loss: 0.0742\n",
      "  Batch 100/938 - Training loss: 0.0034 - Average Test loss: 0.0741\n",
      "  Batch 200/938 - Training loss: 0.0579 - Average Test loss: 0.0744\n",
      "  Batch 300/938 - Training loss: 0.0584 - Average Test loss: 0.0743\n",
      "  Batch 400/938 - Training loss: 0.0539 - Average Test loss: 0.0746\n",
      "  Batch 500/938 - Training loss: 0.0580 - Average Test loss: 0.0745\n",
      "  Batch 600/938 - Training loss: 0.0308 - Average Test loss: 0.0745\n",
      "  Batch 700/938 - Training loss: 0.0395 - Average Test loss: 0.0739\n",
      "  Batch 800/938 - Training loss: 0.0261 - Average Test loss: 0.0741\n",
      "  Batch 900/938 - Training loss: 0.0509 - Average Test loss: 0.0739\n",
      "Epoch = 214\n",
      "  Batch 0/938 - Training loss: 0.0323 - Average Test loss: 0.0739\n",
      "  Batch 100/938 - Training loss: 0.0494 - Average Test loss: 0.0753\n",
      "  Batch 200/938 - Training loss: 0.0788 - Average Test loss: 0.0740\n",
      "  Batch 300/938 - Training loss: 0.0346 - Average Test loss: 0.0747\n",
      "  Batch 400/938 - Training loss: 0.0287 - Average Test loss: 0.0738\n",
      "  Batch 500/938 - Training loss: 0.0191 - Average Test loss: 0.0739\n",
      "  Batch 600/938 - Training loss: 0.0687 - Average Test loss: 0.0741\n",
      "  Batch 700/938 - Training loss: 0.0641 - Average Test loss: 0.0740\n",
      "  Batch 800/938 - Training loss: 0.0692 - Average Test loss: 0.0739\n",
      "  Batch 900/938 - Training loss: 0.0209 - Average Test loss: 0.0740\n",
      "Epoch = 215\n",
      "  Batch 0/938 - Training loss: 0.0150 - Average Test loss: 0.0745\n",
      "  Batch 100/938 - Training loss: 0.0199 - Average Test loss: 0.0745\n",
      "  Batch 200/938 - Training loss: 0.0374 - Average Test loss: 0.0743\n",
      "  Batch 300/938 - Training loss: 0.0460 - Average Test loss: 0.0741\n",
      "  Batch 400/938 - Training loss: 0.0149 - Average Test loss: 0.0745\n",
      "  Batch 500/938 - Training loss: 0.0059 - Average Test loss: 0.0738\n",
      "  Batch 600/938 - Training loss: 0.0439 - Average Test loss: 0.0741\n",
      "  Batch 700/938 - Training loss: 0.0380 - Average Test loss: 0.0742\n",
      "  Batch 800/938 - Training loss: 0.0449 - Average Test loss: 0.0739\n",
      "  Batch 900/938 - Training loss: 0.0835 - Average Test loss: 0.0739\n",
      "Epoch = 216\n",
      "  Batch 0/938 - Training loss: 0.0298 - Average Test loss: 0.0735\n",
      "  Batch 100/938 - Training loss: 0.0645 - Average Test loss: 0.0735\n",
      "  Batch 200/938 - Training loss: 0.0269 - Average Test loss: 0.0741\n",
      "  Batch 300/938 - Training loss: 0.0230 - Average Test loss: 0.0739\n",
      "  Batch 400/938 - Training loss: 0.0192 - Average Test loss: 0.0738\n",
      "  Batch 500/938 - Training loss: 0.1791 - Average Test loss: 0.0739\n",
      "  Batch 600/938 - Training loss: 0.0161 - Average Test loss: 0.0740\n",
      "  Batch 700/938 - Training loss: 0.0543 - Average Test loss: 0.0738\n",
      "  Batch 800/938 - Training loss: 0.0381 - Average Test loss: 0.0739\n",
      "  Batch 900/938 - Training loss: 0.0733 - Average Test loss: 0.0740\n",
      "Epoch = 217\n",
      "  Batch 0/938 - Training loss: 0.1096 - Average Test loss: 0.0738\n",
      "  Batch 100/938 - Training loss: 0.0218 - Average Test loss: 0.0738\n",
      "  Batch 200/938 - Training loss: 0.0112 - Average Test loss: 0.0741\n",
      "  Batch 300/938 - Training loss: 0.1134 - Average Test loss: 0.0736\n",
      "  Batch 400/938 - Training loss: 0.0073 - Average Test loss: 0.0741\n",
      "  Batch 500/938 - Training loss: 0.0205 - Average Test loss: 0.0737\n",
      "  Batch 600/938 - Training loss: 0.0311 - Average Test loss: 0.0736\n",
      "  Batch 700/938 - Training loss: 0.0067 - Average Test loss: 0.0736\n",
      "  Batch 800/938 - Training loss: 0.0518 - Average Test loss: 0.0743\n",
      "  Batch 900/938 - Training loss: 0.0271 - Average Test loss: 0.0740\n",
      "Epoch = 218\n",
      "  Batch 0/938 - Training loss: 0.0484 - Average Test loss: 0.0733\n",
      "  Batch 100/938 - Training loss: 0.1395 - Average Test loss: 0.0737\n",
      "  Batch 200/938 - Training loss: 0.0228 - Average Test loss: 0.0741\n",
      "  Batch 300/938 - Training loss: 0.0461 - Average Test loss: 0.0738\n",
      "  Batch 400/938 - Training loss: 0.0376 - Average Test loss: 0.0742\n",
      "  Batch 500/938 - Training loss: 0.0141 - Average Test loss: 0.0735\n",
      "  Batch 600/938 - Training loss: 0.0275 - Average Test loss: 0.0733\n",
      "  Batch 700/938 - Training loss: 0.0435 - Average Test loss: 0.0737\n",
      "  Batch 800/938 - Training loss: 0.0222 - Average Test loss: 0.0734\n",
      "  Batch 900/938 - Training loss: 0.0230 - Average Test loss: 0.0733\n",
      "Epoch = 219\n",
      "  Batch 0/938 - Training loss: 0.0228 - Average Test loss: 0.0732\n",
      "  Batch 100/938 - Training loss: 0.0965 - Average Test loss: 0.0740\n",
      "  Batch 200/938 - Training loss: 0.0246 - Average Test loss: 0.0737\n",
      "  Batch 300/938 - Training loss: 0.1334 - Average Test loss: 0.0735\n",
      "  Batch 400/938 - Training loss: 0.0365 - Average Test loss: 0.0735\n",
      "  Batch 500/938 - Training loss: 0.0391 - Average Test loss: 0.0734\n",
      "  Batch 600/938 - Training loss: 0.0585 - Average Test loss: 0.0732\n",
      "  Batch 700/938 - Training loss: 0.0423 - Average Test loss: 0.0733\n",
      "  Batch 800/938 - Training loss: 0.0250 - Average Test loss: 0.0729\n",
      "  Batch 900/938 - Training loss: 0.1925 - Average Test loss: 0.0735\n",
      "Epoch = 220\n",
      "  Batch 0/938 - Training loss: 0.0386 - Average Test loss: 0.0733\n",
      "  Batch 100/938 - Training loss: 0.0314 - Average Test loss: 0.0731\n",
      "  Batch 200/938 - Training loss: 0.0204 - Average Test loss: 0.0739\n",
      "  Batch 300/938 - Training loss: 0.0424 - Average Test loss: 0.0734\n",
      "  Batch 400/938 - Training loss: 0.0334 - Average Test loss: 0.0733\n",
      "  Batch 500/938 - Training loss: 0.0408 - Average Test loss: 0.0730\n",
      "  Batch 600/938 - Training loss: 0.0514 - Average Test loss: 0.0732\n",
      "  Batch 700/938 - Training loss: 0.0311 - Average Test loss: 0.0731\n",
      "  Batch 800/938 - Training loss: 0.0345 - Average Test loss: 0.0729\n",
      "  Batch 900/938 - Training loss: 0.0688 - Average Test loss: 0.0735\n",
      "Epoch = 221\n",
      "  Batch 0/938 - Training loss: 0.0374 - Average Test loss: 0.0735\n",
      "  Batch 100/938 - Training loss: 0.0601 - Average Test loss: 0.0729\n",
      "  Batch 200/938 - Training loss: 0.0070 - Average Test loss: 0.0732\n",
      "  Batch 300/938 - Training loss: 0.0435 - Average Test loss: 0.0734\n",
      "  Batch 400/938 - Training loss: 0.0270 - Average Test loss: 0.0730\n",
      "  Batch 500/938 - Training loss: 0.0203 - Average Test loss: 0.0737\n",
      "  Batch 600/938 - Training loss: 0.0576 - Average Test loss: 0.0731\n",
      "  Batch 700/938 - Training loss: 0.0156 - Average Test loss: 0.0737\n",
      "  Batch 800/938 - Training loss: 0.0653 - Average Test loss: 0.0731\n",
      "  Batch 900/938 - Training loss: 0.0232 - Average Test loss: 0.0729\n",
      "Epoch = 222\n",
      "  Batch 0/938 - Training loss: 0.0283 - Average Test loss: 0.0731\n",
      "  Batch 100/938 - Training loss: 0.0324 - Average Test loss: 0.0736\n",
      "  Batch 200/938 - Training loss: 0.0241 - Average Test loss: 0.0730\n",
      "  Batch 300/938 - Training loss: 0.0394 - Average Test loss: 0.0732\n",
      "  Batch 400/938 - Training loss: 0.0237 - Average Test loss: 0.0730\n",
      "  Batch 500/938 - Training loss: 0.0453 - Average Test loss: 0.0729\n",
      "  Batch 600/938 - Training loss: 0.0174 - Average Test loss: 0.0732\n",
      "  Batch 700/938 - Training loss: 0.0866 - Average Test loss: 0.0732\n",
      "  Batch 800/938 - Training loss: 0.0248 - Average Test loss: 0.0732\n",
      "  Batch 900/938 - Training loss: 0.0385 - Average Test loss: 0.0738\n",
      "Epoch = 223\n",
      "  Batch 0/938 - Training loss: 0.0494 - Average Test loss: 0.0729\n",
      "  Batch 100/938 - Training loss: 0.0280 - Average Test loss: 0.0732\n",
      "  Batch 200/938 - Training loss: 0.0076 - Average Test loss: 0.0734\n",
      "  Batch 300/938 - Training loss: 0.0858 - Average Test loss: 0.0730\n",
      "  Batch 400/938 - Training loss: 0.0222 - Average Test loss: 0.0728\n",
      "  Batch 500/938 - Training loss: 0.0244 - Average Test loss: 0.0727\n",
      "  Batch 600/938 - Training loss: 0.0127 - Average Test loss: 0.0736\n",
      "  Batch 700/938 - Training loss: 0.0216 - Average Test loss: 0.0728\n",
      "  Batch 800/938 - Training loss: 0.1125 - Average Test loss: 0.0727\n",
      "  Batch 900/938 - Training loss: 0.0520 - Average Test loss: 0.0729\n",
      "Epoch = 224\n",
      "  Batch 0/938 - Training loss: 0.0486 - Average Test loss: 0.0727\n",
      "  Batch 100/938 - Training loss: 0.0194 - Average Test loss: 0.0732\n",
      "  Batch 200/938 - Training loss: 0.0364 - Average Test loss: 0.0726\n",
      "  Batch 300/938 - Training loss: 0.0694 - Average Test loss: 0.0727\n",
      "  Batch 400/938 - Training loss: 0.0612 - Average Test loss: 0.0727\n",
      "  Batch 500/938 - Training loss: 0.0198 - Average Test loss: 0.0728\n",
      "  Batch 600/938 - Training loss: 0.0273 - Average Test loss: 0.0729\n",
      "  Batch 700/938 - Training loss: 0.0308 - Average Test loss: 0.0726\n",
      "  Batch 800/938 - Training loss: 0.0167 - Average Test loss: 0.0728\n",
      "  Batch 900/938 - Training loss: 0.0382 - Average Test loss: 0.0730\n",
      "Epoch = 225\n",
      "  Batch 0/938 - Training loss: 0.0235 - Average Test loss: 0.0731\n",
      "  Batch 100/938 - Training loss: 0.0312 - Average Test loss: 0.0728\n",
      "  Batch 200/938 - Training loss: 0.0078 - Average Test loss: 0.0729\n",
      "  Batch 300/938 - Training loss: 0.0227 - Average Test loss: 0.0729\n",
      "  Batch 400/938 - Training loss: 0.0339 - Average Test loss: 0.0726\n",
      "  Batch 500/938 - Training loss: 0.0068 - Average Test loss: 0.0727\n",
      "  Batch 600/938 - Training loss: 0.2488 - Average Test loss: 0.0731\n",
      "  Batch 700/938 - Training loss: 0.0273 - Average Test loss: 0.0726\n",
      "  Batch 800/938 - Training loss: 0.0933 - Average Test loss: 0.0726\n",
      "  Batch 900/938 - Training loss: 0.0208 - Average Test loss: 0.0730\n",
      "Epoch = 226\n",
      "  Batch 0/938 - Training loss: 0.1210 - Average Test loss: 0.0725\n",
      "  Batch 100/938 - Training loss: 0.0504 - Average Test loss: 0.0731\n",
      "  Batch 200/938 - Training loss: 0.0514 - Average Test loss: 0.0728\n",
      "  Batch 300/938 - Training loss: 0.0784 - Average Test loss: 0.0726\n",
      "  Batch 400/938 - Training loss: 0.0136 - Average Test loss: 0.0722\n",
      "  Batch 500/938 - Training loss: 0.0519 - Average Test loss: 0.0724\n",
      "  Batch 600/938 - Training loss: 0.0275 - Average Test loss: 0.0723\n",
      "  Batch 700/938 - Training loss: 0.0345 - Average Test loss: 0.0724\n",
      "  Batch 800/938 - Training loss: 0.0511 - Average Test loss: 0.0725\n",
      "  Batch 900/938 - Training loss: 0.0210 - Average Test loss: 0.0728\n",
      "Epoch = 227\n",
      "  Batch 0/938 - Training loss: 0.0692 - Average Test loss: 0.0725\n",
      "  Batch 100/938 - Training loss: 0.0132 - Average Test loss: 0.0725\n",
      "  Batch 200/938 - Training loss: 0.1321 - Average Test loss: 0.0725\n",
      "  Batch 300/938 - Training loss: 0.0330 - Average Test loss: 0.0731\n",
      "  Batch 400/938 - Training loss: 0.0299 - Average Test loss: 0.0729\n",
      "  Batch 500/938 - Training loss: 0.0195 - Average Test loss: 0.0726\n",
      "  Batch 600/938 - Training loss: 0.0330 - Average Test loss: 0.0724\n",
      "  Batch 700/938 - Training loss: 0.0228 - Average Test loss: 0.0723\n",
      "  Batch 800/938 - Training loss: 0.0299 - Average Test loss: 0.0723\n",
      "  Batch 900/938 - Training loss: 0.0394 - Average Test loss: 0.0722\n",
      "Epoch = 228\n",
      "  Batch 0/938 - Training loss: 0.0148 - Average Test loss: 0.0719\n",
      "  Batch 100/938 - Training loss: 0.0208 - Average Test loss: 0.0724\n",
      "  Batch 200/938 - Training loss: 0.0480 - Average Test loss: 0.0727\n",
      "  Batch 300/938 - Training loss: 0.0343 - Average Test loss: 0.0728\n",
      "  Batch 400/938 - Training loss: 0.0258 - Average Test loss: 0.0725\n",
      "  Batch 500/938 - Training loss: 0.0933 - Average Test loss: 0.0722\n",
      "  Batch 600/938 - Training loss: 0.0703 - Average Test loss: 0.0723\n",
      "  Batch 700/938 - Training loss: 0.0306 - Average Test loss: 0.0725\n",
      "  Batch 800/938 - Training loss: 0.0706 - Average Test loss: 0.0726\n",
      "  Batch 900/938 - Training loss: 0.0556 - Average Test loss: 0.0721\n",
      "Epoch = 229\n",
      "  Batch 0/938 - Training loss: 0.0089 - Average Test loss: 0.0721\n",
      "  Batch 100/938 - Training loss: 0.0261 - Average Test loss: 0.0726\n",
      "  Batch 200/938 - Training loss: 0.0431 - Average Test loss: 0.0719\n",
      "  Batch 300/938 - Training loss: 0.0288 - Average Test loss: 0.0732\n",
      "  Batch 400/938 - Training loss: 0.0483 - Average Test loss: 0.0721\n",
      "  Batch 500/938 - Training loss: 0.0165 - Average Test loss: 0.0717\n",
      "  Batch 600/938 - Training loss: 0.0195 - Average Test loss: 0.0727\n",
      "  Batch 700/938 - Training loss: 0.0202 - Average Test loss: 0.0723\n",
      "  Batch 800/938 - Training loss: 0.0325 - Average Test loss: 0.0721\n",
      "  Batch 900/938 - Training loss: 0.0257 - Average Test loss: 0.0720\n",
      "Epoch = 230\n",
      "  Batch 0/938 - Training loss: 0.0173 - Average Test loss: 0.0721\n",
      "  Batch 100/938 - Training loss: 0.0247 - Average Test loss: 0.0720\n",
      "  Batch 200/938 - Training loss: 0.0511 - Average Test loss: 0.0722\n",
      "  Batch 300/938 - Training loss: 0.0301 - Average Test loss: 0.0720\n",
      "  Batch 400/938 - Training loss: 0.0191 - Average Test loss: 0.0726\n",
      "  Batch 500/938 - Training loss: 0.0139 - Average Test loss: 0.0725\n",
      "  Batch 600/938 - Training loss: 0.0476 - Average Test loss: 0.0722\n",
      "  Batch 700/938 - Training loss: 0.0618 - Average Test loss: 0.0720\n",
      "  Batch 800/938 - Training loss: 0.0459 - Average Test loss: 0.0719\n",
      "  Batch 900/938 - Training loss: 0.0305 - Average Test loss: 0.0718\n",
      "Epoch = 231\n",
      "  Batch 0/938 - Training loss: 0.0284 - Average Test loss: 0.0717\n",
      "  Batch 100/938 - Training loss: 0.0492 - Average Test loss: 0.0716\n",
      "  Batch 200/938 - Training loss: 0.0728 - Average Test loss: 0.0718\n",
      "  Batch 300/938 - Training loss: 0.0601 - Average Test loss: 0.0716\n",
      "  Batch 400/938 - Training loss: 0.0288 - Average Test loss: 0.0719\n",
      "  Batch 500/938 - Training loss: 0.0380 - Average Test loss: 0.0718\n",
      "  Batch 600/938 - Training loss: 0.0309 - Average Test loss: 0.0722\n",
      "  Batch 700/938 - Training loss: 0.0025 - Average Test loss: 0.0719\n",
      "  Batch 800/938 - Training loss: 0.0798 - Average Test loss: 0.0717\n",
      "  Batch 900/938 - Training loss: 0.0515 - Average Test loss: 0.0718\n",
      "Epoch = 232\n",
      "  Batch 0/938 - Training loss: 0.0145 - Average Test loss: 0.0716\n",
      "  Batch 100/938 - Training loss: 0.0078 - Average Test loss: 0.0714\n",
      "  Batch 200/938 - Training loss: 0.0655 - Average Test loss: 0.0719\n",
      "  Batch 300/938 - Training loss: 0.0289 - Average Test loss: 0.0719\n",
      "  Batch 400/938 - Training loss: 0.0578 - Average Test loss: 0.0729\n",
      "  Batch 500/938 - Training loss: 0.0226 - Average Test loss: 0.0720\n",
      "  Batch 600/938 - Training loss: 0.0373 - Average Test loss: 0.0715\n",
      "  Batch 700/938 - Training loss: 0.0497 - Average Test loss: 0.0719\n",
      "  Batch 800/938 - Training loss: 0.0659 - Average Test loss: 0.0717\n",
      "  Batch 900/938 - Training loss: 0.1615 - Average Test loss: 0.0719\n",
      "Epoch = 233\n",
      "  Batch 0/938 - Training loss: 0.1268 - Average Test loss: 0.0715\n",
      "  Batch 100/938 - Training loss: 0.0472 - Average Test loss: 0.0717\n",
      "  Batch 200/938 - Training loss: 0.0451 - Average Test loss: 0.0717\n",
      "  Batch 300/938 - Training loss: 0.0213 - Average Test loss: 0.0714\n",
      "  Batch 400/938 - Training loss: 0.0911 - Average Test loss: 0.0716\n",
      "  Batch 500/938 - Training loss: 0.0263 - Average Test loss: 0.0717\n",
      "  Batch 600/938 - Training loss: 0.0637 - Average Test loss: 0.0716\n",
      "  Batch 700/938 - Training loss: 0.0229 - Average Test loss: 0.0719\n",
      "  Batch 800/938 - Training loss: 0.0750 - Average Test loss: 0.0719\n",
      "  Batch 900/938 - Training loss: 0.0382 - Average Test loss: 0.0716\n",
      "Epoch = 234\n",
      "  Batch 0/938 - Training loss: 0.0189 - Average Test loss: 0.0722\n",
      "  Batch 100/938 - Training loss: 0.0631 - Average Test loss: 0.0724\n",
      "  Batch 200/938 - Training loss: 0.0580 - Average Test loss: 0.0714\n",
      "  Batch 300/938 - Training loss: 0.0343 - Average Test loss: 0.0720\n",
      "  Batch 400/938 - Training loss: 0.0231 - Average Test loss: 0.0712\n",
      "  Batch 500/938 - Training loss: 0.0500 - Average Test loss: 0.0713\n",
      "  Batch 600/938 - Training loss: 0.0448 - Average Test loss: 0.0717\n",
      "  Batch 700/938 - Training loss: 0.0276 - Average Test loss: 0.0719\n",
      "  Batch 800/938 - Training loss: 0.0555 - Average Test loss: 0.0716\n",
      "  Batch 900/938 - Training loss: 0.1133 - Average Test loss: 0.0715\n",
      "Epoch = 235\n",
      "  Batch 0/938 - Training loss: 0.0880 - Average Test loss: 0.0715\n",
      "  Batch 100/938 - Training loss: 0.0594 - Average Test loss: 0.0718\n",
      "  Batch 200/938 - Training loss: 0.0377 - Average Test loss: 0.0716\n",
      "  Batch 300/938 - Training loss: 0.0610 - Average Test loss: 0.0716\n",
      "  Batch 400/938 - Training loss: 0.0297 - Average Test loss: 0.0714\n",
      "  Batch 500/938 - Training loss: 0.1271 - Average Test loss: 0.0715\n",
      "  Batch 600/938 - Training loss: 0.0441 - Average Test loss: 0.0710\n",
      "  Batch 700/938 - Training loss: 0.0973 - Average Test loss: 0.0718\n",
      "  Batch 800/938 - Training loss: 0.0390 - Average Test loss: 0.0714\n",
      "  Batch 900/938 - Training loss: 0.0556 - Average Test loss: 0.0711\n",
      "Epoch = 236\n",
      "  Batch 0/938 - Training loss: 0.0142 - Average Test loss: 0.0710\n",
      "  Batch 100/938 - Training loss: 0.0448 - Average Test loss: 0.0712\n",
      "  Batch 200/938 - Training loss: 0.0412 - Average Test loss: 0.0713\n",
      "  Batch 300/938 - Training loss: 0.0289 - Average Test loss: 0.0713\n",
      "  Batch 400/938 - Training loss: 0.0695 - Average Test loss: 0.0712\n",
      "  Batch 500/938 - Training loss: 0.0417 - Average Test loss: 0.0711\n",
      "  Batch 600/938 - Training loss: 0.0357 - Average Test loss: 0.0716\n",
      "  Batch 700/938 - Training loss: 0.0174 - Average Test loss: 0.0712\n",
      "  Batch 800/938 - Training loss: 0.0122 - Average Test loss: 0.0715\n",
      "  Batch 900/938 - Training loss: 0.1295 - Average Test loss: 0.0714\n",
      "Epoch = 237\n",
      "  Batch 0/938 - Training loss: 0.0234 - Average Test loss: 0.0712\n",
      "  Batch 100/938 - Training loss: 0.0114 - Average Test loss: 0.0717\n",
      "  Batch 200/938 - Training loss: 0.0556 - Average Test loss: 0.0710\n",
      "  Batch 300/938 - Training loss: 0.0135 - Average Test loss: 0.0714\n",
      "  Batch 400/938 - Training loss: 0.0279 - Average Test loss: 0.0710\n",
      "  Batch 500/938 - Training loss: 0.1011 - Average Test loss: 0.0708\n",
      "  Batch 600/938 - Training loss: 0.0266 - Average Test loss: 0.0712\n",
      "  Batch 700/938 - Training loss: 0.0308 - Average Test loss: 0.0717\n",
      "  Batch 800/938 - Training loss: 0.0962 - Average Test loss: 0.0714\n",
      "  Batch 900/938 - Training loss: 0.0232 - Average Test loss: 0.0711\n",
      "Epoch = 238\n",
      "  Batch 0/938 - Training loss: 0.0588 - Average Test loss: 0.0706\n",
      "  Batch 100/938 - Training loss: 0.0541 - Average Test loss: 0.0709\n",
      "  Batch 200/938 - Training loss: 0.0235 - Average Test loss: 0.0715\n",
      "  Batch 300/938 - Training loss: 0.0551 - Average Test loss: 0.0713\n",
      "  Batch 400/938 - Training loss: 0.0352 - Average Test loss: 0.0713\n",
      "  Batch 500/938 - Training loss: 0.0220 - Average Test loss: 0.0707\n",
      "  Batch 600/938 - Training loss: 0.0453 - Average Test loss: 0.0708\n",
      "  Batch 700/938 - Training loss: 0.0207 - Average Test loss: 0.0713\n",
      "  Batch 800/938 - Training loss: 0.0132 - Average Test loss: 0.0711\n",
      "  Batch 900/938 - Training loss: 0.0143 - Average Test loss: 0.0709\n",
      "Epoch = 239\n",
      "  Batch 0/938 - Training loss: 0.0149 - Average Test loss: 0.0712\n",
      "  Batch 100/938 - Training loss: 0.0786 - Average Test loss: 0.0716\n",
      "  Batch 200/938 - Training loss: 0.0219 - Average Test loss: 0.0707\n",
      "  Batch 300/938 - Training loss: 0.0137 - Average Test loss: 0.0707\n",
      "  Batch 400/938 - Training loss: 0.0307 - Average Test loss: 0.0710\n",
      "  Batch 500/938 - Training loss: 0.0202 - Average Test loss: 0.0708\n",
      "  Batch 600/938 - Training loss: 0.0182 - Average Test loss: 0.0706\n",
      "  Batch 700/938 - Training loss: 0.0177 - Average Test loss: 0.0712\n",
      "  Batch 800/938 - Training loss: 0.0113 - Average Test loss: 0.0716\n",
      "  Batch 900/938 - Training loss: 0.0350 - Average Test loss: 0.0708\n",
      "Epoch = 240\n",
      "  Batch 0/938 - Training loss: 0.0510 - Average Test loss: 0.0707\n",
      "  Batch 100/938 - Training loss: 0.0222 - Average Test loss: 0.0709\n",
      "  Batch 200/938 - Training loss: 0.0393 - Average Test loss: 0.0709\n",
      "  Batch 300/938 - Training loss: 0.0342 - Average Test loss: 0.0711\n",
      "  Batch 400/938 - Training loss: 0.0810 - Average Test loss: 0.0709\n",
      "  Batch 500/938 - Training loss: 0.0303 - Average Test loss: 0.0711\n",
      "  Batch 600/938 - Training loss: 0.0347 - Average Test loss: 0.0707\n",
      "  Batch 700/938 - Training loss: 0.0572 - Average Test loss: 0.0708\n",
      "  Batch 800/938 - Training loss: 0.0223 - Average Test loss: 0.0706\n",
      "  Batch 900/938 - Training loss: 0.0240 - Average Test loss: 0.0706\n",
      "Epoch = 241\n",
      "  Batch 0/938 - Training loss: 0.0483 - Average Test loss: 0.0711\n",
      "  Batch 100/938 - Training loss: 0.0123 - Average Test loss: 0.0709\n",
      "  Batch 200/938 - Training loss: 0.0121 - Average Test loss: 0.0708\n",
      "  Batch 300/938 - Training loss: 0.0335 - Average Test loss: 0.0706\n",
      "  Batch 400/938 - Training loss: 0.0429 - Average Test loss: 0.0709\n",
      "  Batch 500/938 - Training loss: 0.0299 - Average Test loss: 0.0707\n",
      "  Batch 600/938 - Training loss: 0.0830 - Average Test loss: 0.0707\n",
      "  Batch 700/938 - Training loss: 0.0050 - Average Test loss: 0.0707\n",
      "  Batch 800/938 - Training loss: 0.0210 - Average Test loss: 0.0707\n",
      "  Batch 900/938 - Training loss: 0.0154 - Average Test loss: 0.0717\n",
      "Epoch = 242\n",
      "  Batch 0/938 - Training loss: 0.0914 - Average Test loss: 0.0711\n",
      "  Batch 100/938 - Training loss: 0.0365 - Average Test loss: 0.0707\n",
      "  Batch 200/938 - Training loss: 0.0589 - Average Test loss: 0.0716\n",
      "  Batch 300/938 - Training loss: 0.0327 - Average Test loss: 0.0709\n",
      "  Batch 400/938 - Training loss: 0.0077 - Average Test loss: 0.0706\n",
      "  Batch 500/938 - Training loss: 0.0141 - Average Test loss: 0.0702\n",
      "  Batch 600/938 - Training loss: 0.0321 - Average Test loss: 0.0699\n",
      "  Batch 700/938 - Training loss: 0.0775 - Average Test loss: 0.0703\n",
      "  Batch 800/938 - Training loss: 0.0183 - Average Test loss: 0.0711\n",
      "  Batch 900/938 - Training loss: 0.0262 - Average Test loss: 0.0707\n",
      "Epoch = 243\n",
      "  Batch 0/938 - Training loss: 0.0101 - Average Test loss: 0.0710\n",
      "  Batch 100/938 - Training loss: 0.0121 - Average Test loss: 0.0705\n",
      "  Batch 200/938 - Training loss: 0.0245 - Average Test loss: 0.0708\n",
      "  Batch 300/938 - Training loss: 0.0356 - Average Test loss: 0.0703\n",
      "  Batch 400/938 - Training loss: 0.0273 - Average Test loss: 0.0710\n",
      "  Batch 500/938 - Training loss: 0.0119 - Average Test loss: 0.0707\n",
      "  Batch 600/938 - Training loss: 0.0277 - Average Test loss: 0.0710\n",
      "  Batch 700/938 - Training loss: 0.0278 - Average Test loss: 0.0705\n",
      "  Batch 800/938 - Training loss: 0.0441 - Average Test loss: 0.0713\n",
      "  Batch 900/938 - Training loss: 0.0291 - Average Test loss: 0.0706\n",
      "Epoch = 244\n",
      "  Batch 0/938 - Training loss: 0.0237 - Average Test loss: 0.0707\n",
      "  Batch 100/938 - Training loss: 0.1324 - Average Test loss: 0.0708\n",
      "  Batch 200/938 - Training loss: 0.0559 - Average Test loss: 0.0706\n",
      "  Batch 300/938 - Training loss: 0.0331 - Average Test loss: 0.0707\n",
      "  Batch 400/938 - Training loss: 0.0489 - Average Test loss: 0.0710\n",
      "  Batch 500/938 - Training loss: 0.0937 - Average Test loss: 0.0705\n",
      "  Batch 600/938 - Training loss: 0.0655 - Average Test loss: 0.0706\n",
      "  Batch 700/938 - Training loss: 0.0322 - Average Test loss: 0.0708\n",
      "  Batch 800/938 - Training loss: 0.0782 - Average Test loss: 0.0708\n",
      "  Batch 900/938 - Training loss: 0.0244 - Average Test loss: 0.0709\n",
      "Epoch = 245\n",
      "  Batch 0/938 - Training loss: 0.0075 - Average Test loss: 0.0707\n",
      "  Batch 100/938 - Training loss: 0.0349 - Average Test loss: 0.0705\n",
      "  Batch 200/938 - Training loss: 0.0521 - Average Test loss: 0.0702\n",
      "  Batch 300/938 - Training loss: 0.0331 - Average Test loss: 0.0702\n",
      "  Batch 400/938 - Training loss: 0.0319 - Average Test loss: 0.0706\n",
      "  Batch 500/938 - Training loss: 0.0206 - Average Test loss: 0.0697\n",
      "  Batch 600/938 - Training loss: 0.0797 - Average Test loss: 0.0702\n",
      "  Batch 700/938 - Training loss: 0.0684 - Average Test loss: 0.0700\n",
      "  Batch 800/938 - Training loss: 0.0297 - Average Test loss: 0.0707\n",
      "  Batch 900/938 - Training loss: 0.0103 - Average Test loss: 0.0707\n",
      "Epoch = 246\n",
      "  Batch 0/938 - Training loss: 0.0265 - Average Test loss: 0.0703\n",
      "  Batch 100/938 - Training loss: 0.0170 - Average Test loss: 0.0705\n",
      "  Batch 200/938 - Training loss: 0.0118 - Average Test loss: 0.0700\n",
      "  Batch 300/938 - Training loss: 0.0141 - Average Test loss: 0.0706\n",
      "  Batch 400/938 - Training loss: 0.0122 - Average Test loss: 0.0700\n",
      "  Batch 500/938 - Training loss: 0.0265 - Average Test loss: 0.0702\n",
      "  Batch 600/938 - Training loss: 0.0847 - Average Test loss: 0.0707\n",
      "  Batch 700/938 - Training loss: 0.0259 - Average Test loss: 0.0707\n",
      "  Batch 800/938 - Training loss: 0.0210 - Average Test loss: 0.0703\n",
      "  Batch 900/938 - Training loss: 0.0220 - Average Test loss: 0.0702\n",
      "Epoch = 247\n",
      "  Batch 0/938 - Training loss: 0.0202 - Average Test loss: 0.0698\n",
      "  Batch 100/938 - Training loss: 0.0937 - Average Test loss: 0.0703\n",
      "  Batch 200/938 - Training loss: 0.0349 - Average Test loss: 0.0698\n",
      "  Batch 300/938 - Training loss: 0.0113 - Average Test loss: 0.0700\n",
      "  Batch 400/938 - Training loss: 0.0502 - Average Test loss: 0.0702\n",
      "  Batch 500/938 - Training loss: 0.0294 - Average Test loss: 0.0699\n",
      "  Batch 600/938 - Training loss: 0.0902 - Average Test loss: 0.0698\n",
      "  Batch 700/938 - Training loss: 0.0193 - Average Test loss: 0.0700\n",
      "  Batch 800/938 - Training loss: 0.0561 - Average Test loss: 0.0703\n",
      "  Batch 900/938 - Training loss: 0.0183 - Average Test loss: 0.0702\n",
      "Epoch = 248\n",
      "  Batch 0/938 - Training loss: 0.0937 - Average Test loss: 0.0703\n",
      "  Batch 100/938 - Training loss: 0.0234 - Average Test loss: 0.0699\n",
      "  Batch 200/938 - Training loss: 0.0082 - Average Test loss: 0.0704\n",
      "  Batch 300/938 - Training loss: 0.0204 - Average Test loss: 0.0699\n",
      "  Batch 400/938 - Training loss: 0.0133 - Average Test loss: 0.0703\n",
      "  Batch 500/938 - Training loss: 0.0041 - Average Test loss: 0.0699\n",
      "  Batch 600/938 - Training loss: 0.0970 - Average Test loss: 0.0705\n",
      "  Batch 700/938 - Training loss: 0.0164 - Average Test loss: 0.0700\n",
      "  Batch 800/938 - Training loss: 0.0251 - Average Test loss: 0.0700\n",
      "  Batch 900/938 - Training loss: 0.1303 - Average Test loss: 0.0696\n",
      "Epoch = 249\n",
      "  Batch 0/938 - Training loss: 0.0124 - Average Test loss: 0.0699\n",
      "  Batch 100/938 - Training loss: 0.0115 - Average Test loss: 0.0699\n",
      "  Batch 200/938 - Training loss: 0.0405 - Average Test loss: 0.0698\n",
      "  Batch 300/938 - Training loss: 0.0473 - Average Test loss: 0.0695\n",
      "  Batch 400/938 - Training loss: 0.0922 - Average Test loss: 0.0698\n",
      "  Batch 500/938 - Training loss: 0.0460 - Average Test loss: 0.0698\n",
      "  Batch 600/938 - Training loss: 0.0152 - Average Test loss: 0.0700\n",
      "  Batch 700/938 - Training loss: 0.0126 - Average Test loss: 0.0699\n",
      "  Batch 800/938 - Training loss: 0.0209 - Average Test loss: 0.0699\n",
      "  Batch 900/938 - Training loss: 0.0327 - Average Test loss: 0.0700\n",
      "Epoch = 250\n",
      "  Batch 0/938 - Training loss: 0.0507 - Average Test loss: 0.0703\n",
      "  Batch 100/938 - Training loss: 0.1742 - Average Test loss: 0.0697\n",
      "  Batch 200/938 - Training loss: 0.0077 - Average Test loss: 0.0701\n",
      "  Batch 300/938 - Training loss: 0.0553 - Average Test loss: 0.0700\n",
      "  Batch 400/938 - Training loss: 0.0064 - Average Test loss: 0.0702\n",
      "  Batch 500/938 - Training loss: 0.0136 - Average Test loss: 0.0695\n",
      "  Batch 600/938 - Training loss: 0.0478 - Average Test loss: 0.0694\n",
      "  Batch 700/938 - Training loss: 0.1114 - Average Test loss: 0.0700\n",
      "  Batch 800/938 - Training loss: 0.0332 - Average Test loss: 0.0697\n",
      "  Batch 900/938 - Training loss: 0.0287 - Average Test loss: 0.0701\n",
      "Epoch = 251\n",
      "  Batch 0/938 - Training loss: 0.0253 - Average Test loss: 0.0707\n",
      "  Batch 100/938 - Training loss: 0.0208 - Average Test loss: 0.0699\n",
      "  Batch 200/938 - Training loss: 0.0256 - Average Test loss: 0.0695\n",
      "  Batch 300/938 - Training loss: 0.0566 - Average Test loss: 0.0695\n",
      "  Batch 400/938 - Training loss: 0.0174 - Average Test loss: 0.0694\n",
      "  Batch 500/938 - Training loss: 0.0460 - Average Test loss: 0.0698\n",
      "  Batch 600/938 - Training loss: 0.0298 - Average Test loss: 0.0698\n",
      "  Batch 700/938 - Training loss: 0.0492 - Average Test loss: 0.0697\n",
      "  Batch 800/938 - Training loss: 0.0239 - Average Test loss: 0.0697\n",
      "  Batch 900/938 - Training loss: 0.0419 - Average Test loss: 0.0704\n",
      "Epoch = 252\n",
      "  Batch 0/938 - Training loss: 0.0489 - Average Test loss: 0.0697\n",
      "  Batch 100/938 - Training loss: 0.0245 - Average Test loss: 0.0700\n",
      "  Batch 200/938 - Training loss: 0.0169 - Average Test loss: 0.0696\n",
      "  Batch 300/938 - Training loss: 0.0226 - Average Test loss: 0.0702\n",
      "  Batch 400/938 - Training loss: 0.0329 - Average Test loss: 0.0696\n",
      "  Batch 500/938 - Training loss: 0.0371 - Average Test loss: 0.0697\n",
      "  Batch 600/938 - Training loss: 0.0233 - Average Test loss: 0.0695\n",
      "  Batch 700/938 - Training loss: 0.0290 - Average Test loss: 0.0693\n",
      "  Batch 800/938 - Training loss: 0.0316 - Average Test loss: 0.0697\n",
      "  Batch 900/938 - Training loss: 0.0072 - Average Test loss: 0.0697\n",
      "Epoch = 253\n",
      "  Batch 0/938 - Training loss: 0.0320 - Average Test loss: 0.0699\n",
      "  Batch 100/938 - Training loss: 0.0630 - Average Test loss: 0.0700\n",
      "  Batch 200/938 - Training loss: 0.0254 - Average Test loss: 0.0697\n",
      "  Batch 300/938 - Training loss: 0.0586 - Average Test loss: 0.0694\n",
      "  Batch 400/938 - Training loss: 0.0113 - Average Test loss: 0.0699\n",
      "  Batch 500/938 - Training loss: 0.0247 - Average Test loss: 0.0694\n",
      "  Batch 600/938 - Training loss: 0.0463 - Average Test loss: 0.0696\n",
      "  Batch 700/938 - Training loss: 0.0865 - Average Test loss: 0.0692\n",
      "  Batch 800/938 - Training loss: 0.0234 - Average Test loss: 0.0694\n",
      "  Batch 900/938 - Training loss: 0.0306 - Average Test loss: 0.0693\n",
      "Epoch = 254\n",
      "  Batch 0/938 - Training loss: 0.0662 - Average Test loss: 0.0699\n",
      "  Batch 100/938 - Training loss: 0.0358 - Average Test loss: 0.0703\n",
      "  Batch 200/938 - Training loss: 0.0232 - Average Test loss: 0.0699\n",
      "  Batch 300/938 - Training loss: 0.0518 - Average Test loss: 0.0694\n",
      "  Batch 400/938 - Training loss: 0.0182 - Average Test loss: 0.0693\n",
      "  Batch 500/938 - Training loss: 0.0212 - Average Test loss: 0.0694\n",
      "  Batch 600/938 - Training loss: 0.0237 - Average Test loss: 0.0692\n",
      "  Batch 700/938 - Training loss: 0.0108 - Average Test loss: 0.0692\n",
      "  Batch 800/938 - Training loss: 0.0267 - Average Test loss: 0.0694\n",
      "  Batch 900/938 - Training loss: 0.0340 - Average Test loss: 0.0693\n",
      "Epoch = 255\n",
      "  Batch 0/938 - Training loss: 0.0186 - Average Test loss: 0.0693\n",
      "  Batch 100/938 - Training loss: 0.0102 - Average Test loss: 0.0693\n",
      "  Batch 200/938 - Training loss: 0.1133 - Average Test loss: 0.0696\n",
      "  Batch 300/938 - Training loss: 0.0143 - Average Test loss: 0.0692\n",
      "  Batch 400/938 - Training loss: 0.0285 - Average Test loss: 0.0694\n",
      "  Batch 500/938 - Training loss: 0.0147 - Average Test loss: 0.0693\n",
      "  Batch 600/938 - Training loss: 0.0318 - Average Test loss: 0.0701\n",
      "  Batch 700/938 - Training loss: 0.0184 - Average Test loss: 0.0694\n",
      "  Batch 800/938 - Training loss: 0.0168 - Average Test loss: 0.0692\n",
      "  Batch 900/938 - Training loss: 0.0325 - Average Test loss: 0.0690\n",
      "Epoch = 256\n",
      "  Batch 0/938 - Training loss: 0.0221 - Average Test loss: 0.0692\n",
      "  Batch 100/938 - Training loss: 0.0237 - Average Test loss: 0.0697\n",
      "  Batch 200/938 - Training loss: 0.0188 - Average Test loss: 0.0696\n",
      "  Batch 300/938 - Training loss: 0.0289 - Average Test loss: 0.0691\n",
      "  Batch 400/938 - Training loss: 0.0283 - Average Test loss: 0.0694\n",
      "  Batch 500/938 - Training loss: 0.0533 - Average Test loss: 0.0693\n",
      "  Batch 600/938 - Training loss: 0.0284 - Average Test loss: 0.0691\n",
      "  Batch 700/938 - Training loss: 0.0152 - Average Test loss: 0.0689\n",
      "  Batch 800/938 - Training loss: 0.0226 - Average Test loss: 0.0690\n",
      "  Batch 900/938 - Training loss: 0.0215 - Average Test loss: 0.0693\n",
      "Epoch = 257\n",
      "  Batch 0/938 - Training loss: 0.0127 - Average Test loss: 0.0693\n",
      "  Batch 100/938 - Training loss: 0.0722 - Average Test loss: 0.0691\n",
      "  Batch 200/938 - Training loss: 0.0304 - Average Test loss: 0.0694\n",
      "  Batch 300/938 - Training loss: 0.0157 - Average Test loss: 0.0695\n",
      "  Batch 400/938 - Training loss: 0.0475 - Average Test loss: 0.0696\n",
      "  Batch 500/938 - Training loss: 0.0270 - Average Test loss: 0.0689\n",
      "  Batch 600/938 - Training loss: 0.0150 - Average Test loss: 0.0687\n",
      "  Batch 700/938 - Training loss: 0.1038 - Average Test loss: 0.0690\n",
      "  Batch 800/938 - Training loss: 0.0223 - Average Test loss: 0.0695\n",
      "  Batch 900/938 - Training loss: 0.0309 - Average Test loss: 0.0694\n",
      "Epoch = 258\n",
      "  Batch 0/938 - Training loss: 0.0314 - Average Test loss: 0.0690\n",
      "  Batch 100/938 - Training loss: 0.0339 - Average Test loss: 0.0694\n",
      "  Batch 200/938 - Training loss: 0.0453 - Average Test loss: 0.0697\n",
      "  Batch 300/938 - Training loss: 0.0145 - Average Test loss: 0.0689\n",
      "  Batch 400/938 - Training loss: 0.0121 - Average Test loss: 0.0690\n",
      "  Batch 500/938 - Training loss: 0.0070 - Average Test loss: 0.0692\n",
      "  Batch 600/938 - Training loss: 0.0230 - Average Test loss: 0.0690\n",
      "  Batch 700/938 - Training loss: 0.0164 - Average Test loss: 0.0693\n",
      "  Batch 800/938 - Training loss: 0.0176 - Average Test loss: 0.0693\n",
      "  Batch 900/938 - Training loss: 0.0258 - Average Test loss: 0.0687\n",
      "Epoch = 259\n",
      "  Batch 0/938 - Training loss: 0.0316 - Average Test loss: 0.0690\n",
      "  Batch 100/938 - Training loss: 0.0709 - Average Test loss: 0.0690\n",
      "  Batch 200/938 - Training loss: 0.0145 - Average Test loss: 0.0689\n",
      "  Batch 300/938 - Training loss: 0.0205 - Average Test loss: 0.0690\n",
      "  Batch 400/938 - Training loss: 0.0242 - Average Test loss: 0.0695\n",
      "  Batch 500/938 - Training loss: 0.0241 - Average Test loss: 0.0696\n",
      "  Batch 600/938 - Training loss: 0.0398 - Average Test loss: 0.0685\n",
      "  Batch 700/938 - Training loss: 0.0123 - Average Test loss: 0.0692\n",
      "  Batch 800/938 - Training loss: 0.0274 - Average Test loss: 0.0690\n",
      "  Batch 900/938 - Training loss: 0.0473 - Average Test loss: 0.0684\n",
      "Epoch = 260\n",
      "  Batch 0/938 - Training loss: 0.0178 - Average Test loss: 0.0692\n",
      "  Batch 100/938 - Training loss: 0.0329 - Average Test loss: 0.0693\n",
      "  Batch 200/938 - Training loss: 0.0097 - Average Test loss: 0.0689\n",
      "  Batch 300/938 - Training loss: 0.0216 - Average Test loss: 0.0696\n",
      "  Batch 400/938 - Training loss: 0.0224 - Average Test loss: 0.0687\n",
      "  Batch 500/938 - Training loss: 0.0241 - Average Test loss: 0.0687\n",
      "  Batch 600/938 - Training loss: 0.0507 - Average Test loss: 0.0688\n",
      "  Batch 700/938 - Training loss: 0.0626 - Average Test loss: 0.0691\n",
      "  Batch 800/938 - Training loss: 0.0359 - Average Test loss: 0.0686\n",
      "  Batch 900/938 - Training loss: 0.0234 - Average Test loss: 0.0687\n",
      "Epoch = 261\n",
      "  Batch 0/938 - Training loss: 0.0206 - Average Test loss: 0.0687\n",
      "  Batch 100/938 - Training loss: 0.0599 - Average Test loss: 0.0687\n",
      "  Batch 200/938 - Training loss: 0.0370 - Average Test loss: 0.0686\n",
      "  Batch 300/938 - Training loss: 0.0349 - Average Test loss: 0.0686\n",
      "  Batch 400/938 - Training loss: 0.0306 - Average Test loss: 0.0688\n",
      "  Batch 500/938 - Training loss: 0.0560 - Average Test loss: 0.0693\n",
      "  Batch 600/938 - Training loss: 0.0264 - Average Test loss: 0.0685\n",
      "  Batch 700/938 - Training loss: 0.0211 - Average Test loss: 0.0691\n",
      "  Batch 800/938 - Training loss: 0.1089 - Average Test loss: 0.0686\n",
      "  Batch 900/938 - Training loss: 0.0356 - Average Test loss: 0.0685\n",
      "Epoch = 262\n",
      "  Batch 0/938 - Training loss: 0.0279 - Average Test loss: 0.0685\n",
      "  Batch 100/938 - Training loss: 0.0445 - Average Test loss: 0.0686\n",
      "  Batch 200/938 - Training loss: 0.0257 - Average Test loss: 0.0684\n",
      "  Batch 300/938 - Training loss: 0.0326 - Average Test loss: 0.0688\n",
      "  Batch 400/938 - Training loss: 0.0290 - Average Test loss: 0.0688\n",
      "  Batch 500/938 - Training loss: 0.0259 - Average Test loss: 0.0685\n",
      "  Batch 600/938 - Training loss: 0.0082 - Average Test loss: 0.0685\n",
      "  Batch 700/938 - Training loss: 0.0133 - Average Test loss: 0.0696\n",
      "  Batch 800/938 - Training loss: 0.0661 - Average Test loss: 0.0688\n",
      "  Batch 900/938 - Training loss: 0.0591 - Average Test loss: 0.0688\n",
      "Epoch = 263\n",
      "  Batch 0/938 - Training loss: 0.0153 - Average Test loss: 0.0687\n",
      "  Batch 100/938 - Training loss: 0.0154 - Average Test loss: 0.0688\n",
      "  Batch 200/938 - Training loss: 0.0360 - Average Test loss: 0.0691\n",
      "  Batch 300/938 - Training loss: 0.0525 - Average Test loss: 0.0686\n",
      "  Batch 400/938 - Training loss: 0.0068 - Average Test loss: 0.0691\n",
      "  Batch 500/938 - Training loss: 0.0296 - Average Test loss: 0.0684\n",
      "  Batch 600/938 - Training loss: 0.0116 - Average Test loss: 0.0686\n",
      "  Batch 700/938 - Training loss: 0.0105 - Average Test loss: 0.0685\n",
      "  Batch 800/938 - Training loss: 0.0181 - Average Test loss: 0.0686\n",
      "  Batch 900/938 - Training loss: 0.0294 - Average Test loss: 0.0690\n",
      "Epoch = 264\n",
      "  Batch 0/938 - Training loss: 0.0234 - Average Test loss: 0.0693\n",
      "  Batch 100/938 - Training loss: 0.0254 - Average Test loss: 0.0686\n",
      "  Batch 200/938 - Training loss: 0.0385 - Average Test loss: 0.0687\n",
      "  Batch 300/938 - Training loss: 0.0161 - Average Test loss: 0.0685\n",
      "  Batch 400/938 - Training loss: 0.0343 - Average Test loss: 0.0683\n",
      "  Batch 500/938 - Training loss: 0.0904 - Average Test loss: 0.0688\n",
      "  Batch 600/938 - Training loss: 0.0232 - Average Test loss: 0.0683\n",
      "  Batch 700/938 - Training loss: 0.0295 - Average Test loss: 0.0686\n",
      "  Batch 800/938 - Training loss: 0.0521 - Average Test loss: 0.0685\n",
      "  Batch 900/938 - Training loss: 0.0207 - Average Test loss: 0.0686\n",
      "Epoch = 265\n",
      "  Batch 0/938 - Training loss: 0.0972 - Average Test loss: 0.0684\n",
      "  Batch 100/938 - Training loss: 0.0315 - Average Test loss: 0.0685\n",
      "  Batch 200/938 - Training loss: 0.0182 - Average Test loss: 0.0682\n",
      "  Batch 300/938 - Training loss: 0.0057 - Average Test loss: 0.0684\n",
      "  Batch 400/938 - Training loss: 0.0444 - Average Test loss: 0.0681\n",
      "  Batch 500/938 - Training loss: 0.0238 - Average Test loss: 0.0683\n",
      "  Batch 600/938 - Training loss: 0.0745 - Average Test loss: 0.0683\n",
      "  Batch 700/938 - Training loss: 0.0238 - Average Test loss: 0.0685\n",
      "  Batch 800/938 - Training loss: 0.0104 - Average Test loss: 0.0687\n",
      "  Batch 900/938 - Training loss: 0.0495 - Average Test loss: 0.0684\n",
      "Epoch = 266\n",
      "  Batch 0/938 - Training loss: 0.0435 - Average Test loss: 0.0685\n",
      "  Batch 100/938 - Training loss: 0.0144 - Average Test loss: 0.0687\n",
      "  Batch 200/938 - Training loss: 0.0464 - Average Test loss: 0.0686\n",
      "  Batch 300/938 - Training loss: 0.1365 - Average Test loss: 0.0681\n",
      "  Batch 400/938 - Training loss: 0.0454 - Average Test loss: 0.0681\n",
      "  Batch 500/938 - Training loss: 0.0534 - Average Test loss: 0.0685\n",
      "  Batch 600/938 - Training loss: 0.0199 - Average Test loss: 0.0683\n",
      "  Batch 700/938 - Training loss: 0.0471 - Average Test loss: 0.0681\n",
      "  Batch 800/938 - Training loss: 0.0122 - Average Test loss: 0.0687\n",
      "  Batch 900/938 - Training loss: 0.0451 - Average Test loss: 0.0685\n",
      "Epoch = 267\n",
      "  Batch 0/938 - Training loss: 0.0398 - Average Test loss: 0.0682\n",
      "  Batch 100/938 - Training loss: 0.0318 - Average Test loss: 0.0682\n",
      "  Batch 200/938 - Training loss: 0.0235 - Average Test loss: 0.0680\n",
      "  Batch 300/938 - Training loss: 0.0254 - Average Test loss: 0.0686\n",
      "  Batch 400/938 - Training loss: 0.0295 - Average Test loss: 0.0683\n",
      "  Batch 500/938 - Training loss: 0.0275 - Average Test loss: 0.0679\n",
      "  Batch 600/938 - Training loss: 0.1017 - Average Test loss: 0.0681\n",
      "  Batch 700/938 - Training loss: 0.0152 - Average Test loss: 0.0678\n",
      "  Batch 800/938 - Training loss: 0.0117 - Average Test loss: 0.0685\n",
      "  Batch 900/938 - Training loss: 0.0172 - Average Test loss: 0.0685\n",
      "Epoch = 268\n",
      "  Batch 0/938 - Training loss: 0.0263 - Average Test loss: 0.0685\n",
      "  Batch 100/938 - Training loss: 0.0152 - Average Test loss: 0.0684\n",
      "  Batch 200/938 - Training loss: 0.0252 - Average Test loss: 0.0684\n",
      "  Batch 300/938 - Training loss: 0.0375 - Average Test loss: 0.0682\n",
      "  Batch 400/938 - Training loss: 0.0092 - Average Test loss: 0.0687\n",
      "  Batch 500/938 - Training loss: 0.0442 - Average Test loss: 0.0683\n",
      "  Batch 600/938 - Training loss: 0.1377 - Average Test loss: 0.0680\n",
      "  Batch 700/938 - Training loss: 0.0287 - Average Test loss: 0.0678\n",
      "  Batch 800/938 - Training loss: 0.0244 - Average Test loss: 0.0683\n",
      "  Batch 900/938 - Training loss: 0.0202 - Average Test loss: 0.0683\n",
      "Epoch = 269\n",
      "  Batch 0/938 - Training loss: 0.0863 - Average Test loss: 0.0682\n",
      "  Batch 100/938 - Training loss: 0.0280 - Average Test loss: 0.0680\n",
      "  Batch 200/938 - Training loss: 0.0360 - Average Test loss: 0.0686\n",
      "  Batch 300/938 - Training loss: 0.0243 - Average Test loss: 0.0684\n",
      "  Batch 400/938 - Training loss: 0.0375 - Average Test loss: 0.0682\n",
      "  Batch 500/938 - Training loss: 0.0304 - Average Test loss: 0.0683\n",
      "  Batch 600/938 - Training loss: 0.0126 - Average Test loss: 0.0682\n",
      "  Batch 700/938 - Training loss: 0.0049 - Average Test loss: 0.0684\n",
      "  Batch 800/938 - Training loss: 0.0418 - Average Test loss: 0.0679\n",
      "  Batch 900/938 - Training loss: 0.0886 - Average Test loss: 0.0682\n",
      "Epoch = 270\n",
      "  Batch 0/938 - Training loss: 0.0184 - Average Test loss: 0.0678\n",
      "  Batch 100/938 - Training loss: 0.1158 - Average Test loss: 0.0678\n",
      "  Batch 200/938 - Training loss: 0.0611 - Average Test loss: 0.0682\n",
      "  Batch 300/938 - Training loss: 0.0405 - Average Test loss: 0.0683\n",
      "  Batch 400/938 - Training loss: 0.0370 - Average Test loss: 0.0679\n",
      "  Batch 500/938 - Training loss: 0.0191 - Average Test loss: 0.0678\n",
      "  Batch 600/938 - Training loss: 0.0176 - Average Test loss: 0.0678\n",
      "  Batch 700/938 - Training loss: 0.0793 - Average Test loss: 0.0679\n",
      "  Batch 800/938 - Training loss: 0.0200 - Average Test loss: 0.0680\n",
      "  Batch 900/938 - Training loss: 0.0627 - Average Test loss: 0.0680\n",
      "Epoch = 271\n",
      "  Batch 0/938 - Training loss: 0.0324 - Average Test loss: 0.0686\n",
      "  Batch 100/938 - Training loss: 0.0287 - Average Test loss: 0.0685\n",
      "  Batch 200/938 - Training loss: 0.0244 - Average Test loss: 0.0677\n",
      "  Batch 300/938 - Training loss: 0.0227 - Average Test loss: 0.0676\n",
      "  Batch 400/938 - Training loss: 0.0130 - Average Test loss: 0.0676\n",
      "  Batch 500/938 - Training loss: 0.0423 - Average Test loss: 0.0678\n",
      "  Batch 600/938 - Training loss: 0.0707 - Average Test loss: 0.0680\n",
      "  Batch 700/938 - Training loss: 0.1173 - Average Test loss: 0.0681\n",
      "  Batch 800/938 - Training loss: 0.0260 - Average Test loss: 0.0681\n",
      "  Batch 900/938 - Training loss: 0.0113 - Average Test loss: 0.0679\n",
      "Epoch = 272\n",
      "  Batch 0/938 - Training loss: 0.0469 - Average Test loss: 0.0679\n",
      "  Batch 100/938 - Training loss: 0.0191 - Average Test loss: 0.0675\n",
      "  Batch 200/938 - Training loss: 0.0253 - Average Test loss: 0.0681\n",
      "  Batch 300/938 - Training loss: 0.0098 - Average Test loss: 0.0677\n",
      "  Batch 400/938 - Training loss: 0.0135 - Average Test loss: 0.0683\n",
      "  Batch 500/938 - Training loss: 0.0219 - Average Test loss: 0.0679\n",
      "  Batch 600/938 - Training loss: 0.1044 - Average Test loss: 0.0680\n",
      "  Batch 700/938 - Training loss: 0.0366 - Average Test loss: 0.0677\n",
      "  Batch 800/938 - Training loss: 0.1103 - Average Test loss: 0.0679\n",
      "  Batch 900/938 - Training loss: 0.0653 - Average Test loss: 0.0678\n",
      "Epoch = 273\n",
      "  Batch 0/938 - Training loss: 0.0157 - Average Test loss: 0.0681\n",
      "  Batch 100/938 - Training loss: 0.0422 - Average Test loss: 0.0688\n",
      "  Batch 200/938 - Training loss: 0.0142 - Average Test loss: 0.0681\n",
      "  Batch 300/938 - Training loss: 0.0368 - Average Test loss: 0.0680\n",
      "  Batch 400/938 - Training loss: 0.0333 - Average Test loss: 0.0677\n",
      "  Batch 500/938 - Training loss: 0.0420 - Average Test loss: 0.0677\n",
      "  Batch 600/938 - Training loss: 0.0539 - Average Test loss: 0.0675\n",
      "  Batch 700/938 - Training loss: 0.0260 - Average Test loss: 0.0676\n",
      "  Batch 800/938 - Training loss: 0.0321 - Average Test loss: 0.0675\n",
      "  Batch 900/938 - Training loss: 0.0291 - Average Test loss: 0.0678\n",
      "Epoch = 274\n",
      "  Batch 0/938 - Training loss: 0.0093 - Average Test loss: 0.0675\n",
      "  Batch 100/938 - Training loss: 0.0101 - Average Test loss: 0.0675\n",
      "  Batch 200/938 - Training loss: 0.0326 - Average Test loss: 0.0678\n",
      "  Batch 300/938 - Training loss: 0.0146 - Average Test loss: 0.0678\n",
      "  Batch 400/938 - Training loss: 0.0213 - Average Test loss: 0.0676\n",
      "  Batch 500/938 - Training loss: 0.0129 - Average Test loss: 0.0677\n",
      "  Batch 600/938 - Training loss: 0.0361 - Average Test loss: 0.0676\n",
      "  Batch 700/938 - Training loss: 0.0426 - Average Test loss: 0.0680\n",
      "  Batch 800/938 - Training loss: 0.0303 - Average Test loss: 0.0676\n",
      "  Batch 900/938 - Training loss: 0.0898 - Average Test loss: 0.0678\n",
      "Epoch = 275\n",
      "  Batch 0/938 - Training loss: 0.0233 - Average Test loss: 0.0676\n",
      "  Batch 100/938 - Training loss: 0.0084 - Average Test loss: 0.0676\n",
      "  Batch 200/938 - Training loss: 0.0082 - Average Test loss: 0.0677\n",
      "  Batch 300/938 - Training loss: 0.0309 - Average Test loss: 0.0680\n",
      "  Batch 400/938 - Training loss: 0.0266 - Average Test loss: 0.0678\n",
      "  Batch 500/938 - Training loss: 0.0121 - Average Test loss: 0.0673\n",
      "  Batch 600/938 - Training loss: 0.0152 - Average Test loss: 0.0674\n",
      "  Batch 700/938 - Training loss: 0.0354 - Average Test loss: 0.0673\n",
      "  Batch 800/938 - Training loss: 0.0620 - Average Test loss: 0.0677\n",
      "  Batch 900/938 - Training loss: 0.0430 - Average Test loss: 0.0675\n",
      "Epoch = 276\n",
      "  Batch 0/938 - Training loss: 0.0380 - Average Test loss: 0.0677\n",
      "  Batch 100/938 - Training loss: 0.0098 - Average Test loss: 0.0674\n",
      "  Batch 200/938 - Training loss: 0.0267 - Average Test loss: 0.0677\n",
      "  Batch 300/938 - Training loss: 0.0590 - Average Test loss: 0.0673\n",
      "  Batch 400/938 - Training loss: 0.0943 - Average Test loss: 0.0678\n",
      "  Batch 500/938 - Training loss: 0.0345 - Average Test loss: 0.0672\n",
      "  Batch 600/938 - Training loss: 0.0172 - Average Test loss: 0.0672\n",
      "  Batch 700/938 - Training loss: 0.0242 - Average Test loss: 0.0674\n",
      "  Batch 800/938 - Training loss: 0.0258 - Average Test loss: 0.0678\n",
      "  Batch 900/938 - Training loss: 0.0306 - Average Test loss: 0.0675\n",
      "Epoch = 277\n",
      "  Batch 0/938 - Training loss: 0.0209 - Average Test loss: 0.0675\n",
      "  Batch 100/938 - Training loss: 0.0363 - Average Test loss: 0.0678\n",
      "  Batch 200/938 - Training loss: 0.0318 - Average Test loss: 0.0675\n",
      "  Batch 300/938 - Training loss: 0.0112 - Average Test loss: 0.0682\n",
      "  Batch 400/938 - Training loss: 0.0468 - Average Test loss: 0.0674\n",
      "  Batch 500/938 - Training loss: 0.0449 - Average Test loss: 0.0675\n",
      "  Batch 600/938 - Training loss: 0.0475 - Average Test loss: 0.0674\n",
      "  Batch 700/938 - Training loss: 0.0244 - Average Test loss: 0.0678\n",
      "  Batch 800/938 - Training loss: 0.0335 - Average Test loss: 0.0674\n",
      "  Batch 900/938 - Training loss: 0.0331 - Average Test loss: 0.0673\n",
      "Epoch = 278\n",
      "  Batch 0/938 - Training loss: 0.0200 - Average Test loss: 0.0673\n",
      "  Batch 100/938 - Training loss: 0.0088 - Average Test loss: 0.0673\n",
      "  Batch 200/938 - Training loss: 0.0560 - Average Test loss: 0.0674\n",
      "  Batch 300/938 - Training loss: 0.0471 - Average Test loss: 0.0673\n",
      "  Batch 400/938 - Training loss: 0.0166 - Average Test loss: 0.0673\n",
      "  Batch 500/938 - Training loss: 0.0223 - Average Test loss: 0.0672\n",
      "  Batch 600/938 - Training loss: 0.0325 - Average Test loss: 0.0673\n",
      "  Batch 700/938 - Training loss: 0.0162 - Average Test loss: 0.0676\n",
      "  Batch 800/938 - Training loss: 0.0036 - Average Test loss: 0.0671\n",
      "  Batch 900/938 - Training loss: 0.0473 - Average Test loss: 0.0672\n",
      "Epoch = 279\n",
      "  Batch 0/938 - Training loss: 0.0411 - Average Test loss: 0.0673\n",
      "  Batch 100/938 - Training loss: 0.0175 - Average Test loss: 0.0676\n",
      "  Batch 200/938 - Training loss: 0.0598 - Average Test loss: 0.0673\n",
      "  Batch 300/938 - Training loss: 0.0443 - Average Test loss: 0.0670\n",
      "  Batch 400/938 - Training loss: 0.0164 - Average Test loss: 0.0673\n",
      "  Batch 500/938 - Training loss: 0.0334 - Average Test loss: 0.0673\n",
      "  Batch 600/938 - Training loss: 0.0050 - Average Test loss: 0.0672\n",
      "  Batch 700/938 - Training loss: 0.0185 - Average Test loss: 0.0672\n",
      "  Batch 800/938 - Training loss: 0.0249 - Average Test loss: 0.0669\n",
      "  Batch 900/938 - Training loss: 0.0209 - Average Test loss: 0.0678\n",
      "Epoch = 280\n",
      "  Batch 0/938 - Training loss: 0.0207 - Average Test loss: 0.0680\n",
      "  Batch 100/938 - Training loss: 0.0090 - Average Test loss: 0.0675\n",
      "  Batch 200/938 - Training loss: 0.0206 - Average Test loss: 0.0672\n",
      "  Batch 300/938 - Training loss: 0.0123 - Average Test loss: 0.0674\n",
      "  Batch 400/938 - Training loss: 0.0472 - Average Test loss: 0.0675\n",
      "  Batch 500/938 - Training loss: 0.0368 - Average Test loss: 0.0672\n",
      "  Batch 600/938 - Training loss: 0.0283 - Average Test loss: 0.0671\n",
      "  Batch 700/938 - Training loss: 0.0322 - Average Test loss: 0.0669\n",
      "  Batch 800/938 - Training loss: 0.0061 - Average Test loss: 0.0675\n",
      "  Batch 900/938 - Training loss: 0.0204 - Average Test loss: 0.0673\n",
      "Epoch = 281\n",
      "  Batch 0/938 - Training loss: 0.0114 - Average Test loss: 0.0675\n",
      "  Batch 100/938 - Training loss: 0.0240 - Average Test loss: 0.0673\n",
      "  Batch 200/938 - Training loss: 0.0098 - Average Test loss: 0.0669\n",
      "  Batch 300/938 - Training loss: 0.0723 - Average Test loss: 0.0675\n",
      "  Batch 400/938 - Training loss: 0.0297 - Average Test loss: 0.0672\n",
      "  Batch 500/938 - Training loss: 0.0201 - Average Test loss: 0.0673\n",
      "  Batch 600/938 - Training loss: 0.0367 - Average Test loss: 0.0672\n",
      "  Batch 700/938 - Training loss: 0.0332 - Average Test loss: 0.0676\n",
      "  Batch 800/938 - Training loss: 0.0221 - Average Test loss: 0.0672\n",
      "  Batch 900/938 - Training loss: 0.0279 - Average Test loss: 0.0672\n",
      "Epoch = 282\n",
      "  Batch 0/938 - Training loss: 0.0211 - Average Test loss: 0.0674\n",
      "  Batch 100/938 - Training loss: 0.0368 - Average Test loss: 0.0670\n",
      "  Batch 200/938 - Training loss: 0.0179 - Average Test loss: 0.0667\n",
      "  Batch 300/938 - Training loss: 0.0713 - Average Test loss: 0.0667\n",
      "  Batch 400/938 - Training loss: 0.0105 - Average Test loss: 0.0669\n",
      "  Batch 500/938 - Training loss: 0.1100 - Average Test loss: 0.0669\n",
      "  Batch 600/938 - Training loss: 0.0140 - Average Test loss: 0.0670\n",
      "  Batch 700/938 - Training loss: 0.0185 - Average Test loss: 0.0672\n",
      "  Batch 800/938 - Training loss: 0.0068 - Average Test loss: 0.0670\n",
      "  Batch 900/938 - Training loss: 0.0276 - Average Test loss: 0.0677\n",
      "Epoch = 283\n",
      "  Batch 0/938 - Training loss: 0.0306 - Average Test loss: 0.0672\n",
      "  Batch 100/938 - Training loss: 0.0233 - Average Test loss: 0.0671\n",
      "  Batch 200/938 - Training loss: 0.0192 - Average Test loss: 0.0668\n",
      "  Batch 300/938 - Training loss: 0.1019 - Average Test loss: 0.0667\n",
      "  Batch 400/938 - Training loss: 0.0954 - Average Test loss: 0.0669\n",
      "  Batch 500/938 - Training loss: 0.0611 - Average Test loss: 0.0674\n",
      "  Batch 600/938 - Training loss: 0.0134 - Average Test loss: 0.0675\n",
      "  Batch 700/938 - Training loss: 0.0146 - Average Test loss: 0.0674\n",
      "  Batch 800/938 - Training loss: 0.0242 - Average Test loss: 0.0673\n",
      "  Batch 900/938 - Training loss: 0.0222 - Average Test loss: 0.0669\n",
      "Epoch = 284\n",
      "  Batch 0/938 - Training loss: 0.0224 - Average Test loss: 0.0669\n",
      "  Batch 100/938 - Training loss: 0.0408 - Average Test loss: 0.0670\n",
      "  Batch 200/938 - Training loss: 0.0300 - Average Test loss: 0.0669\n",
      "  Batch 300/938 - Training loss: 0.0376 - Average Test loss: 0.0665\n",
      "  Batch 400/938 - Training loss: 0.0216 - Average Test loss: 0.0670\n",
      "  Batch 500/938 - Training loss: 0.0622 - Average Test loss: 0.0669\n",
      "  Batch 600/938 - Training loss: 0.0219 - Average Test loss: 0.0670\n",
      "  Batch 700/938 - Training loss: 0.0169 - Average Test loss: 0.0673\n",
      "  Batch 800/938 - Training loss: 0.0524 - Average Test loss: 0.0671\n",
      "  Batch 900/938 - Training loss: 0.0326 - Average Test loss: 0.0672\n",
      "Epoch = 285\n",
      "  Batch 0/938 - Training loss: 0.0103 - Average Test loss: 0.0671\n",
      "  Batch 100/938 - Training loss: 0.0347 - Average Test loss: 0.0667\n",
      "  Batch 200/938 - Training loss: 0.0172 - Average Test loss: 0.0670\n",
      "  Batch 300/938 - Training loss: 0.0172 - Average Test loss: 0.0669\n",
      "  Batch 400/938 - Training loss: 0.0169 - Average Test loss: 0.0667\n",
      "  Batch 500/938 - Training loss: 0.0305 - Average Test loss: 0.0671\n",
      "  Batch 600/938 - Training loss: 0.0112 - Average Test loss: 0.0668\n",
      "  Batch 700/938 - Training loss: 0.0131 - Average Test loss: 0.0665\n",
      "  Batch 800/938 - Training loss: 0.0310 - Average Test loss: 0.0666\n",
      "  Batch 900/938 - Training loss: 0.1393 - Average Test loss: 0.0667\n",
      "Epoch = 286\n",
      "  Batch 0/938 - Training loss: 0.0751 - Average Test loss: 0.0671\n",
      "  Batch 100/938 - Training loss: 0.0276 - Average Test loss: 0.0670\n",
      "  Batch 200/938 - Training loss: 0.0113 - Average Test loss: 0.0668\n",
      "  Batch 300/938 - Training loss: 0.0317 - Average Test loss: 0.0667\n",
      "  Batch 400/938 - Training loss: 0.0233 - Average Test loss: 0.0671\n",
      "  Batch 500/938 - Training loss: 0.0139 - Average Test loss: 0.0668\n",
      "  Batch 600/938 - Training loss: 0.0155 - Average Test loss: 0.0670\n",
      "  Batch 700/938 - Training loss: 0.0105 - Average Test loss: 0.0672\n",
      "  Batch 800/938 - Training loss: 0.0221 - Average Test loss: 0.0666\n",
      "  Batch 900/938 - Training loss: 0.0059 - Average Test loss: 0.0670\n",
      "Epoch = 287\n",
      "  Batch 0/938 - Training loss: 0.0145 - Average Test loss: 0.0666\n",
      "  Batch 100/938 - Training loss: 0.0367 - Average Test loss: 0.0664\n",
      "  Batch 200/938 - Training loss: 0.0292 - Average Test loss: 0.0671\n",
      "  Batch 300/938 - Training loss: 0.0378 - Average Test loss: 0.0668\n",
      "  Batch 400/938 - Training loss: 0.0289 - Average Test loss: 0.0665\n",
      "  Batch 500/938 - Training loss: 0.0300 - Average Test loss: 0.0665\n",
      "  Batch 600/938 - Training loss: 0.0143 - Average Test loss: 0.0666\n",
      "  Batch 700/938 - Training loss: 0.0505 - Average Test loss: 0.0668\n",
      "  Batch 800/938 - Training loss: 0.0270 - Average Test loss: 0.0666\n",
      "  Batch 900/938 - Training loss: 0.0187 - Average Test loss: 0.0666\n",
      "Epoch = 288\n",
      "  Batch 0/938 - Training loss: 0.0099 - Average Test loss: 0.0664\n",
      "  Batch 100/938 - Training loss: 0.0192 - Average Test loss: 0.0667\n",
      "  Batch 200/938 - Training loss: 0.0445 - Average Test loss: 0.0665\n",
      "  Batch 300/938 - Training loss: 0.0134 - Average Test loss: 0.0670\n",
      "  Batch 400/938 - Training loss: 0.0217 - Average Test loss: 0.0672\n",
      "  Batch 500/938 - Training loss: 0.0545 - Average Test loss: 0.0670\n",
      "  Batch 600/938 - Training loss: 0.0140 - Average Test loss: 0.0664\n",
      "  Batch 700/938 - Training loss: 0.0138 - Average Test loss: 0.0665\n",
      "  Batch 800/938 - Training loss: 0.0195 - Average Test loss: 0.0669\n",
      "  Batch 900/938 - Training loss: 0.0238 - Average Test loss: 0.0665\n",
      "Epoch = 289\n",
      "  Batch 0/938 - Training loss: 0.0165 - Average Test loss: 0.0669\n",
      "  Batch 100/938 - Training loss: 0.0173 - Average Test loss: 0.0670\n",
      "  Batch 200/938 - Training loss: 0.0430 - Average Test loss: 0.0670\n",
      "  Batch 300/938 - Training loss: 0.0376 - Average Test loss: 0.0665\n",
      "  Batch 400/938 - Training loss: 0.0181 - Average Test loss: 0.0666\n",
      "  Batch 500/938 - Training loss: 0.0425 - Average Test loss: 0.0667\n",
      "  Batch 600/938 - Training loss: 0.0239 - Average Test loss: 0.0663\n",
      "  Batch 700/938 - Training loss: 0.0045 - Average Test loss: 0.0666\n",
      "  Batch 800/938 - Training loss: 0.0180 - Average Test loss: 0.0668\n",
      "  Batch 900/938 - Training loss: 0.0098 - Average Test loss: 0.0666\n",
      "Epoch = 290\n",
      "  Batch 0/938 - Training loss: 0.0271 - Average Test loss: 0.0663\n",
      "  Batch 100/938 - Training loss: 0.0156 - Average Test loss: 0.0664\n",
      "  Batch 200/938 - Training loss: 0.0071 - Average Test loss: 0.0664\n",
      "  Batch 300/938 - Training loss: 0.0168 - Average Test loss: 0.0666\n",
      "  Batch 400/938 - Training loss: 0.0115 - Average Test loss: 0.0663\n",
      "  Batch 500/938 - Training loss: 0.0154 - Average Test loss: 0.0666\n",
      "  Batch 600/938 - Training loss: 0.0069 - Average Test loss: 0.0665\n",
      "  Batch 700/938 - Training loss: 0.0442 - Average Test loss: 0.0663\n",
      "  Batch 800/938 - Training loss: 0.0594 - Average Test loss: 0.0667\n",
      "  Batch 900/938 - Training loss: 0.0163 - Average Test loss: 0.0665\n",
      "Epoch = 291\n",
      "  Batch 0/938 - Training loss: 0.0474 - Average Test loss: 0.0663\n",
      "  Batch 100/938 - Training loss: 0.0085 - Average Test loss: 0.0667\n",
      "  Batch 200/938 - Training loss: 0.0184 - Average Test loss: 0.0665\n",
      "  Batch 300/938 - Training loss: 0.0866 - Average Test loss: 0.0663\n",
      "  Batch 400/938 - Training loss: 0.0394 - Average Test loss: 0.0666\n",
      "  Batch 500/938 - Training loss: 0.0181 - Average Test loss: 0.0664\n",
      "  Batch 600/938 - Training loss: 0.0349 - Average Test loss: 0.0663\n",
      "  Batch 700/938 - Training loss: 0.0329 - Average Test loss: 0.0663\n",
      "  Batch 800/938 - Training loss: 0.0246 - Average Test loss: 0.0667\n",
      "  Batch 900/938 - Training loss: 0.0058 - Average Test loss: 0.0663\n",
      "Epoch = 292\n",
      "  Batch 0/938 - Training loss: 0.0278 - Average Test loss: 0.0662\n",
      "  Batch 100/938 - Training loss: 0.0129 - Average Test loss: 0.0665\n",
      "  Batch 200/938 - Training loss: 0.0329 - Average Test loss: 0.0666\n",
      "  Batch 300/938 - Training loss: 0.0289 - Average Test loss: 0.0665\n",
      "  Batch 400/938 - Training loss: 0.0193 - Average Test loss: 0.0664\n",
      "  Batch 500/938 - Training loss: 0.0181 - Average Test loss: 0.0665\n",
      "  Batch 600/938 - Training loss: 0.0372 - Average Test loss: 0.0663\n",
      "  Batch 700/938 - Training loss: 0.0164 - Average Test loss: 0.0662\n",
      "  Batch 800/938 - Training loss: 0.0491 - Average Test loss: 0.0660\n",
      "  Batch 900/938 - Training loss: 0.0127 - Average Test loss: 0.0662\n",
      "Epoch = 293\n",
      "  Batch 0/938 - Training loss: 0.0148 - Average Test loss: 0.0662\n",
      "  Batch 100/938 - Training loss: 0.0360 - Average Test loss: 0.0666\n",
      "  Batch 200/938 - Training loss: 0.0053 - Average Test loss: 0.0663\n",
      "  Batch 300/938 - Training loss: 0.0200 - Average Test loss: 0.0661\n",
      "  Batch 400/938 - Training loss: 0.0112 - Average Test loss: 0.0667\n",
      "  Batch 500/938 - Training loss: 0.0276 - Average Test loss: 0.0662\n",
      "  Batch 600/938 - Training loss: 0.0138 - Average Test loss: 0.0664\n",
      "  Batch 700/938 - Training loss: 0.0197 - Average Test loss: 0.0662\n",
      "  Batch 800/938 - Training loss: 0.1072 - Average Test loss: 0.0664\n",
      "  Batch 900/938 - Training loss: 0.0048 - Average Test loss: 0.0664\n",
      "Epoch = 294\n",
      "  Batch 0/938 - Training loss: 0.0542 - Average Test loss: 0.0665\n",
      "  Batch 100/938 - Training loss: 0.0226 - Average Test loss: 0.0664\n",
      "  Batch 200/938 - Training loss: 0.0271 - Average Test loss: 0.0664\n",
      "  Batch 300/938 - Training loss: 0.0052 - Average Test loss: 0.0667\n",
      "  Batch 400/938 - Training loss: 0.0741 - Average Test loss: 0.0666\n",
      "  Batch 500/938 - Training loss: 0.0415 - Average Test loss: 0.0667\n",
      "  Batch 600/938 - Training loss: 0.0137 - Average Test loss: 0.0666\n",
      "  Batch 700/938 - Training loss: 0.0050 - Average Test loss: 0.0663\n",
      "  Batch 800/938 - Training loss: 0.0110 - Average Test loss: 0.0661\n",
      "  Batch 900/938 - Training loss: 0.0164 - Average Test loss: 0.0663\n",
      "Epoch = 295\n",
      "  Batch 0/938 - Training loss: 0.0246 - Average Test loss: 0.0660\n",
      "  Batch 100/938 - Training loss: 0.0560 - Average Test loss: 0.0662\n",
      "  Batch 200/938 - Training loss: 0.0314 - Average Test loss: 0.0662\n",
      "  Batch 300/938 - Training loss: 0.0173 - Average Test loss: 0.0660\n",
      "  Batch 400/938 - Training loss: 0.0099 - Average Test loss: 0.0659\n",
      "  Batch 500/938 - Training loss: 0.0459 - Average Test loss: 0.0665\n",
      "  Batch 600/938 - Training loss: 0.0212 - Average Test loss: 0.0663\n",
      "  Batch 700/938 - Training loss: 0.0133 - Average Test loss: 0.0662\n",
      "  Batch 800/938 - Training loss: 0.0164 - Average Test loss: 0.0662\n",
      "  Batch 900/938 - Training loss: 0.0231 - Average Test loss: 0.0660\n",
      "Epoch = 296\n",
      "  Batch 0/938 - Training loss: 0.0171 - Average Test loss: 0.0662\n",
      "  Batch 100/938 - Training loss: 0.0090 - Average Test loss: 0.0663\n",
      "  Batch 200/938 - Training loss: 0.0506 - Average Test loss: 0.0665\n",
      "  Batch 300/938 - Training loss: 0.0069 - Average Test loss: 0.0659\n",
      "  Batch 400/938 - Training loss: 0.0620 - Average Test loss: 0.0662\n",
      "  Batch 500/938 - Training loss: 0.0145 - Average Test loss: 0.0662\n",
      "  Batch 600/938 - Training loss: 0.0507 - Average Test loss: 0.0659\n",
      "  Batch 700/938 - Training loss: 0.0500 - Average Test loss: 0.0659\n",
      "  Batch 800/938 - Training loss: 0.0123 - Average Test loss: 0.0662\n",
      "  Batch 900/938 - Training loss: 0.0149 - Average Test loss: 0.0661\n",
      "Epoch = 297\n",
      "  Batch 0/938 - Training loss: 0.0204 - Average Test loss: 0.0660\n",
      "  Batch 100/938 - Training loss: 0.0317 - Average Test loss: 0.0659\n",
      "  Batch 200/938 - Training loss: 0.0225 - Average Test loss: 0.0660\n",
      "  Batch 300/938 - Training loss: 0.0258 - Average Test loss: 0.0662\n",
      "  Batch 400/938 - Training loss: 0.0195 - Average Test loss: 0.0658\n",
      "  Batch 500/938 - Training loss: 0.0273 - Average Test loss: 0.0661\n",
      "  Batch 600/938 - Training loss: 0.0373 - Average Test loss: 0.0660\n",
      "  Batch 700/938 - Training loss: 0.0307 - Average Test loss: 0.0657\n",
      "  Batch 800/938 - Training loss: 0.0069 - Average Test loss: 0.0663\n",
      "  Batch 900/938 - Training loss: 0.0153 - Average Test loss: 0.0662\n",
      "Epoch = 298\n",
      "  Batch 0/938 - Training loss: 0.0210 - Average Test loss: 0.0664\n",
      "  Batch 100/938 - Training loss: 0.0198 - Average Test loss: 0.0665\n",
      "  Batch 200/938 - Training loss: 0.0223 - Average Test loss: 0.0664\n",
      "  Batch 300/938 - Training loss: 0.0105 - Average Test loss: 0.0665\n",
      "  Batch 400/938 - Training loss: 0.0114 - Average Test loss: 0.0660\n",
      "  Batch 500/938 - Training loss: 0.0342 - Average Test loss: 0.0659\n",
      "  Batch 600/938 - Training loss: 0.0117 - Average Test loss: 0.0661\n",
      "  Batch 700/938 - Training loss: 0.0261 - Average Test loss: 0.0659\n",
      "  Batch 800/938 - Training loss: 0.0191 - Average Test loss: 0.0662\n",
      "  Batch 900/938 - Training loss: 0.0267 - Average Test loss: 0.0658\n",
      "Epoch = 299\n",
      "  Batch 0/938 - Training loss: 0.0121 - Average Test loss: 0.0657\n",
      "  Batch 100/938 - Training loss: 0.1158 - Average Test loss: 0.0661\n",
      "  Batch 200/938 - Training loss: 0.0195 - Average Test loss: 0.0658\n",
      "  Batch 300/938 - Training loss: 0.0305 - Average Test loss: 0.0658\n",
      "  Batch 400/938 - Training loss: 0.0098 - Average Test loss: 0.0660\n",
      "  Batch 500/938 - Training loss: 0.0413 - Average Test loss: 0.0659\n",
      "  Batch 600/938 - Training loss: 0.0175 - Average Test loss: 0.0661\n",
      "  Batch 700/938 - Training loss: 0.0345 - Average Test loss: 0.0656\n",
      "  Batch 800/938 - Training loss: 0.0389 - Average Test loss: 0.0658\n",
      "  Batch 900/938 - Training loss: 0.0635 - Average Test loss: 0.0657\n",
      "Epoch = 300\n",
      "  Batch 0/938 - Training loss: 0.0566 - Average Test loss: 0.0663\n",
      "  Batch 100/938 - Training loss: 0.0422 - Average Test loss: 0.0658\n",
      "  Batch 200/938 - Training loss: 0.0184 - Average Test loss: 0.0657\n",
      "  Batch 300/938 - Training loss: 0.0354 - Average Test loss: 0.0659\n",
      "  Batch 400/938 - Training loss: 0.0943 - Average Test loss: 0.0658\n",
      "  Batch 500/938 - Training loss: 0.0049 - Average Test loss: 0.0660\n",
      "  Batch 600/938 - Training loss: 0.0100 - Average Test loss: 0.0666\n",
      "  Batch 700/938 - Training loss: 0.0575 - Average Test loss: 0.0656\n",
      "  Batch 800/938 - Training loss: 0.0235 - Average Test loss: 0.0657\n",
      "  Batch 900/938 - Training loss: 0.0299 - Average Test loss: 0.0659\n",
      "Epoch = 301\n",
      "  Batch 0/938 - Training loss: 0.0588 - Average Test loss: 0.0661\n",
      "  Batch 100/938 - Training loss: 0.1047 - Average Test loss: 0.0660\n",
      "  Batch 200/938 - Training loss: 0.0223 - Average Test loss: 0.0658\n",
      "  Batch 300/938 - Training loss: 0.0659 - Average Test loss: 0.0658\n",
      "  Batch 400/938 - Training loss: 0.0407 - Average Test loss: 0.0659\n",
      "  Batch 500/938 - Training loss: 0.0193 - Average Test loss: 0.0663\n",
      "  Batch 600/938 - Training loss: 0.0094 - Average Test loss: 0.0658\n",
      "  Batch 700/938 - Training loss: 0.0230 - Average Test loss: 0.0659\n",
      "  Batch 800/938 - Training loss: 0.0410 - Average Test loss: 0.0660\n",
      "  Batch 900/938 - Training loss: 0.0087 - Average Test loss: 0.0657\n",
      "Epoch = 302\n",
      "  Batch 0/938 - Training loss: 0.0074 - Average Test loss: 0.0660\n",
      "  Batch 100/938 - Training loss: 0.0225 - Average Test loss: 0.0659\n",
      "  Batch 200/938 - Training loss: 0.0288 - Average Test loss: 0.0655\n",
      "  Batch 300/938 - Training loss: 0.0236 - Average Test loss: 0.0655\n",
      "  Batch 400/938 - Training loss: 0.0220 - Average Test loss: 0.0659\n",
      "  Batch 500/938 - Training loss: 0.0078 - Average Test loss: 0.0661\n",
      "  Batch 600/938 - Training loss: 0.0030 - Average Test loss: 0.0659\n",
      "  Batch 700/938 - Training loss: 0.0278 - Average Test loss: 0.0655\n",
      "  Batch 800/938 - Training loss: 0.0270 - Average Test loss: 0.0660\n",
      "  Batch 900/938 - Training loss: 0.0612 - Average Test loss: 0.0656\n",
      "Epoch = 303\n",
      "  Batch 0/938 - Training loss: 0.0247 - Average Test loss: 0.0658\n",
      "  Batch 100/938 - Training loss: 0.0288 - Average Test loss: 0.0657\n",
      "  Batch 200/938 - Training loss: 0.0270 - Average Test loss: 0.0658\n",
      "  Batch 300/938 - Training loss: 0.0253 - Average Test loss: 0.0668\n",
      "  Batch 400/938 - Training loss: 0.0132 - Average Test loss: 0.0658\n",
      "  Batch 500/938 - Training loss: 0.0077 - Average Test loss: 0.0655\n",
      "  Batch 600/938 - Training loss: 0.0484 - Average Test loss: 0.0655\n",
      "  Batch 700/938 - Training loss: 0.0079 - Average Test loss: 0.0655\n",
      "  Batch 800/938 - Training loss: 0.0421 - Average Test loss: 0.0658\n",
      "  Batch 900/938 - Training loss: 0.0237 - Average Test loss: 0.0657\n",
      "Epoch = 304\n",
      "  Batch 0/938 - Training loss: 0.0100 - Average Test loss: 0.0656\n",
      "  Batch 100/938 - Training loss: 0.0137 - Average Test loss: 0.0657\n",
      "  Batch 200/938 - Training loss: 0.0317 - Average Test loss: 0.0658\n",
      "  Batch 300/938 - Training loss: 0.0304 - Average Test loss: 0.0657\n",
      "  Batch 400/938 - Training loss: 0.0157 - Average Test loss: 0.0657\n",
      "  Batch 500/938 - Training loss: 0.0209 - Average Test loss: 0.0658\n",
      "  Batch 600/938 - Training loss: 0.0111 - Average Test loss: 0.0660\n",
      "  Batch 700/938 - Training loss: 0.0371 - Average Test loss: 0.0656\n",
      "  Batch 800/938 - Training loss: 0.0179 - Average Test loss: 0.0654\n",
      "  Batch 900/938 - Training loss: 0.0218 - Average Test loss: 0.0655\n",
      "Epoch = 305\n",
      "  Batch 0/938 - Training loss: 0.0277 - Average Test loss: 0.0654\n",
      "  Batch 100/938 - Training loss: 0.0214 - Average Test loss: 0.0655\n",
      "  Batch 200/938 - Training loss: 0.0295 - Average Test loss: 0.0661\n",
      "  Batch 300/938 - Training loss: 0.0071 - Average Test loss: 0.0660\n",
      "  Batch 400/938 - Training loss: 0.0547 - Average Test loss: 0.0656\n",
      "  Batch 500/938 - Training loss: 0.0175 - Average Test loss: 0.0658\n",
      "  Batch 600/938 - Training loss: 0.0145 - Average Test loss: 0.0654\n",
      "  Batch 700/938 - Training loss: 0.0098 - Average Test loss: 0.0656\n",
      "  Batch 800/938 - Training loss: 0.0498 - Average Test loss: 0.0656\n",
      "  Batch 900/938 - Training loss: 0.0231 - Average Test loss: 0.0656\n",
      "Epoch = 306\n",
      "  Batch 0/938 - Training loss: 0.0346 - Average Test loss: 0.0657\n",
      "  Batch 100/938 - Training loss: 0.0387 - Average Test loss: 0.0659\n",
      "  Batch 200/938 - Training loss: 0.0253 - Average Test loss: 0.0656\n",
      "  Batch 300/938 - Training loss: 0.0445 - Average Test loss: 0.0658\n",
      "  Batch 400/938 - Training loss: 0.1108 - Average Test loss: 0.0662\n",
      "  Batch 500/938 - Training loss: 0.0210 - Average Test loss: 0.0655\n",
      "  Batch 600/938 - Training loss: 0.0234 - Average Test loss: 0.0655\n",
      "  Batch 700/938 - Training loss: 0.0246 - Average Test loss: 0.0654\n",
      "  Batch 800/938 - Training loss: 0.0138 - Average Test loss: 0.0653\n",
      "  Batch 900/938 - Training loss: 0.0160 - Average Test loss: 0.0655\n",
      "Epoch = 307\n",
      "  Batch 0/938 - Training loss: 0.0350 - Average Test loss: 0.0654\n",
      "  Batch 100/938 - Training loss: 0.0168 - Average Test loss: 0.0657\n",
      "  Batch 200/938 - Training loss: 0.0143 - Average Test loss: 0.0656\n",
      "  Batch 300/938 - Training loss: 0.0439 - Average Test loss: 0.0656\n",
      "  Batch 400/938 - Training loss: 0.0241 - Average Test loss: 0.0657\n",
      "  Batch 500/938 - Training loss: 0.0433 - Average Test loss: 0.0655\n",
      "  Batch 600/938 - Training loss: 0.0270 - Average Test loss: 0.0653\n",
      "  Batch 700/938 - Training loss: 0.0160 - Average Test loss: 0.0653\n",
      "  Batch 800/938 - Training loss: 0.0913 - Average Test loss: 0.0650\n",
      "  Batch 900/938 - Training loss: 0.0203 - Average Test loss: 0.0652\n",
      "Epoch = 308\n",
      "  Batch 0/938 - Training loss: 0.0154 - Average Test loss: 0.0653\n",
      "  Batch 100/938 - Training loss: 0.0260 - Average Test loss: 0.0654\n",
      "  Batch 200/938 - Training loss: 0.0254 - Average Test loss: 0.0655\n",
      "  Batch 300/938 - Training loss: 0.0221 - Average Test loss: 0.0655\n",
      "  Batch 400/938 - Training loss: 0.0264 - Average Test loss: 0.0660\n",
      "  Batch 500/938 - Training loss: 0.0511 - Average Test loss: 0.0655\n",
      "  Batch 600/938 - Training loss: 0.0159 - Average Test loss: 0.0653\n",
      "  Batch 700/938 - Training loss: 0.0172 - Average Test loss: 0.0652\n",
      "  Batch 800/938 - Training loss: 0.0114 - Average Test loss: 0.0655\n",
      "  Batch 900/938 - Training loss: 0.0231 - Average Test loss: 0.0654\n",
      "Epoch = 309\n",
      "  Batch 0/938 - Training loss: 0.0785 - Average Test loss: 0.0652\n",
      "  Batch 100/938 - Training loss: 0.0262 - Average Test loss: 0.0654\n",
      "  Batch 200/938 - Training loss: 0.0088 - Average Test loss: 0.0655\n",
      "  Batch 300/938 - Training loss: 0.0468 - Average Test loss: 0.0654\n",
      "  Batch 400/938 - Training loss: 0.0201 - Average Test loss: 0.0655\n",
      "  Batch 500/938 - Training loss: 0.0306 - Average Test loss: 0.0652\n",
      "  Batch 600/938 - Training loss: 0.0103 - Average Test loss: 0.0657\n",
      "  Batch 700/938 - Training loss: 0.0137 - Average Test loss: 0.0652\n",
      "  Batch 800/938 - Training loss: 0.0119 - Average Test loss: 0.0652\n",
      "  Batch 900/938 - Training loss: 0.0177 - Average Test loss: 0.0654\n",
      "Epoch = 310\n",
      "  Batch 0/938 - Training loss: 0.0400 - Average Test loss: 0.0653\n",
      "  Batch 100/938 - Training loss: 0.0407 - Average Test loss: 0.0652\n",
      "  Batch 200/938 - Training loss: 0.0281 - Average Test loss: 0.0654\n",
      "  Batch 300/938 - Training loss: 0.0248 - Average Test loss: 0.0652\n",
      "  Batch 400/938 - Training loss: 0.0085 - Average Test loss: 0.0652\n",
      "  Batch 500/938 - Training loss: 0.0268 - Average Test loss: 0.0653\n",
      "  Batch 600/938 - Training loss: 0.0443 - Average Test loss: 0.0652\n",
      "  Batch 700/938 - Training loss: 0.0144 - Average Test loss: 0.0655\n",
      "  Batch 800/938 - Training loss: 0.0212 - Average Test loss: 0.0654\n",
      "  Batch 900/938 - Training loss: 0.0443 - Average Test loss: 0.0652\n",
      "Epoch = 311\n",
      "  Batch 0/938 - Training loss: 0.0183 - Average Test loss: 0.0654\n",
      "  Batch 100/938 - Training loss: 0.0689 - Average Test loss: 0.0651\n",
      "  Batch 200/938 - Training loss: 0.0056 - Average Test loss: 0.0653\n",
      "  Batch 300/938 - Training loss: 0.0376 - Average Test loss: 0.0651\n",
      "  Batch 400/938 - Training loss: 0.0088 - Average Test loss: 0.0655\n",
      "  Batch 500/938 - Training loss: 0.0275 - Average Test loss: 0.0657\n",
      "  Batch 600/938 - Training loss: 0.1044 - Average Test loss: 0.0655\n",
      "  Batch 700/938 - Training loss: 0.0767 - Average Test loss: 0.0657\n",
      "  Batch 800/938 - Training loss: 0.0762 - Average Test loss: 0.0653\n",
      "  Batch 900/938 - Training loss: 0.0243 - Average Test loss: 0.0651\n",
      "Epoch = 312\n",
      "  Batch 0/938 - Training loss: 0.0142 - Average Test loss: 0.0651\n",
      "  Batch 100/938 - Training loss: 0.0113 - Average Test loss: 0.0651\n",
      "  Batch 200/938 - Training loss: 0.0099 - Average Test loss: 0.0653\n",
      "  Batch 300/938 - Training loss: 0.0093 - Average Test loss: 0.0652\n",
      "  Batch 400/938 - Training loss: 0.0199 - Average Test loss: 0.0651\n",
      "  Batch 500/938 - Training loss: 0.0216 - Average Test loss: 0.0651\n",
      "  Batch 600/938 - Training loss: 0.0127 - Average Test loss: 0.0653\n",
      "  Batch 700/938 - Training loss: 0.0317 - Average Test loss: 0.0652\n",
      "  Batch 800/938 - Training loss: 0.0114 - Average Test loss: 0.0649\n",
      "  Batch 900/938 - Training loss: 0.0174 - Average Test loss: 0.0651\n",
      "Epoch = 313\n",
      "  Batch 0/938 - Training loss: 0.0220 - Average Test loss: 0.0653\n",
      "  Batch 100/938 - Training loss: 0.0091 - Average Test loss: 0.0651\n",
      "  Batch 200/938 - Training loss: 0.0064 - Average Test loss: 0.0649\n",
      "  Batch 300/938 - Training loss: 0.0188 - Average Test loss: 0.0649\n",
      "  Batch 400/938 - Training loss: 0.0037 - Average Test loss: 0.0656\n",
      "  Batch 500/938 - Training loss: 0.0181 - Average Test loss: 0.0653\n",
      "  Batch 600/938 - Training loss: 0.0150 - Average Test loss: 0.0651\n",
      "  Batch 700/938 - Training loss: 0.0303 - Average Test loss: 0.0651\n",
      "  Batch 800/938 - Training loss: 0.0525 - Average Test loss: 0.0650\n",
      "  Batch 900/938 - Training loss: 0.0096 - Average Test loss: 0.0657\n",
      "Epoch = 314\n",
      "  Batch 0/938 - Training loss: 0.0576 - Average Test loss: 0.0654\n",
      "  Batch 100/938 - Training loss: 0.0080 - Average Test loss: 0.0650\n",
      "  Batch 200/938 - Training loss: 0.0246 - Average Test loss: 0.0652\n",
      "  Batch 300/938 - Training loss: 0.0452 - Average Test loss: 0.0653\n",
      "  Batch 400/938 - Training loss: 0.0254 - Average Test loss: 0.0652\n",
      "  Batch 500/938 - Training loss: 0.0145 - Average Test loss: 0.0652\n",
      "  Batch 600/938 - Training loss: 0.0322 - Average Test loss: 0.0653\n",
      "  Batch 700/938 - Training loss: 0.0324 - Average Test loss: 0.0650\n",
      "  Batch 800/938 - Training loss: 0.0189 - Average Test loss: 0.0653\n",
      "  Batch 900/938 - Training loss: 0.0270 - Average Test loss: 0.0652\n",
      "Epoch = 315\n",
      "  Batch 0/938 - Training loss: 0.0051 - Average Test loss: 0.0650\n",
      "  Batch 100/938 - Training loss: 0.0044 - Average Test loss: 0.0650\n",
      "  Batch 200/938 - Training loss: 0.0103 - Average Test loss: 0.0651\n",
      "  Batch 300/938 - Training loss: 0.0189 - Average Test loss: 0.0650\n",
      "  Batch 400/938 - Training loss: 0.0208 - Average Test loss: 0.0650\n",
      "  Batch 500/938 - Training loss: 0.0108 - Average Test loss: 0.0657\n",
      "  Batch 600/938 - Training loss: 0.0359 - Average Test loss: 0.0649\n",
      "  Batch 700/938 - Training loss: 0.0498 - Average Test loss: 0.0653\n",
      "  Batch 800/938 - Training loss: 0.0157 - Average Test loss: 0.0650\n",
      "  Batch 900/938 - Training loss: 0.0320 - Average Test loss: 0.0648\n",
      "Epoch = 316\n",
      "  Batch 0/938 - Training loss: 0.0086 - Average Test loss: 0.0648\n",
      "  Batch 100/938 - Training loss: 0.0101 - Average Test loss: 0.0647\n",
      "  Batch 200/938 - Training loss: 0.0416 - Average Test loss: 0.0648\n",
      "  Batch 300/938 - Training loss: 0.0382 - Average Test loss: 0.0647\n",
      "  Batch 400/938 - Training loss: 0.0299 - Average Test loss: 0.0649\n",
      "  Batch 500/938 - Training loss: 0.0097 - Average Test loss: 0.0658\n",
      "  Batch 600/938 - Training loss: 0.0242 - Average Test loss: 0.0651\n",
      "  Batch 700/938 - Training loss: 0.0158 - Average Test loss: 0.0651\n",
      "  Batch 800/938 - Training loss: 0.0216 - Average Test loss: 0.0650\n",
      "  Batch 900/938 - Training loss: 0.0065 - Average Test loss: 0.0652\n",
      "Epoch = 317\n",
      "  Batch 0/938 - Training loss: 0.0107 - Average Test loss: 0.0654\n",
      "  Batch 100/938 - Training loss: 0.0107 - Average Test loss: 0.0651\n",
      "  Batch 200/938 - Training loss: 0.0054 - Average Test loss: 0.0649\n",
      "  Batch 300/938 - Training loss: 0.0528 - Average Test loss: 0.0648\n",
      "  Batch 400/938 - Training loss: 0.0076 - Average Test loss: 0.0651\n",
      "  Batch 500/938 - Training loss: 0.0280 - Average Test loss: 0.0649\n",
      "  Batch 600/938 - Training loss: 0.0591 - Average Test loss: 0.0647\n",
      "  Batch 700/938 - Training loss: 0.0174 - Average Test loss: 0.0649\n",
      "  Batch 800/938 - Training loss: 0.0434 - Average Test loss: 0.0651\n",
      "  Batch 900/938 - Training loss: 0.0192 - Average Test loss: 0.0648\n",
      "Epoch = 318\n",
      "  Batch 0/938 - Training loss: 0.0144 - Average Test loss: 0.0650\n",
      "  Batch 100/938 - Training loss: 0.0156 - Average Test loss: 0.0651\n",
      "  Batch 200/938 - Training loss: 0.0357 - Average Test loss: 0.0647\n",
      "  Batch 300/938 - Training loss: 0.0062 - Average Test loss: 0.0649\n",
      "  Batch 400/938 - Training loss: 0.0160 - Average Test loss: 0.0646\n",
      "  Batch 500/938 - Training loss: 0.1206 - Average Test loss: 0.0646\n",
      "  Batch 600/938 - Training loss: 0.0255 - Average Test loss: 0.0650\n",
      "  Batch 700/938 - Training loss: 0.0103 - Average Test loss: 0.0656\n",
      "  Batch 800/938 - Training loss: 0.0148 - Average Test loss: 0.0649\n",
      "  Batch 900/938 - Training loss: 0.0333 - Average Test loss: 0.0653\n",
      "Epoch = 319\n",
      "  Batch 0/938 - Training loss: 0.0169 - Average Test loss: 0.0649\n",
      "  Batch 100/938 - Training loss: 0.0232 - Average Test loss: 0.0647\n",
      "  Batch 200/938 - Training loss: 0.0295 - Average Test loss: 0.0650\n",
      "  Batch 300/938 - Training loss: 0.0182 - Average Test loss: 0.0650\n",
      "  Batch 400/938 - Training loss: 0.0660 - Average Test loss: 0.0650\n",
      "  Batch 500/938 - Training loss: 0.0327 - Average Test loss: 0.0650\n",
      "  Batch 600/938 - Training loss: 0.0245 - Average Test loss: 0.0649\n",
      "  Batch 700/938 - Training loss: 0.0133 - Average Test loss: 0.0646\n",
      "  Batch 800/938 - Training loss: 0.0752 - Average Test loss: 0.0647\n",
      "  Batch 900/938 - Training loss: 0.0202 - Average Test loss: 0.0650\n",
      "Epoch = 320\n",
      "  Batch 0/938 - Training loss: 0.0151 - Average Test loss: 0.0654\n",
      "  Batch 100/938 - Training loss: 0.0100 - Average Test loss: 0.0649\n",
      "  Batch 200/938 - Training loss: 0.0204 - Average Test loss: 0.0648\n",
      "  Batch 300/938 - Training loss: 0.0238 - Average Test loss: 0.0648\n",
      "  Batch 400/938 - Training loss: 0.0130 - Average Test loss: 0.0647\n",
      "  Batch 500/938 - Training loss: 0.0107 - Average Test loss: 0.0651\n",
      "  Batch 600/938 - Training loss: 0.0103 - Average Test loss: 0.0652\n",
      "  Batch 700/938 - Training loss: 0.0164 - Average Test loss: 0.0645\n",
      "  Batch 800/938 - Training loss: 0.0239 - Average Test loss: 0.0647\n",
      "  Batch 900/938 - Training loss: 0.0198 - Average Test loss: 0.0647\n",
      "Epoch = 321\n",
      "  Batch 0/938 - Training loss: 0.0078 - Average Test loss: 0.0648\n",
      "  Batch 100/938 - Training loss: 0.0100 - Average Test loss: 0.0649\n",
      "  Batch 200/938 - Training loss: 0.0295 - Average Test loss: 0.0646\n",
      "  Batch 300/938 - Training loss: 0.0272 - Average Test loss: 0.0645\n",
      "  Batch 400/938 - Training loss: 0.0529 - Average Test loss: 0.0647\n",
      "  Batch 500/938 - Training loss: 0.2398 - Average Test loss: 0.0648\n",
      "  Batch 600/938 - Training loss: 0.0108 - Average Test loss: 0.0647\n",
      "  Batch 700/938 - Training loss: 0.0388 - Average Test loss: 0.0645\n",
      "  Batch 800/938 - Training loss: 0.0062 - Average Test loss: 0.0647\n",
      "  Batch 900/938 - Training loss: 0.0138 - Average Test loss: 0.0649\n",
      "Epoch = 322\n",
      "  Batch 0/938 - Training loss: 0.0097 - Average Test loss: 0.0648\n",
      "  Batch 100/938 - Training loss: 0.0216 - Average Test loss: 0.0648\n",
      "  Batch 200/938 - Training loss: 0.0275 - Average Test loss: 0.0652\n",
      "  Batch 300/938 - Training loss: 0.0094 - Average Test loss: 0.0645\n",
      "  Batch 400/938 - Training loss: 0.0285 - Average Test loss: 0.0644\n",
      "  Batch 500/938 - Training loss: 0.0624 - Average Test loss: 0.0647\n",
      "  Batch 600/938 - Training loss: 0.0128 - Average Test loss: 0.0645\n",
      "  Batch 700/938 - Training loss: 0.0411 - Average Test loss: 0.0644\n",
      "  Batch 800/938 - Training loss: 0.0144 - Average Test loss: 0.0646\n",
      "  Batch 900/938 - Training loss: 0.0215 - Average Test loss: 0.0646\n",
      "Epoch = 323\n",
      "  Batch 0/938 - Training loss: 0.0224 - Average Test loss: 0.0647\n",
      "  Batch 100/938 - Training loss: 0.0316 - Average Test loss: 0.0650\n",
      "  Batch 200/938 - Training loss: 0.0145 - Average Test loss: 0.0647\n",
      "  Batch 300/938 - Training loss: 0.0813 - Average Test loss: 0.0643\n",
      "  Batch 400/938 - Training loss: 0.0110 - Average Test loss: 0.0646\n",
      "  Batch 500/938 - Training loss: 0.0243 - Average Test loss: 0.0645\n",
      "  Batch 600/938 - Training loss: 0.0190 - Average Test loss: 0.0648\n",
      "  Batch 700/938 - Training loss: 0.0114 - Average Test loss: 0.0647\n",
      "  Batch 800/938 - Training loss: 0.0167 - Average Test loss: 0.0643\n",
      "  Batch 900/938 - Training loss: 0.0159 - Average Test loss: 0.0644\n",
      "Epoch = 324\n",
      "  Batch 0/938 - Training loss: 0.0065 - Average Test loss: 0.0646\n",
      "  Batch 100/938 - Training loss: 0.0271 - Average Test loss: 0.0647\n",
      "  Batch 200/938 - Training loss: 0.0130 - Average Test loss: 0.0646\n",
      "  Batch 300/938 - Training loss: 0.0461 - Average Test loss: 0.0645\n",
      "  Batch 400/938 - Training loss: 0.0087 - Average Test loss: 0.0649\n",
      "  Batch 500/938 - Training loss: 0.0142 - Average Test loss: 0.0647\n",
      "  Batch 600/938 - Training loss: 0.0138 - Average Test loss: 0.0649\n",
      "  Batch 700/938 - Training loss: 0.0075 - Average Test loss: 0.0644\n",
      "  Batch 800/938 - Training loss: 0.0410 - Average Test loss: 0.0643\n",
      "  Batch 900/938 - Training loss: 0.0029 - Average Test loss: 0.0644\n",
      "Epoch = 325\n",
      "  Batch 0/938 - Training loss: 0.0182 - Average Test loss: 0.0643\n",
      "  Batch 100/938 - Training loss: 0.0153 - Average Test loss: 0.0643\n",
      "  Batch 200/938 - Training loss: 0.0413 - Average Test loss: 0.0647\n",
      "  Batch 300/938 - Training loss: 0.0088 - Average Test loss: 0.0644\n",
      "  Batch 400/938 - Training loss: 0.0194 - Average Test loss: 0.0649\n",
      "  Batch 500/938 - Training loss: 0.0246 - Average Test loss: 0.0646\n",
      "  Batch 600/938 - Training loss: 0.0723 - Average Test loss: 0.0644\n",
      "  Batch 700/938 - Training loss: 0.0296 - Average Test loss: 0.0645\n",
      "  Batch 800/938 - Training loss: 0.0322 - Average Test loss: 0.0647\n",
      "  Batch 900/938 - Training loss: 0.0117 - Average Test loss: 0.0647\n",
      "Epoch = 326\n",
      "  Batch 0/938 - Training loss: 0.0113 - Average Test loss: 0.0644\n",
      "  Batch 100/938 - Training loss: 0.0081 - Average Test loss: 0.0643\n",
      "  Batch 200/938 - Training loss: 0.0191 - Average Test loss: 0.0644\n",
      "  Batch 300/938 - Training loss: 0.0261 - Average Test loss: 0.0643\n",
      "  Batch 400/938 - Training loss: 0.0211 - Average Test loss: 0.0645\n",
      "  Batch 500/938 - Training loss: 0.0390 - Average Test loss: 0.0644\n",
      "  Batch 600/938 - Training loss: 0.0203 - Average Test loss: 0.0646\n",
      "  Batch 700/938 - Training loss: 0.0129 - Average Test loss: 0.0644\n",
      "  Batch 800/938 - Training loss: 0.0119 - Average Test loss: 0.0644\n",
      "  Batch 900/938 - Training loss: 0.0158 - Average Test loss: 0.0647\n",
      "Epoch = 327\n",
      "  Batch 0/938 - Training loss: 0.0112 - Average Test loss: 0.0646\n",
      "  Batch 100/938 - Training loss: 0.0144 - Average Test loss: 0.0644\n",
      "  Batch 200/938 - Training loss: 0.0117 - Average Test loss: 0.0644\n",
      "  Batch 300/938 - Training loss: 0.0148 - Average Test loss: 0.0646\n",
      "  Batch 400/938 - Training loss: 0.0067 - Average Test loss: 0.0643\n",
      "  Batch 500/938 - Training loss: 0.0052 - Average Test loss: 0.0644\n",
      "  Batch 600/938 - Training loss: 0.0220 - Average Test loss: 0.0644\n",
      "  Batch 700/938 - Training loss: 0.0259 - Average Test loss: 0.0645\n",
      "  Batch 800/938 - Training loss: 0.0083 - Average Test loss: 0.0647\n",
      "  Batch 900/938 - Training loss: 0.0198 - Average Test loss: 0.0648\n",
      "Epoch = 328\n",
      "  Batch 0/938 - Training loss: 0.0055 - Average Test loss: 0.0647\n",
      "  Batch 100/938 - Training loss: 0.0180 - Average Test loss: 0.0643\n",
      "  Batch 200/938 - Training loss: 0.0059 - Average Test loss: 0.0649\n",
      "  Batch 300/938 - Training loss: 0.0176 - Average Test loss: 0.0642\n",
      "  Batch 400/938 - Training loss: 0.0346 - Average Test loss: 0.0644\n",
      "  Batch 500/938 - Training loss: 0.0127 - Average Test loss: 0.0642\n",
      "  Batch 600/938 - Training loss: 0.0188 - Average Test loss: 0.0643\n",
      "  Batch 700/938 - Training loss: 0.0191 - Average Test loss: 0.0645\n",
      "  Batch 800/938 - Training loss: 0.0098 - Average Test loss: 0.0649\n",
      "  Batch 900/938 - Training loss: 0.0175 - Average Test loss: 0.0644\n",
      "Epoch = 329\n",
      "  Batch 0/938 - Training loss: 0.0104 - Average Test loss: 0.0645\n",
      "  Batch 100/938 - Training loss: 0.0574 - Average Test loss: 0.0643\n",
      "  Batch 200/938 - Training loss: 0.0273 - Average Test loss: 0.0644\n",
      "  Batch 300/938 - Training loss: 0.0323 - Average Test loss: 0.0644\n",
      "  Batch 400/938 - Training loss: 0.0600 - Average Test loss: 0.0643\n",
      "  Batch 500/938 - Training loss: 0.0091 - Average Test loss: 0.0648\n",
      "  Batch 600/938 - Training loss: 0.0167 - Average Test loss: 0.0644\n",
      "  Batch 700/938 - Training loss: 0.0141 - Average Test loss: 0.0642\n",
      "  Batch 800/938 - Training loss: 0.0235 - Average Test loss: 0.0644\n",
      "  Batch 900/938 - Training loss: 0.0270 - Average Test loss: 0.0643\n",
      "Epoch = 330\n",
      "  Batch 0/938 - Training loss: 0.0211 - Average Test loss: 0.0641\n",
      "  Batch 100/938 - Training loss: 0.0192 - Average Test loss: 0.0644\n",
      "  Batch 200/938 - Training loss: 0.0303 - Average Test loss: 0.0646\n",
      "  Batch 300/938 - Training loss: 0.0797 - Average Test loss: 0.0642\n",
      "  Batch 400/938 - Training loss: 0.0258 - Average Test loss: 0.0647\n",
      "  Batch 500/938 - Training loss: 0.0126 - Average Test loss: 0.0641\n",
      "  Batch 600/938 - Training loss: 0.0170 - Average Test loss: 0.0642\n",
      "  Batch 700/938 - Training loss: 0.0039 - Average Test loss: 0.0642\n",
      "  Batch 800/938 - Training loss: 0.0231 - Average Test loss: 0.0642\n",
      "  Batch 900/938 - Training loss: 0.0256 - Average Test loss: 0.0642\n",
      "Epoch = 331\n",
      "  Batch 0/938 - Training loss: 0.0116 - Average Test loss: 0.0645\n",
      "  Batch 100/938 - Training loss: 0.0244 - Average Test loss: 0.0643\n",
      "  Batch 200/938 - Training loss: 0.0141 - Average Test loss: 0.0643\n",
      "  Batch 300/938 - Training loss: 0.0360 - Average Test loss: 0.0650\n",
      "  Batch 400/938 - Training loss: 0.0058 - Average Test loss: 0.0644\n",
      "  Batch 500/938 - Training loss: 0.0044 - Average Test loss: 0.0643\n",
      "  Batch 600/938 - Training loss: 0.0546 - Average Test loss: 0.0643\n",
      "  Batch 700/938 - Training loss: 0.0238 - Average Test loss: 0.0642\n",
      "  Batch 800/938 - Training loss: 0.0087 - Average Test loss: 0.0642\n",
      "  Batch 900/938 - Training loss: 0.0184 - Average Test loss: 0.0643\n",
      "Epoch = 332\n",
      "  Batch 0/938 - Training loss: 0.0267 - Average Test loss: 0.0643\n",
      "  Batch 100/938 - Training loss: 0.0103 - Average Test loss: 0.0646\n",
      "  Batch 200/938 - Training loss: 0.0086 - Average Test loss: 0.0645\n",
      "  Batch 300/938 - Training loss: 0.0116 - Average Test loss: 0.0645\n",
      "  Batch 400/938 - Training loss: 0.0073 - Average Test loss: 0.0643\n",
      "  Batch 500/938 - Training loss: 0.0066 - Average Test loss: 0.0643\n",
      "  Batch 600/938 - Training loss: 0.0089 - Average Test loss: 0.0640\n",
      "  Batch 700/938 - Training loss: 0.0532 - Average Test loss: 0.0641\n",
      "  Batch 800/938 - Training loss: 0.0514 - Average Test loss: 0.0643\n",
      "  Batch 900/938 - Training loss: 0.0413 - Average Test loss: 0.0642\n",
      "Epoch = 333\n",
      "  Batch 0/938 - Training loss: 0.0079 - Average Test loss: 0.0644\n",
      "  Batch 100/938 - Training loss: 0.0159 - Average Test loss: 0.0641\n",
      "  Batch 200/938 - Training loss: 0.0056 - Average Test loss: 0.0643\n",
      "  Batch 300/938 - Training loss: 0.0290 - Average Test loss: 0.0643\n",
      "  Batch 400/938 - Training loss: 0.0034 - Average Test loss: 0.0636\n",
      "  Batch 500/938 - Training loss: 0.0133 - Average Test loss: 0.0645\n",
      "  Batch 600/938 - Training loss: 0.0191 - Average Test loss: 0.0642\n",
      "  Batch 700/938 - Training loss: 0.0611 - Average Test loss: 0.0638\n",
      "  Batch 800/938 - Training loss: 0.0142 - Average Test loss: 0.0637\n",
      "  Batch 900/938 - Training loss: 0.0053 - Average Test loss: 0.0642\n",
      "Epoch = 334\n",
      "  Batch 0/938 - Training loss: 0.0173 - Average Test loss: 0.0641\n",
      "  Batch 100/938 - Training loss: 0.0171 - Average Test loss: 0.0641\n",
      "  Batch 200/938 - Training loss: 0.0117 - Average Test loss: 0.0642\n",
      "  Batch 300/938 - Training loss: 0.0378 - Average Test loss: 0.0644\n",
      "  Batch 400/938 - Training loss: 0.0055 - Average Test loss: 0.0640\n",
      "  Batch 500/938 - Training loss: 0.0188 - Average Test loss: 0.0643\n",
      "  Batch 600/938 - Training loss: 0.0187 - Average Test loss: 0.0638\n",
      "  Batch 700/938 - Training loss: 0.0165 - Average Test loss: 0.0642\n",
      "  Batch 800/938 - Training loss: 0.0217 - Average Test loss: 0.0644\n",
      "  Batch 900/938 - Training loss: 0.0118 - Average Test loss: 0.0641\n",
      "Epoch = 335\n",
      "  Batch 0/938 - Training loss: 0.0100 - Average Test loss: 0.0641\n",
      "  Batch 100/938 - Training loss: 0.0178 - Average Test loss: 0.0641\n",
      "  Batch 200/938 - Training loss: 0.0156 - Average Test loss: 0.0646\n",
      "  Batch 300/938 - Training loss: 0.0150 - Average Test loss: 0.0643\n",
      "  Batch 400/938 - Training loss: 0.0109 - Average Test loss: 0.0642\n",
      "  Batch 500/938 - Training loss: 0.0107 - Average Test loss: 0.0645\n",
      "  Batch 600/938 - Training loss: 0.0067 - Average Test loss: 0.0641\n",
      "  Batch 700/938 - Training loss: 0.0165 - Average Test loss: 0.0639\n",
      "  Batch 800/938 - Training loss: 0.0202 - Average Test loss: 0.0641\n",
      "  Batch 900/938 - Training loss: 0.0095 - Average Test loss: 0.0643\n",
      "Epoch = 336\n",
      "  Batch 0/938 - Training loss: 0.0081 - Average Test loss: 0.0640\n",
      "  Batch 100/938 - Training loss: 0.0097 - Average Test loss: 0.0642\n",
      "  Batch 200/938 - Training loss: 0.0283 - Average Test loss: 0.0639\n",
      "  Batch 300/938 - Training loss: 0.0793 - Average Test loss: 0.0640\n",
      "  Batch 400/938 - Training loss: 0.0191 - Average Test loss: 0.0643\n",
      "  Batch 500/938 - Training loss: 0.0914 - Average Test loss: 0.0642\n",
      "  Batch 600/938 - Training loss: 0.0500 - Average Test loss: 0.0640\n",
      "  Batch 700/938 - Training loss: 0.0296 - Average Test loss: 0.0639\n",
      "  Batch 800/938 - Training loss: 0.0218 - Average Test loss: 0.0639\n",
      "  Batch 900/938 - Training loss: 0.0215 - Average Test loss: 0.0641\n",
      "Epoch = 337\n",
      "  Batch 0/938 - Training loss: 0.0102 - Average Test loss: 0.0642\n",
      "  Batch 100/938 - Training loss: 0.0302 - Average Test loss: 0.0641\n",
      "  Batch 200/938 - Training loss: 0.0120 - Average Test loss: 0.0641\n",
      "  Batch 300/938 - Training loss: 0.0129 - Average Test loss: 0.0642\n",
      "  Batch 400/938 - Training loss: 0.1539 - Average Test loss: 0.0639\n",
      "  Batch 500/938 - Training loss: 0.0152 - Average Test loss: 0.0643\n",
      "  Batch 600/938 - Training loss: 0.0246 - Average Test loss: 0.0642\n",
      "  Batch 700/938 - Training loss: 0.0211 - Average Test loss: 0.0643\n",
      "  Batch 800/938 - Training loss: 0.0090 - Average Test loss: 0.0642\n",
      "  Batch 900/938 - Training loss: 0.0210 - Average Test loss: 0.0641\n",
      "Epoch = 338\n",
      "  Batch 0/938 - Training loss: 0.0287 - Average Test loss: 0.0641\n",
      "  Batch 100/938 - Training loss: 0.0096 - Average Test loss: 0.0643\n",
      "  Batch 200/938 - Training loss: 0.0038 - Average Test loss: 0.0639\n",
      "  Batch 300/938 - Training loss: 0.0256 - Average Test loss: 0.0639\n",
      "  Batch 400/938 - Training loss: 0.0065 - Average Test loss: 0.0638\n",
      "  Batch 500/938 - Training loss: 0.0149 - Average Test loss: 0.0640\n",
      "  Batch 600/938 - Training loss: 0.0053 - Average Test loss: 0.0640\n",
      "  Batch 700/938 - Training loss: 0.0617 - Average Test loss: 0.0638\n",
      "  Batch 800/938 - Training loss: 0.0333 - Average Test loss: 0.0640\n",
      "  Batch 900/938 - Training loss: 0.0125 - Average Test loss: 0.0640\n",
      "Epoch = 339\n",
      "  Batch 0/938 - Training loss: 0.0091 - Average Test loss: 0.0641\n",
      "  Batch 100/938 - Training loss: 0.0453 - Average Test loss: 0.0639\n",
      "  Batch 200/938 - Training loss: 0.0384 - Average Test loss: 0.0638\n",
      "  Batch 300/938 - Training loss: 0.0262 - Average Test loss: 0.0639\n",
      "  Batch 400/938 - Training loss: 0.0389 - Average Test loss: 0.0641\n",
      "  Batch 500/938 - Training loss: 0.0050 - Average Test loss: 0.0642\n",
      "  Batch 600/938 - Training loss: 0.0111 - Average Test loss: 0.0639\n",
      "  Batch 700/938 - Training loss: 0.0126 - Average Test loss: 0.0640\n",
      "  Batch 800/938 - Training loss: 0.0251 - Average Test loss: 0.0641\n",
      "  Batch 900/938 - Training loss: 0.0069 - Average Test loss: 0.0639\n",
      "Epoch = 340\n",
      "  Batch 0/938 - Training loss: 0.0078 - Average Test loss: 0.0638\n",
      "  Batch 100/938 - Training loss: 0.0111 - Average Test loss: 0.0637\n",
      "  Batch 200/938 - Training loss: 0.0278 - Average Test loss: 0.0640\n",
      "  Batch 300/938 - Training loss: 0.0820 - Average Test loss: 0.0639\n",
      "  Batch 400/938 - Training loss: 0.0516 - Average Test loss: 0.0644\n",
      "  Batch 500/938 - Training loss: 0.0209 - Average Test loss: 0.0639\n",
      "  Batch 600/938 - Training loss: 0.0604 - Average Test loss: 0.0642\n",
      "  Batch 700/938 - Training loss: 0.0181 - Average Test loss: 0.0639\n",
      "  Batch 800/938 - Training loss: 0.0103 - Average Test loss: 0.0637\n",
      "  Batch 900/938 - Training loss: 0.0118 - Average Test loss: 0.0637\n",
      "Epoch = 341\n",
      "  Batch 0/938 - Training loss: 0.0283 - Average Test loss: 0.0637\n",
      "  Batch 100/938 - Training loss: 0.0196 - Average Test loss: 0.0637\n",
      "  Batch 200/938 - Training loss: 0.0039 - Average Test loss: 0.0636\n",
      "  Batch 300/938 - Training loss: 0.0335 - Average Test loss: 0.0636\n",
      "  Batch 400/938 - Training loss: 0.0652 - Average Test loss: 0.0637\n",
      "  Batch 500/938 - Training loss: 0.0153 - Average Test loss: 0.0639\n",
      "  Batch 600/938 - Training loss: 0.0153 - Average Test loss: 0.0641\n",
      "  Batch 700/938 - Training loss: 0.0109 - Average Test loss: 0.0639\n",
      "  Batch 800/938 - Training loss: 0.0374 - Average Test loss: 0.0639\n",
      "  Batch 900/938 - Training loss: 0.0354 - Average Test loss: 0.0636\n",
      "Epoch = 342\n",
      "  Batch 0/938 - Training loss: 0.0101 - Average Test loss: 0.0638\n",
      "  Batch 100/938 - Training loss: 0.0129 - Average Test loss: 0.0639\n",
      "  Batch 200/938 - Training loss: 0.0226 - Average Test loss: 0.0638\n",
      "  Batch 300/938 - Training loss: 0.0187 - Average Test loss: 0.0638\n",
      "  Batch 400/938 - Training loss: 0.0157 - Average Test loss: 0.0639\n",
      "  Batch 500/938 - Training loss: 0.0262 - Average Test loss: 0.0640\n",
      "  Batch 600/938 - Training loss: 0.0255 - Average Test loss: 0.0642\n",
      "  Batch 700/938 - Training loss: 0.0263 - Average Test loss: 0.0639\n",
      "  Batch 800/938 - Training loss: 0.0110 - Average Test loss: 0.0637\n",
      "  Batch 900/938 - Training loss: 0.0147 - Average Test loss: 0.0639\n",
      "Epoch = 343\n",
      "  Batch 0/938 - Training loss: 0.0129 - Average Test loss: 0.0639\n",
      "  Batch 100/938 - Training loss: 0.0189 - Average Test loss: 0.0640\n",
      "  Batch 200/938 - Training loss: 0.0092 - Average Test loss: 0.0638\n",
      "  Batch 300/938 - Training loss: 0.0383 - Average Test loss: 0.0634\n",
      "  Batch 400/938 - Training loss: 0.0292 - Average Test loss: 0.0641\n",
      "  Batch 500/938 - Training loss: 0.0542 - Average Test loss: 0.0638\n",
      "  Batch 600/938 - Training loss: 0.0563 - Average Test loss: 0.0640\n",
      "  Batch 700/938 - Training loss: 0.0396 - Average Test loss: 0.0641\n",
      "  Batch 800/938 - Training loss: 0.0045 - Average Test loss: 0.0635\n",
      "  Batch 900/938 - Training loss: 0.0303 - Average Test loss: 0.0635\n",
      "Epoch = 344\n",
      "  Batch 0/938 - Training loss: 0.0130 - Average Test loss: 0.0639\n",
      "  Batch 100/938 - Training loss: 0.0081 - Average Test loss: 0.0639\n",
      "  Batch 200/938 - Training loss: 0.0140 - Average Test loss: 0.0637\n",
      "  Batch 300/938 - Training loss: 0.0104 - Average Test loss: 0.0639\n",
      "  Batch 400/938 - Training loss: 0.0115 - Average Test loss: 0.0637\n",
      "  Batch 500/938 - Training loss: 0.0229 - Average Test loss: 0.0637\n",
      "  Batch 600/938 - Training loss: 0.0044 - Average Test loss: 0.0638\n",
      "  Batch 700/938 - Training loss: 0.0122 - Average Test loss: 0.0639\n",
      "  Batch 800/938 - Training loss: 0.0170 - Average Test loss: 0.0637\n",
      "  Batch 900/938 - Training loss: 0.0206 - Average Test loss: 0.0638\n",
      "Epoch = 345\n",
      "  Batch 0/938 - Training loss: 0.0248 - Average Test loss: 0.0639\n",
      "  Batch 100/938 - Training loss: 0.0097 - Average Test loss: 0.0638\n",
      "  Batch 200/938 - Training loss: 0.0242 - Average Test loss: 0.0637\n",
      "  Batch 300/938 - Training loss: 0.0209 - Average Test loss: 0.0639\n",
      "  Batch 400/938 - Training loss: 0.0310 - Average Test loss: 0.0638\n",
      "  Batch 500/938 - Training loss: 0.0093 - Average Test loss: 0.0636\n",
      "  Batch 600/938 - Training loss: 0.0108 - Average Test loss: 0.0634\n",
      "  Batch 700/938 - Training loss: 0.0116 - Average Test loss: 0.0641\n",
      "  Batch 800/938 - Training loss: 0.1090 - Average Test loss: 0.0637\n",
      "  Batch 900/938 - Training loss: 0.0091 - Average Test loss: 0.0640\n",
      "Epoch = 346\n",
      "  Batch 0/938 - Training loss: 0.0057 - Average Test loss: 0.0638\n",
      "  Batch 100/938 - Training loss: 0.0167 - Average Test loss: 0.0641\n",
      "  Batch 200/938 - Training loss: 0.0065 - Average Test loss: 0.0640\n",
      "  Batch 300/938 - Training loss: 0.0295 - Average Test loss: 0.0640\n",
      "  Batch 400/938 - Training loss: 0.0352 - Average Test loss: 0.0636\n",
      "  Batch 500/938 - Training loss: 0.0109 - Average Test loss: 0.0634\n",
      "  Batch 600/938 - Training loss: 0.0312 - Average Test loss: 0.0636\n",
      "  Batch 700/938 - Training loss: 0.0167 - Average Test loss: 0.0636\n",
      "  Batch 800/938 - Training loss: 0.0058 - Average Test loss: 0.0636\n",
      "  Batch 900/938 - Training loss: 0.0101 - Average Test loss: 0.0637\n",
      "Epoch = 347\n",
      "  Batch 0/938 - Training loss: 0.0296 - Average Test loss: 0.0638\n",
      "  Batch 100/938 - Training loss: 0.0110 - Average Test loss: 0.0635\n",
      "  Batch 200/938 - Training loss: 0.0341 - Average Test loss: 0.0635\n",
      "  Batch 300/938 - Training loss: 0.0103 - Average Test loss: 0.0634\n",
      "  Batch 400/938 - Training loss: 0.0107 - Average Test loss: 0.0636\n",
      "  Batch 500/938 - Training loss: 0.0199 - Average Test loss: 0.0634\n",
      "  Batch 600/938 - Training loss: 0.0164 - Average Test loss: 0.0636\n",
      "  Batch 700/938 - Training loss: 0.0168 - Average Test loss: 0.0640\n",
      "  Batch 800/938 - Training loss: 0.0394 - Average Test loss: 0.0640\n",
      "  Batch 900/938 - Training loss: 0.0269 - Average Test loss: 0.0638\n",
      "Epoch = 348\n",
      "  Batch 0/938 - Training loss: 0.0326 - Average Test loss: 0.0638\n",
      "  Batch 100/938 - Training loss: 0.0323 - Average Test loss: 0.0636\n",
      "  Batch 200/938 - Training loss: 0.0244 - Average Test loss: 0.0636\n",
      "  Batch 300/938 - Training loss: 0.0241 - Average Test loss: 0.0638\n",
      "  Batch 400/938 - Training loss: 0.0365 - Average Test loss: 0.0641\n",
      "  Batch 500/938 - Training loss: 0.0075 - Average Test loss: 0.0634\n",
      "  Batch 600/938 - Training loss: 0.0068 - Average Test loss: 0.0637\n",
      "  Batch 700/938 - Training loss: 0.0072 - Average Test loss: 0.0636\n",
      "  Batch 800/938 - Training loss: 0.0322 - Average Test loss: 0.0635\n",
      "  Batch 900/938 - Training loss: 0.0261 - Average Test loss: 0.0635\n",
      "Epoch = 349\n",
      "  Batch 0/938 - Training loss: 0.0201 - Average Test loss: 0.0634\n",
      "  Batch 100/938 - Training loss: 0.0091 - Average Test loss: 0.0636\n",
      "  Batch 200/938 - Training loss: 0.0420 - Average Test loss: 0.0635\n",
      "  Batch 300/938 - Training loss: 0.0307 - Average Test loss: 0.0634\n",
      "  Batch 400/938 - Training loss: 0.0312 - Average Test loss: 0.0635\n",
      "  Batch 500/938 - Training loss: 0.0388 - Average Test loss: 0.0635\n",
      "  Batch 600/938 - Training loss: 0.0166 - Average Test loss: 0.0638\n",
      "  Batch 700/938 - Training loss: 0.0181 - Average Test loss: 0.0639\n",
      "  Batch 800/938 - Training loss: 0.0105 - Average Test loss: 0.0636\n",
      "  Batch 900/938 - Training loss: 0.0084 - Average Test loss: 0.0636\n"
     ]
    }
   ],
   "source": [
    "W_1 = np.random.randn(d1, d) * 0.01\n",
    "W_2 = np.random.randn(d2, d1) * 0.01\n",
    "\n",
    "### Please note that I defined this myself, just to keep track of my weight vectors. I am not using a built-in Model method here.\n",
    "model = myModel(W_1, W_2)\n",
    "\n",
    "train_e = []\n",
    "test_e = []\n",
    "\n",
    "\n",
    "epochs = 300\n",
    "alpha = 0.03\n",
    "batch_size = 64  \n",
    "\n",
    "num_batches = len(x_train) // batch_size\n",
    "if len(x_train) % batch_size != 0:\n",
    "    num_batches += 1\n",
    "print(f\"Number of batches: {num_batches}\")\n",
    "interval = num_batches // 4\n",
    "\n",
    "\n",
    "for i in range(epochs):\n",
    "    print(f\"Epoch = {i}\")\n",
    "    \n",
    "    for j, (x_batch, y_batch) in enumerate(mini_batches(x_train, y_train, batch_size)):\n",
    "        # Forward pass\n",
    "        h = first_Layer(x_batch, model.W_1)\n",
    "        yhats = softmax(h, model.W_2)\n",
    "        \n",
    "        epsilon = 1e-10\n",
    "        cross_loss = -np.sum(y_batch * np.log(yhats + epsilon), axis=1)\n",
    "        batch_loss = np.sum(cross_loss)\n",
    "\n",
    "        # Backward pass\n",
    "        e_term = yhats - y_batch\n",
    "        sum_Term = h * (1 - h) * np.dot(e_term, model.W_2)\n",
    "        \n",
    "        dW2_total = np.dot(e_term.T, h)\n",
    "        dW1_total = np.dot(sum_Term.T, x_batch)\n",
    "\n",
    "        # Update weights\n",
    "        model.W_2 -= alpha * (dW2_total / batch_size)\n",
    "        model.W_1 -= alpha * (dW1_total / batch_size)\n",
    "\n",
    "        de = 100\n",
    "        if j % de == 0:\n",
    "            train_e.append(batch_loss / batch_size)\n",
    "\n",
    "            # Test phase vectorized\n",
    "            htest = first_Layer(x_test, model.W_1)\n",
    "            yhatstest = softmax(htest, model.W_2)\n",
    "            cross_loss_test = -np.sum(y_test * np.log(yhatstest + epsilon), axis=1)\n",
    "            total_test_loss = np.sum(cross_loss_test)\n",
    "\n",
    "            test_e.append(total_test_loss / len(x_test))\n",
    "\n",
    "            print(f\"  Batch {j}/{num_batches} - Training loss: {batch_loss / batch_size:.4f} - Average Test loss: {total_test_loss / len(x_test):.4f}\")\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "points_per_epoch = num_batches // 100  # Number of times data is appended per epoch\n",
    "avg_train_e_per_epoch = [np.mean(train_e[i * points_per_epoch: (i + 1) * points_per_epoch]) for i in range(epochs)]\n",
    "avg_test_e_per_epoch = [np.mean(test_e[i * points_per_epoch: (i + 1) * points_per_epoch]) for i in range(epochs)]\n",
    "\n",
    "epochs_range = range(1, epochs + 1)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs_range, avg_train_e_per_epoch, label='Average Training Error')\n",
    "plt.plot(epochs_range, avg_test_e_per_epoch, label='Average Testing Error')\n",
    "plt.title('Training and Testing Error with 64-batch - My implementation, init weights to random')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Error')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding overall test error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Error on Test: 635.1603399691743\n",
      "Average Error on Test: 0.06351603399691742\n",
      "Accuracy on Test: 98.03%\n"
     ]
    }
   ],
   "source": [
    "# Forward pass for entire test set\n",
    "htest = first_Layer(x_test, model.W_1)\n",
    "yhatstest = softmax(htest, model.W_2)\n",
    "\n",
    "# Cross-entropy error computation\n",
    "epsilon = 1e-10\n",
    "cross_loss_test = -np.sum(y_test * np.log(yhatstest + epsilon), axis=1)\n",
    "total_error = np.sum(cross_loss_test)\n",
    "\n",
    "# Compute number of correct predictions\n",
    "correct_predictions = np.sum(np.argmax(yhatstest, axis=1) == np.argmax(y_test, axis=1))\n",
    "\n",
    "# Average error and accuracy\n",
    "average_error = total_error / len(x_test)\n",
    "accuracy = (correct_predictions / len(x_test)) * 100\n",
    "\n",
    "print(f\"Total Error on Test: {total_error}\")\n",
    "print(f\"Average Error on Test: {average_error}\")\n",
    "print(f\"Accuracy on Test: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing PyTorch now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(NN, self).__init__()\n",
    "        ### Implementing the same architecture as I used for my from-scratch model\n",
    "        self.layer1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.layer2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.layer2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tensor = torch.tensor(x_train, dtype=torch.float32)\n",
    "y_train_labels = torch.tensor(np.argmax(y_train, axis=1), dtype=torch.long)  # Convert one-hot to class indices\n",
    "x_test_tensor = torch.tensor(x_test, dtype=torch.float32)\n",
    "y_test_labels = torch.tensor(np.argmax(y_test, axis=1), dtype=torch.long)\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(x_train_tensor, y_train_labels)\n",
    "test_dataset = torch.utils.data.TensorDataset(x_test_tensor, y_test_labels)\n",
    "\n",
    "### Using the same batch size as I used previously\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1_pt = 300\n",
    "output = 10\n",
    "d_pt = 28 * 28\n",
    "lr = 0.0003\n",
    "model = NN(d_pt, d1_pt, output)\n",
    "\n",
    "### Part 4 problem 4 a)\n",
    "# with torch.no_grad():\n",
    "#     model.layer1.weight.fill_(0.0)\n",
    "#     model.layer1.bias.fill_(0.0)\n",
    "#     model.layer2.weight.fill_(0.0)\n",
    "#     model.layer2.bias.fill_(0.0)\n",
    "\n",
    "# Part 4 problem 4 b)\n",
    "# with torch.no_grad():\n",
    "#     model.layer1.weight.uniform_(-1, 1)\n",
    "#     model.layer1.bias.uniform_(-1, 1)\n",
    "#     model.layer2.weight.uniform_(-1, 1)\n",
    "#     model.layer2.bias.uniform_(-1, 1)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "epochs = 35\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35, Training Loss: 0.6114, Test Loss: 0.2995\n",
      "Epoch 2/35, Training Loss: 0.2739, Test Loss: 0.2381\n",
      "Epoch 3/35, Training Loss: 0.2218, Test Loss: 0.2057\n",
      "Epoch 4/35, Training Loss: 0.1874, Test Loss: 0.1783\n",
      "Epoch 5/35, Training Loss: 0.1613, Test Loss: 0.1534\n",
      "Epoch 6/35, Training Loss: 0.1405, Test Loss: 0.1394\n",
      "Epoch 7/35, Training Loss: 0.1234, Test Loss: 0.1247\n",
      "Epoch 8/35, Training Loss: 0.1094, Test Loss: 0.1157\n",
      "Epoch 9/35, Training Loss: 0.0971, Test Loss: 0.1066\n",
      "Epoch 10/35, Training Loss: 0.0871, Test Loss: 0.1023\n",
      "Epoch 11/35, Training Loss: 0.0782, Test Loss: 0.0946\n",
      "Epoch 12/35, Training Loss: 0.0706, Test Loss: 0.0887\n",
      "Epoch 13/35, Training Loss: 0.0636, Test Loss: 0.0854\n",
      "Epoch 14/35, Training Loss: 0.0576, Test Loss: 0.0828\n",
      "Epoch 15/35, Training Loss: 0.0522, Test Loss: 0.0789\n",
      "Epoch 16/35, Training Loss: 0.0473, Test Loss: 0.0772\n",
      "Epoch 17/35, Training Loss: 0.0433, Test Loss: 0.0733\n",
      "Epoch 18/35, Training Loss: 0.0391, Test Loss: 0.0698\n",
      "Epoch 19/35, Training Loss: 0.0356, Test Loss: 0.0709\n",
      "Epoch 20/35, Training Loss: 0.0322, Test Loss: 0.0694\n",
      "Epoch 21/35, Training Loss: 0.0289, Test Loss: 0.0683\n",
      "Epoch 22/35, Training Loss: 0.0264, Test Loss: 0.0658\n",
      "Epoch 23/35, Training Loss: 0.0236, Test Loss: 0.0664\n",
      "Epoch 24/35, Training Loss: 0.0216, Test Loss: 0.0661\n",
      "Epoch 25/35, Training Loss: 0.0193, Test Loss: 0.0651\n",
      "Epoch 26/35, Training Loss: 0.0174, Test Loss: 0.0654\n",
      "Epoch 27/35, Training Loss: 0.0157, Test Loss: 0.0645\n",
      "Epoch 28/35, Training Loss: 0.0139, Test Loss: 0.0650\n",
      "Epoch 29/35, Training Loss: 0.0125, Test Loss: 0.0643\n",
      "Epoch 30/35, Training Loss: 0.0111, Test Loss: 0.0659\n",
      "Epoch 31/35, Training Loss: 0.0099, Test Loss: 0.0638\n",
      "Epoch 32/35, Training Loss: 0.0089, Test Loss: 0.0648\n",
      "Epoch 33/35, Training Loss: 0.0078, Test Loss: 0.0651\n",
      "Epoch 34/35, Training Loss: 0.0070, Test Loss: 0.0649\n",
      "Epoch 35/35, Training Loss: 0.0061, Test Loss: 0.0656\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):   # Iterate over batches\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, target)\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, target)\n",
    "            test_loss += loss.item()\n",
    "    \n",
    "    avg_test_loss = test_loss / len(test_loader)\n",
    "    test_losses.append(avg_test_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Training Loss: {avg_train_loss:.4f}, Test Loss: {avg_test_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(train_losses, label=\"Training Loss\")\n",
    "plt.plot(test_losses, label=\"Test Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training and Test Loss over Epochs - 64-batch size PyTorch Mini-batch implementation\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Error on Test Set: 0.0656\n",
      "Total Accuracy on Test Set: 97.91%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "N = 0\n",
    "\n",
    "with torch.no_grad():  \n",
    "    for data, target in test_loader:\n",
    "        outputs = model(data)\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += (predicted == target).sum().item()\n",
    "        N += target.size(0)\n",
    "\n",
    "accuracy = correct / N * 100\n",
    "\n",
    "print(f\"Total Error on Test Set: {test_losses[-1]:.4f}\")\n",
    "print(f\"Total Accuracy on Test Set: {accuracy:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
