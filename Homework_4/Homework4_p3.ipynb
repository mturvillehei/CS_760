{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Morgan Turville-Heitz\n",
    "CS 760\n",
    "10/18/2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import ipykernel\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the Doc class, where counts/vectors are stored for each document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class docRegistry(type):\n",
    "    def __iter__(cls):\n",
    "        return iter(cls._registry)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Doc(metaclass=docRegistry):\n",
    "    _registry = []\n",
    "    \n",
    "    def __init__(self, raw, fn, testset):\n",
    "        self._registry.append(self)\n",
    "        self.fn = fn\n",
    "        self.vector = self.vectorize(raw)\n",
    "        self.char_counts = self.count(self.vector)\n",
    "        self.label = fn[0]\n",
    "        self.pe = None\n",
    "        self.pj = None\n",
    "        self.ps = None\n",
    "        self.testset = testset\n",
    "\n",
    "    def vectorize(self, data):\n",
    "        ### Stripping newlines/special characters\n",
    "        filtered = ''.join([char for char in data if char.isalpha() or char == ' '])\n",
    "        return list(filtered)\n",
    "\n",
    "    def count(self, vector):\n",
    "        count = {char: 0 for char in 'abcdefghijklmnopqrstuvwxyz '}\n",
    "        for char in vector:\n",
    "            count[char]+=1\n",
    "        return count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each language, I have a separate class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Natural log form of the class conditional probability is \n",
    "$$\\ln(P(c_{i}|e)) = \\ln(n(c_{i,e}) + \\alpha) - \\ln(N_{c} + |c| \\alpha)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class label(metaclass=docRegistry):\n",
    "    _registry = []\n",
    "    def __init__(self, prior, smoothing=0.5):\n",
    "        self._registry.append(self)\n",
    "        self.prior = prior\n",
    "        self.char_count = None\n",
    "        self.ntot = None\n",
    "        self.smoothing = smoothing\n",
    "        self.lncc = None\n",
    "        self.pcc = None\n",
    "\n",
    "    def class_conditional(self):\n",
    "        lncc = {char: 0 for char in 'abcdefghijklmnopqrstuvwxyz '}\n",
    "        ctot = 27\n",
    "        for char in lncc.keys():\n",
    "            d = np.log(self.char_count[char] + self.smoothing)\n",
    "            n = np.log(self.ntot + self.smoothing * ctot)\n",
    "            lncc[char] = d - n\n",
    "        self.lncc = lncc\n",
    "        return lncc\n",
    "    \n",
    "    def convert_P(self):\n",
    "        lncc = self.lncc\n",
    "        self.pcc = {char: np.exp(val) for char, val in lncc.items()}\n",
    "        return self.pcc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading files, creating the Doc class for each file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n"
     ]
    }
   ],
   "source": [
    "direc = r\"C:\\Users\\Meau\\Documents\\GRAD SCHOOL\\CS 760\\Hw4\\languageID\"\n",
    "files = os.listdir(direc)\n",
    "for txtfile in files:\n",
    "    testset = False\n",
    "    numlabel = int(re.search(r'(\\d+)', txtfile).group(1))\n",
    "    if int(numlabel) > 9:\n",
    "        #print(f\"Added to testset: {txtfile}\")\n",
    "        testset = True\n",
    "    path = os.path.join(direc, txtfile)\n",
    "    with open(path, 'r') as file:\n",
    "        raw = file.read().replace('\\n', '')\n",
    "    Doc(raw, str(txtfile), testset)\n",
    "print(len(Doc._registry))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the priors, with additive smoothing $$ P(x) = \\frac{n(x) + \\alpha}{N + k \\alpha }, \\alpha = \\frac{1}{2} $$ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Priors for languages are: {'e': 0.3333333333333333, 's': 0.3333333333333333, 'j': 0.3333333333333333}\n"
     ]
    }
   ],
   "source": [
    "counts = {\"e\":0, \"s\":0, \"j\":0}\n",
    "logpriors = {\"e\":0, \"s\":0, \"j\":0}\n",
    "alpha = 0.5\n",
    "Nd = 0\n",
    "k = 3\n",
    "for doc in Doc:\n",
    "    if doc.testset:\n",
    "        #print(f'Testset for doc {doc.fn}')\n",
    "        continue\n",
    "    Nd += 1\n",
    "    counts[doc.label] += 1\n",
    "\n",
    "for la in counts.keys():\n",
    "    logpriors[la] = np.log((counts[la] + alpha ) / (Nd + k * alpha))\n",
    "    \n",
    "e = label(logpriors[\"e\"])\n",
    "s = label(logpriors[\"s\"])\n",
    "j = label(logpriors[\"j\"])\n",
    "\n",
    "priors = {la : np.exp(logpriors[la]) for la in logpriors.keys()}\n",
    "print(f\"Priors for languages are: {priors}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class conditional probability is $\\theta_{i,e}\\coloneqq \\hat{p} (c_{i} | y = e)$ for $i$-th character $c_{i}$.\n",
    "$\\theta_{i,e}$ is the multinomial parameter.\n",
    "\n",
    "With additive smoothing, this becomes $$ P(c_{i}|e) = \\frac{n(c_{i,e}) + \\alpha}{N_{c} + |c| \\alpha } $$\n",
    "where $ |c| $ is the number of characters (in this case, 27).\n",
    "Looking for the conditional probability so we can find the a posteriori with prior.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ctot = {char: 0 for char in 'abcdefghijklmnopqrstuvwxyz '}\n",
    "ntot = 0\n",
    "for doc in Doc:\n",
    "    if doc.testset:\n",
    "        #print(f'Testset for doc {doc.fn}')\n",
    "        continue\n",
    "    if doc.label != \"e\":\n",
    "        continue\n",
    "\n",
    "    count = doc.char_counts\n",
    "    for char, char_count in count.items():\n",
    "        ntot += char_count\n",
    "        ctot[char] += char_count\n",
    "e.char_count = ctot\n",
    "e.ntot = ntot\n",
    "\n",
    "ctot = {char: 0 for char in 'abcdefghijklmnopqrstuvwxyz '}\n",
    "ntot = 0\n",
    "for doc in Doc:\n",
    "    if doc.testset:\n",
    "        #print(f'Testset for doc {doc.fn}')\n",
    "        continue\n",
    "    if doc.label != \"s\":\n",
    "        continue\n",
    "\n",
    "    count = doc.char_counts\n",
    "    for char, char_count in count.items():\n",
    "        ntot += char_count\n",
    "        ctot[char] += char_count\n",
    "s.char_count = ctot\n",
    "s.ntot = ntot\n",
    "\n",
    "ctot = {char: 0 for char in 'abcdefghijklmnopqrstuvwxyz '}\n",
    "ntot = 0\n",
    "for doc in Doc:\n",
    "    if doc.testset:\n",
    "        #print(f'Testset for doc {doc.fn}')\n",
    "        continue\n",
    "    if doc.label != \"j\":\n",
    "        continue\n",
    "\n",
    "    count = doc.char_counts\n",
    "    for char, char_count in count.items():\n",
    "        ntot += char_count\n",
    "        ctot[char] += char_count\n",
    "j.char_count = ctot\n",
    "j.ntot = ntot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class conditional probabilities (and their natural log) is calculated in the label class. Printing here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Class conditional log probabilities for English are: {e.class_conditional()}\")\n",
    "print(f\"Class conditional log probabilities for Spanish are: {s.class_conditional()}\")\n",
    "print(f\"Class conditional log probabilities for Japanese are: {j.class_conditional()}\")\n",
    "\n",
    "print(f\"Class conditional probabilities for English are: {e.convert_P()}\")\n",
    "print(f\"Class conditional probabilities for Spanish are: {s.convert_P()}\")\n",
    "print(f\"Class conditional probabilities for Japanese are: {j.convert_P()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latex_table(e, s, j):\n",
    "    latex_code = \"\\\\begin{table}[h!]\\n\"\n",
    "    latex_code += \"\\\\centering\\n\"\n",
    "    latex_code += \"\\\\begin{tabular}{c|ccc|ccc}\\n\"\n",
    "    latex_code += \"\\\\toprule\\n\"\n",
    "    latex_code += \"Character & $\\\\ln(P_e)$ & $\\\\ln(P_s)$ & $\\\\ln(P_j)$ & $P_e$ & $P_s$ & $P_j$ \\\\\\\\\\n\"\n",
    "    latex_code += \"\\\\midrule\\n\"\n",
    "\n",
    "    for char in 'abcdefghijklmnopqrstuvwxyz ':\n",
    "        latex_code += char + \" & \"\n",
    "        latex_code += \"{:.4f}\".format(e.lncc[char]) + \" & \"\n",
    "        latex_code += \"{:.4f}\".format(s.lncc[char]) + \" & \"\n",
    "        latex_code += \"{:.4f}\".format(j.lncc[char]) + \" & \"\n",
    "        latex_code += \"{:.4f}\".format(e.pcc[char]) + \" & \"\n",
    "        latex_code += \"{:.4f}\".format(s.pcc[char]) + \" & \"\n",
    "        latex_code += \"{:.4f}\".format(j.pcc[char])\n",
    "        latex_code += \" \\\\\\\\\\n\"\n",
    "\n",
    "    latex_code += \"\\\\bottomrule\\n\"\n",
    "    latex_code += \"\\\\end{tabular}\\n\"\n",
    "    latex_code += \"\\\\caption{Log class conditional probabilities and conditional probabilities for each character.}\\n\"\n",
    "    latex_code += \"\\\\end{table}\"\n",
    "\n",
    "    return latex_code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_output = generate_latex_table(e, s, j)\n",
    "print(latex_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\hat{e} = argmax_{e} p(e|c) $$\n",
    "$$ \\hat{e} = argmax_{e} \\frac{ p(c|e) p(e) }{p(c)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 164, 'b': 32, 'c': 53, 'd': 57, 'e': 311, 'f': 55, 'g': 51, 'h': 140, 'i': 140, 'j': 3, 'k': 6, 'l': 85, 'm': 64, 'n': 139, 'o': 182, 'p': 53, 'q': 3, 'r': 141, 's': 186, 't': 225, 'u': 65, 'v': 31, 'w': 47, 'x': 4, 'y': 38, 'z': 2, ' ': 498}\n"
     ]
    }
   ],
   "source": [
    "for doc in Doc:\n",
    "    if doc.testset == True and doc.fn == 'e10.txt':\n",
    "        #print('e10.txt found.')\n",
    "        print(doc.char_counts)\n",
    "        xhat = doc.char_counts\n",
    "        test_doc = doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\hat{p}(X|y) = \\prod_{i=1}^{d} \\theta_{i,y}^{x_{i}}$$\n",
    "$$log(\\hat{p}(X|y)) = \\sum_{i=1}^{d} log(\\theta_{i,y}^{x_{i}})$$\n",
    "$$log(\\hat{p}{X|Y = y}) = \\sum_{i = a}^{i=space}x_{i}*log(\\theta_{i, Y=y})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(f\"As a reminder, class conditionals are the following \\n e: {e.pcc}, s: {s.pcc}, j: {j.pcc}\")\n",
    "\n",
    "lconditional_e = 0\n",
    "lconditional_j = 0\n",
    "lconditional_s = 0\n",
    "\n",
    "for char, val in xhat.items():\n",
    "    char_count = test_doc.char_counts\n",
    "    lconditional_e += val * np.log(e.pcc[char])\n",
    "    lconditional_j += val * np.log(j.pcc[char])\n",
    "    lconditional_s += val * np.log(s.pcc[char])\n",
    "conditional_e = np.exp(lconditional_e)\n",
    "conditional_j = np.exp(lconditional_j)\n",
    "conditional_s = np.exp(lconditional_s)\n",
    "print(f\"For test document e10.txt, log conditional probabilities are: \\n For y = e, {lconditional_e} \\n For y = j, {lconditional_j} \\n For y = s, {lconditional_s}\")\n",
    "print(f\"For test document e10.txt, conditional probabilities are: \\n For y = e, {conditional_e:.6e} \\n For y = j, {conditional_j:.6e} \\n For y = s, {conditional_s:.6e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$p(Y=y|x) = \\frac{p(x|Y=y)p(Y=y)}{p(x)}$$\n",
    "$$log(p(Y=y|x)) = log(p(x|Y=y)) + log(p(Y=y)) - log(p(x))$$\n",
    "Omitting $p(x)$ for stability\n",
    "\n",
    "$$p(Y=y|x) = p(x|Y=y)p(Y=y)$$\n",
    "$$log(p(Y=y|x)) = log(p(x|Y=y)) + log(p(Y=y))$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Log priors are {logpriors}\")\n",
    "print(f\"Log conditionals for e10.txt are e: {lconditional_e}, j: {lconditional_j}, s: {lconditional_s}\")\n",
    "print(f\"Omitting p(x) for stability: \")\n",
    "lposteriori_e = logpriors['e'] + lconditional_e\n",
    "lposteriori_j = logpriors['j'] + lconditional_j\n",
    "lposteriori_s = logpriors['s'] + lconditional_s\n",
    "\n",
    "print(f\"log(p(Y=e | x = e10.txt)) is {lposteriori_e}\")\n",
    "print(f\"p(Y=e | x = e10.txt) is {np.exp(lposteriori_e)}\")\n",
    "print(f\"log(p(Y=s | x = e10.txt)) is {lposteriori_s}\")\n",
    "print(f\"p(Y=s | x = e10.txt) is {np.exp(lposteriori_s)}\")\n",
    "print(f\"log(p(Y=j | x = e10.txt)) is {lposteriori_j}\")\n",
    "print(f\"p(Y=j | x = e10.txt) is {np.exp(lposteriori_j)}\")\n",
    "\n",
    "print(f\"Finding the normalization factor manually:\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'e': {'e': 10, 's': 0, 'j': 0}, 's': {'e': 0, 's': 10, 'j': 0}, 'j': {'e': 0, 's': 0, 'j': 10}}\n"
     ]
    }
   ],
   "source": [
    "### First key is the correct label, second key is the predicted label\n",
    "predictions = {'e': {'e': 0, 's':0, 'j':0 }, 's': {'e': 0, 's':0, 'j':0 }, 'j':{'e': 0, 's':0, 'j':0 }}\n",
    "for doc in Doc:\n",
    "    if doc.testset:\n",
    "        lab = doc.label\n",
    "        #print(f\"True label is {lab} for doc {doc.fn}\")\n",
    "        lconditional = {'e' : 0, 's': 0, 'j' :0}\n",
    "\n",
    "        ### Creating the bag of words representation for the document:\n",
    "        xhat = doc.char_counts\n",
    "        #print(f\"For the document {doc.fn}, bag of word count is {xhat}\")\n",
    "        for char, val in xhat.items():\n",
    "            ### Char count * log(p(c | y = Y))\n",
    "            lconditional['e'] += val * np.log(e.pcc[char])\n",
    "            lconditional['s'] += val * np.log(s.pcc[char])\n",
    "            lconditional['j'] += val * np.log(j.pcc[char])\n",
    "        \n",
    "        lposteriori = {'e' : 0, 's': 0, 'j' :0}\n",
    "        for key, i in lposteriori.items():\n",
    "            lposteriori[key] = lconditional[key] + logpriors[key]\n",
    "        #print(f\"Posteriori for {doc.fn} is {lposteriori}\")\n",
    "        pred = max(lposteriori, key=lposteriori.get)\n",
    "        predictions[lab][pred] += 1\n",
    "print(predictions) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
